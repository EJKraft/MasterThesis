{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenSMILE Analysis\n",
    "This notebook loads OpenSMILE csv- data, cleans and plots it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import statsmodels.api as sm\n",
    "#import nltk\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import Helper as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load .csv data with results of OpenSMILE Analysis\n",
    "First we load .csv data and clean it (removing of NaNs), then we store information of all files in seperate panda dataframes containing information about affect, emotion and valence/arousal for all participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"UIST2019_OpenSMILE.csv\")\n",
    "\n",
    "#Set Labels \n",
    "emotion_label = ['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness']\n",
    "affect_label = ['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired']\n",
    "loi_label = ['Disinterest', 'Normal', 'High Interest']\n",
    "\n",
    "#Get specific data and save it into new data frames\n",
    "# We use the pandas .copy(deep=True) function to prevent the SettingWithCopyWarning we would otherwise get. Since we do\n",
    "# not write, but only read from the data, the warning does not affect the data frames\n",
    "df_emotion = data[['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness', 'Filename']].copy(deep=True)\n",
    "df_affect = data[['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired', 'Filename']].copy(deep=True)\n",
    "df_loi = data[['Disinterest', 'Normal', 'High Interest', 'Filename']].copy(deep=True)\n",
    "df_ar_val = data[['Arousal', 'Valence', 'Filename']].copy(deep=True)\n",
    "#For further usage, we want to append the CharacterID as a column, which is saved with other information in the filename\n",
    "#Since we only want the digits, we can remove all non-digit characters of the filename column and append the column to the df\n",
    "\n",
    "df_emotion['Char_ID'] = df_emotion['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_affect['Char_ID'] = df_affect['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_loi['Char_ID'] = df_loi['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Filename'].replace('\\D+','', regex = True).copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load information about the speakers\n",
    "The speaker ID is saved in a single .csv file containing four important columns: ID, Age, Sex and Acadedmic Status. Since before loaded OpenSMILE csv files are named using the corresponding index (ex. speaker with id 0 has two files 0_a.csv and 0_b.csv), so that a link can be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_data = pd.read_csv(\"UIST2019_CharacterData.csv\")  \n",
    "\n",
    "#Join above tables and Character Tables\n",
    "\n",
    "#To Join DataFrames we have to cast the column on which we want to join to int, so that both columns have the same data type\n",
    "char_data['ID'] = char_data['ID'].astype(int)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Char_ID'].astype(int)\n",
    "df_emotion['Char_ID'] = df_emotion['Char_ID'].astype(int)\n",
    "df_affect['Char_ID'] = df_affect['Char_ID'].astype(int)\n",
    "df_loi['Char_ID'] = df_loi['Char_ID'].astype(int)\n",
    "\n",
    "#Safe new data frames\n",
    "df_ar_val_char = df_ar_val.merge(char_data, how = 'left', left_on='Char_ID', right_on='ID')\n",
    "df_emotion_char = df_emotion.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_affect_char = df_affect.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_loi_char = df_loi.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now have a look at correlation\n",
    "### Have a look at arousal and what it corrlates with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions and Arousal\n",
      "Correlation between Arousal and Anger: -0.11960116467375333\n",
      "Cohen d: 1.0038101525157788\n",
      "Correlation between Arousal and Boredom: -0.15724156022576966\n",
      "Cohen d: 0.9280649625886008\n",
      "Correlation between Arousal and Disgust: 0.31142090322066945\n",
      "Cohen d: 0.12619986564219535\n",
      "Correlation between Arousal and Fear: -0.12065193543111381\n",
      "Cohen d: 1.0088509049605552\n",
      "Correlation between Arousal and Happiness: -0.12745701355512387\n",
      "Cohen d: 1.0068969820425526\n",
      "Correlation between Arousal and Emo_Neutral: -0.12625517556888255\n",
      "Cohen d: 1.0000073098884006\n",
      "Correlation between Arousal and Sadness: -0.2690114288749918\n",
      "Cohen d: -5.460177225486265\n",
      "Affect and Arousal\n",
      "Correlation between Arousal and Aggressiv: 0.06684792387301247\n",
      "Cohen d: 0.048486623323264935\n",
      "Correlation between Arousal and Cheerful: -0.5678322970999742\n",
      "Cohen d: -1.2806979634109281\n",
      "Correlation between Arousal and Intoxicated: 0.614456354498157\n",
      "Cohen d: -1.1121919431101954\n",
      "Correlation between Arousal and Nervous: 0.2005106913725884\n",
      "Cohen d: 0.30894916626593316\n",
      "Correlation between Arousal and Aff_Neutral: 0.0980936441028357\n",
      "Cohen d: -0.21805388899292638\n",
      "Correlation between Arousal and Tired: -0.6964226522030321\n",
      "Cohen d: -0.24281009340061468\n",
      "Level of Interest and Arousal\n",
      "Correlation between Arousal and Disinterest: 0.39974083975192914\n",
      "Cohen d: 0.3941755427973242\n",
      "Correlation between Arousal and Normal: -0.3689133344633781\n",
      "Cohen d: -5.08983504630847\n",
      "Correlation between Arousal and High Interest: 0.22722510213233663\n",
      "Cohen d: -0.004519922768281071\n"
     ]
    }
   ],
   "source": [
    "#'Clean' our dataFrames so that we can call the panda .corr function (default is spearman)\n",
    "#Let's start with arousal and look how correlation is between emotions\n",
    "print('Emotions and Arousal')\n",
    "cor_ar_emo = hp.correlations(df_ar_val['Arousal'], df_emotion, emotion_label)\n",
    "# Now arousal and affect\n",
    "print('Affect and Arousal')\n",
    "cor_ar_aff = hp.correlations(df_ar_val['Arousal'], df_affect, affect_label)\n",
    "# Now arousal and level of Interest\n",
    "print('Level of Interest and Arousal')\n",
    "cor_ar_loi = hp.correlations(df_ar_val['Arousal'], df_loi, loi_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now look at valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions and valence\n",
      "Correlation between Valence and Anger: -0.3124995201247417\n",
      "Cohen d: 1.4200472018669366\n",
      "Correlation between Valence and Boredom: -0.26509745567227183\n",
      "Cohen d: 1.3594280990223377\n",
      "Correlation between Valence and Disgust: -0.20672906887783082\n",
      "Cohen d: 0.5867104641016552\n",
      "Correlation between Valence and Fear: -0.27483848312832276\n",
      "Cohen d: 1.4239631878102155\n",
      "Correlation between Valence and Happiness: -0.3065434608342312\n",
      "Cohen d: 1.422446394407046\n",
      "Correlation between Valence and Emo_Neutral: -0.24688029616822277\n",
      "Cohen d: 1.417063981453608\n",
      "Correlation between Valence and Sadness: 0.26306821038460826\n",
      "Cohen d: -4.373471293321692\n",
      "Affect and valence\n",
      "Correlation between Valence and Aggressiv: -0.3335699261573498\n",
      "Cohen d: 0.6561805645814583\n",
      "Correlation between Valence and Cheerful: -0.7241748894708327\n",
      "Cohen d: -0.6553855428137522\n",
      "Correlation between Valence and Intoxicated: 0.5310386061614225\n",
      "Cohen d: -0.6546721565220764\n",
      "Correlation between Valence and Nervous: 0.6158725167513683\n",
      "Cohen d: 0.8479352096653413\n",
      "Correlation between Valence and Aff_Neutral: 0.32167413838248893\n",
      "Cohen d: 0.41672703633395003\n",
      "Correlation between Valence and Tired: -0.5242922646584782\n",
      "Cohen d: 0.3262474911129793\n",
      "Level of Interest and valence\n",
      "Correlation between Valence and Disinterest: 0.7400616295675385\n",
      "Cohen d: 0.9155337367006623\n",
      "Correlation between Valence and Normal: -0.38066453831713293\n",
      "Cohen d: -4.028634644602963\n",
      "Correlation between Valence and High Interest: 0.06689315956535821\n",
      "Cohen d: 0.5020188775368657\n"
     ]
    }
   ],
   "source": [
    "print('Emotions and valence')\n",
    "cor_val_emo = hp.correlations(df_ar_val['Valence'], df_emotion, emotion_label)\n",
    "\n",
    "# Now valence and affect\n",
    "print('Affect and valence')\n",
    "cor_val_aff = hp.correlations(df_ar_val['Valence'], df_affect, affect_label)\n",
    "\n",
    "# Now arousal and level of Interest\n",
    "print('Level of Interest and valence')\n",
    "cor_val_loi = hp.correlations(df_ar_val['Valence'], df_loi, loi_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now look at the different emotions and how they correlate with affect and level of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGER\n",
      "Affect and anger\n",
      "Correlation between Anger and Aggressiv: 0.23964088160619282\n",
      "Cohen d: -2.575375652135281\n",
      "Correlation between Anger and Cheerful: 0.2766279052354653\n",
      "Cohen d: -2.54244685327253\n",
      "Correlation between Anger and Intoxicated: -0.19822753557486464\n",
      "Cohen d: -1.8417008864025526\n",
      "Correlation between Anger and Nervous: -0.13735598175422528\n",
      "Cohen d: -1.3004006304271691\n",
      "Correlation between Anger and Aff_Neutral: -0.16259822887082206\n",
      "Cohen d: -2.34163026077441\n",
      "Correlation between Anger and Tired: 0.1105955221813773\n",
      "Cohen d: -1.5252241417571457\n",
      "Level of Interest and anger\n",
      "Correlation between Anger and Disinterest: -0.16507842650147914\n",
      "Cohen d: -1.0834350225209848\n",
      "Correlation between Anger and Normal: 0.010935129350005316\n",
      "Cohen d: -7.514696690964597\n",
      "Correlation between Anger and High Interest: 0.07164551352517692\n",
      "Cohen d: -0.9999633842840118\n",
      "BOREDOM\n",
      "Affect and boredom\n",
      "Correlation between Boredom and Aggressiv: 0.07834589344162006\n",
      "Cohen d: -2.1330200744748296\n",
      "Correlation between Boredom and Cheerful: 0.1767393989128617\n",
      "Cohen d: -2.4581912670836346\n",
      "Correlation between Boredom and Intoxicated: -0.18483221296969699\n",
      "Cohen d: -1.7980440420877883\n",
      "Correlation between Boredom and Nervous: -0.12400315360786279\n",
      "Cohen d: -1.1047086562092872\n",
      "Correlation between Boredom and Aff_Neutral: -0.17007575269882744\n",
      "Cohen d: -2.0945353154020085\n",
      "Correlation between Boredom and Tired: 0.2830911325724964\n",
      "Cohen d: -1.4223698699195593\n",
      "Level of Interest and boredom\n",
      "Correlation between Boredom and Disinterest: -0.1367293590260142\n",
      "Cohen d: -0.9075730474347967\n",
      "Correlation between Boredom and Normal: -0.013440919988926884\n",
      "Cohen d: -7.363463750302905\n",
      "Correlation between Boredom and High Interest: 0.0856690729350812\n",
      "Cohen d: -0.9252198532461439\n",
      "DISGUST\n",
      "Affect and disgust\n",
      "Correlation between Disgust and Aggressiv: 0.37694146943719\n",
      "Cohen d: -0.1161321822235196\n",
      "Correlation between Disgust and Cheerful: 0.08952141760002523\n",
      "Cohen d: -1.3063208480697173\n",
      "Correlation between Disgust and Intoxicated: 0.1247168470030946\n",
      "Cohen d: -1.1560011541495536\n",
      "Correlation between Disgust and Nervous: -0.2576726837151067\n",
      "Cohen d: 0.11845362481151486\n",
      "Correlation between Disgust and Aff_Neutral: -0.21368350957596924\n",
      "Cohen d: -0.3424429506372948\n",
      "Correlation between Disgust and Tired: -0.25438924450442235\n",
      "Cohen d: -0.3533880303564451\n",
      "Level of Interest and disgust\n",
      "Correlation between Disgust and Disinterest: -0.2564263734274719\n",
      "Cohen d: 0.19402723106634406\n",
      "Correlation between Disgust and Normal: -0.029391169184419565\n",
      "Cohen d: -4.845714401299939\n",
      "Correlation between Disgust and High Interest: 0.16556260385663266\n",
      "Cohen d: -0.12980258394857422\n",
      "FEAR\n",
      "Affect and fear\n",
      "Correlation between Fear and Aggressiv: 0.1423910167383337\n",
      "Cohen d: -2.591423582464778\n",
      "Correlation between Fear and Cheerful: 0.18965824993842398\n",
      "Cohen d: -2.546903605852709\n",
      "Correlation between Fear and Intoxicated: -0.16663235144115726\n",
      "Cohen d: -1.8445424174129783\n",
      "Correlation between Fear and Nervous: -0.11227194899647507\n",
      "Cohen d: -1.310832460374885\n",
      "Correlation between Fear and Aff_Neutral: -0.1561388444627538\n",
      "Cohen d: -2.3520102801316973\n",
      "Correlation between Fear and Tired: 0.18589874955633273\n",
      "Cohen d: -1.5311535835103351\n",
      "Level of Interest and fear\n",
      "Correlation between Fear and Disinterest: -0.12744156192437053\n",
      "Cohen d: -1.093501989424454\n",
      "Correlation between Fear and Normal: -0.0243036230598865\n",
      "Cohen d: -7.5196335439109605\n",
      "Correlation between Fear and High Interest: 0.09362971483439685\n",
      "Cohen d: -1.004950812816936\n",
      "HAPPINESS\n",
      "Affect and happiness\n",
      "Correlation between Happiness and Aggressiv: 0.20534987215712805\n",
      "Cohen d: -2.5854381244823825\n",
      "Correlation between Happiness and Cheerful: 0.2537381981065933\n",
      "Cohen d: -2.5451908223093525\n",
      "Correlation between Happiness and Intoxicated: -0.1965279642079321\n",
      "Cohen d: -1.8434412974958938\n",
      "Correlation between Happiness and Nervous: -0.13018363156056367\n",
      "Cohen d: -1.3068337089274225\n",
      "Correlation between Happiness and Aff_Neutral: -0.16522491340865858\n",
      "Cohen d: -2.3480793079561004\n",
      "Correlation between Happiness and Tired: 0.1499572154730419\n",
      "Cohen d: -1.528867878916343\n",
      "Level of Interest and happiness\n",
      "Correlation between Happiness and Disinterest: -0.15534608270169906\n",
      "Cohen d: -1.0896301764388374\n",
      "Correlation between Happiness and Normal: -0.00036844662020440446\n",
      "Cohen d: -7.517786693541222\n",
      "Correlation between Happiness and High Interest: 0.07989461596657478\n",
      "Cohen d: -1.0030173577621644\n",
      "NEUTRAL\n",
      "Affect and neutral\n",
      "Correlation between Emo_Neutral and Aggressiv: 0.11079884527138448\n",
      "Cohen d: -2.5572734345351678\n",
      "Correlation between Emo_Neutral and Cheerful: 0.1641755096601197\n",
      "Cohen d: -2.538707267294052\n",
      "Correlation between Emo_Neutral and Intoxicated: -0.16592865155109932\n",
      "Cohen d: -1.8395490900892173\n",
      "Correlation between Emo_Neutral and Nervous: -0.11445914461707266\n",
      "Cohen d: -1.291380878743145\n",
      "Correlation between Emo_Neutral and Aff_Neutral: -0.1506401419066327\n",
      "Cohen d: -2.331433356798566\n",
      "Correlation between Emo_Neutral and Tired: 0.23009197905603573\n",
      "Cohen d: -1.5204260722078475\n",
      "Level of Interest and neutral\n",
      "Correlation between Emo_Neutral and Disinterest: -0.12994166190707035\n",
      "Cohen d: -1.0750604037695506\n",
      "Correlation between Emo_Neutral and Normal: 0.008048156317407353\n",
      "Cohen d: -7.509264614418006\n",
      "Correlation between Emo_Neutral and High Interest: 0.05705050732177956\n",
      "Cohen d: -0.9962059466147009\n",
      "SADNESS\n",
      "Affect and sadness\n",
      "Correlation between Sadness and Aggressiv: -0.39044718660112776\n",
      "Cohen d: 6.821393207292829\n",
      "Correlation between Sadness and Cheerful: -0.13007090009202696\n",
      "Cohen d: 3.918616670970277\n",
      "Correlation between Sadness and Intoxicated: -0.07913783239006948\n",
      "Cohen d: 2.9303855557417546\n",
      "Correlation between Sadness and Nervous: 0.2792689302393017\n",
      "Cohen d: 6.804812680813034\n",
      "Correlation between Sadness and Aff_Neutral: 0.2462989563943794\n",
      "Cohen d: 6.297171960017214\n",
      "Correlation between Sadness and Tired: 0.18897935890132767\n",
      "Cohen d: 5.5382633982679685\n",
      "Level of Interest and sadness\n",
      "Correlation between Sadness and Disinterest: 0.281475518849079\n",
      "Cohen d: 6.856253108268133\n",
      "Correlation between Sadness and Normal: 0.030589613914889895\n",
      "Cohen d: 0.40087319889711087\n",
      "Correlation between Sadness and High Interest: -0.17977828057308282\n",
      "Cohen d: 5.433286987577207\n"
     ]
    }
   ],
   "source": [
    "# Now emotion and affect\n",
    "print('ANGER')\n",
    "print('Affect and anger')\n",
    "cor_ang_aff = hp.correlations(df_emotion['Anger'], df_affect, affect_label)\n",
    "# Now arousal and level of Interest\n",
    "print('Level of Interest and anger')\n",
    "cor_ang_loi = hp.correlations(df_emotion['Anger'], df_loi, loi_label)\n",
    "##########\n",
    "# Now look at boredom\n",
    "print('BOREDOM')\n",
    "print('Affect and boredom')\n",
    "cor_bor_aff = hp.correlations(df_emotion['Boredom'], df_affect, affect_label)\n",
    "# Now arousal and level of Interest\n",
    "print('Level of Interest and boredom')\n",
    "cor_bor_loi = hp.correlations(df_emotion['Boredom'], df_loi, loi_label)\n",
    "##########\n",
    "# Disgust\n",
    "print('DISGUST')\n",
    "print('Affect and disgust')\n",
    "cor_dis_aff = hp.correlations(df_emotion['Disgust'], df_affect, affect_label)\n",
    "# Now level of Interest\n",
    "print('Level of Interest and disgust')\n",
    "cor_dis_loi = hp.correlations(df_emotion['Disgust'], df_loi, loi_label)\n",
    "######\n",
    "# fear\n",
    "print('FEAR')\n",
    "print('Affect and fear')\n",
    "cor_fea_aff = hp.correlations(df_emotion['Fear'], df_affect, affect_label)\n",
    "# Now arousal and level of Interest\n",
    "print('Level of Interest and fear')\n",
    "cor_fea_loi = hp.correlations(df_emotion['Fear'], df_loi, loi_label)\n",
    "##########\n",
    "# happiness\n",
    "print('HAPPINESS')\n",
    "print('Affect and happiness')\n",
    "cor_hap_aff = hp.correlations(df_emotion['Happiness'], df_affect, affect_label)\n",
    "# Now level of Interest\n",
    "print('Level of Interest and happiness')\n",
    "cor_hap_loi = hp.correlations(df_emotion['Happiness'], df_loi, loi_label)\n",
    "##########\n",
    "# neutral\n",
    "print('NEUTRAL')\n",
    "print('Affect and neutral')\n",
    "cor_eneu_aff = hp.correlations(df_emotion['Emo_Neutral'], df_affect, affect_label)\n",
    "# Now arousal and level of Interest\n",
    "print('Level of Interest and neutral')\n",
    "cor_eneu_loi = hp.correlations(df_emotion['Emo_Neutral'], df_loi, loi_label)\n",
    "##########\n",
    "# Sadness\n",
    "print('SADNESS')\n",
    "print('Affect and sadness')\n",
    "cor_sad_aff = hp.correlations(df_emotion['Sadness'], df_affect, affect_label)\n",
    "# Now level of Interest\n",
    "print('Level of Interest and sadness')\n",
    "cor_sad_loi = hp.correlations(df_emotion['Sadness'], df_loi, loi_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now have a look at affect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGRESSIV\n",
      "Level of Interest and aggressiv\n",
      "Correlation between Aggressiv and Disinterest: -0.37600554602965947\n",
      "Cohen d: 0.6172006300170615\n",
      "Correlation between Aggressiv and Normal: 0.18040556873532998\n",
      "Cohen d: -6.405055252844228\n",
      "Correlation between Aggressiv and High Interest: -0.018773756064177527\n",
      "Cohen d: -0.054025108125872405\n",
      "CHEERFUL\n",
      "Level of Interest and cheerful\n",
      "Correlation between Cheerful and Disinterest: -0.5724896790302542\n",
      "Cohen d: 1.887980017620989\n",
      "Correlation between Cheerful and Normal: 0.2795570728565973\n",
      "Cohen d: -3.553168536617402\n",
      "Correlation between Cheerful and High Interest: -0.03429455210080225\n",
      "Cohen d: 1.2709946787499047\n",
      "INTOXICATED\n",
      "Level of Interest and intoxicated\n",
      "Correlation between Intoxicated and Disinterest: 0.28524946241995097\n",
      "Cohen d: 1.4654871740406061\n",
      "Correlation between Intoxicated and Normal: -0.13644370042294082\n",
      "Cohen d: -2.6319160155207424\n",
      "Correlation between Intoxicated and High Interest: 0.013754189913378435\n",
      "Cohen d: 1.106291756382935\n",
      "NERVOUS\n",
      "Level of Interest and nervous\n",
      "Correlation between Nervous and Disinterest: 0.7684569817511463\n",
      "Cohen d: 0.13490624087929995\n",
      "Correlation between Nervous and Normal: -0.48578313687088537\n",
      "Cohen d: -6.398932502638375\n",
      "Correlation between Nervous and High Interest: 0.17537764274697\n",
      "Cohen d: -0.3121262417272819\n",
      "NEUTRAL\n",
      "Level of Interest and neutral\n",
      "Correlation between Aff_Neutral and Disinterest: 0.30371913827842656\n",
      "Cohen d: 0.9297569485185634\n",
      "Correlation between Aff_Neutral and Normal: 0.013186413274301857\n",
      "Cohen d: -5.884976654484494\n",
      "Correlation between Aff_Neutral and High Interest: -0.17079098449486468\n",
      "Cohen d: 0.21069968903314212\n",
      "TIRED\n",
      "Level of Interest and tired\n",
      "Correlation between Tired and Disinterest: -0.2859440058754495\n",
      "Cohen d: 0.7570410120592361\n",
      "Correlation between Tired and Normal: 0.1002300746270295\n",
      "Cohen d: -5.152354009463414\n",
      "Correlation between Tired and High Interest: 0.02897821065737056\n",
      "Cohen d: 0.23657217999974173\n"
     ]
    }
   ],
   "source": [
    "##########\n",
    "# Aggressiv\n",
    "print('AGGRESSIV')\n",
    "print('Level of Interest and aggressiv')\n",
    "cor_agg_loi = hp.correlations(df_affect['Aggressiv'], df_loi, loi_label)\n",
    "##########\n",
    "# Cheerful\n",
    "print('CHEERFUL')\n",
    "print('Level of Interest and cheerful')\n",
    "cor_che_loi = hp.correlations(df_affect['Cheerful'], df_loi, loi_label)\n",
    "##########\n",
    "# Intoxicated\n",
    "print('INTOXICATED')\n",
    "print('Level of Interest and intoxicated')\n",
    "cor_tox_loi = hp.correlations(df_affect['Intoxicated'], df_loi, loi_label)\n",
    "##########\n",
    "# Nervous\n",
    "print('NERVOUS')\n",
    "print('Level of Interest and nervous')\n",
    "cor_ner_loi = hp.correlations(df_affect['Nervous'], df_loi, loi_label)\n",
    "##########\n",
    "# Neutral\n",
    "print('NEUTRAL')\n",
    "print('Level of Interest and neutral')\n",
    "# Now intoxicated and level of Interest\n",
    "cor_aneu = hp.correlations(df_affect['Aff_Neutral'], df_loi, loi_label)\n",
    "#########\n",
    "# Tired\n",
    "print('TIRED')\n",
    "print('Level of Interest and tired')\n",
    "cor_tir_loi = hp.correlations(df_affect['Tired'], df_loi, loi_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared Test of Independence\n",
    "We Start with characteristic sex. The null hypothesis states that the two categorical variables sex and e.g. emotion are independent.\n",
    "\n",
    "For that we convert the previously used data frames which contain probabilities of e.g. emotion, affect etc. to frequency tables using the helper method calcFrequencyTable(). For each row (sample) the function selects the maximum probability and counts it as an occured frequency. Furthermore the function takes in an integer so that the matching labels for emotion are generated (voice features). The second integer defines the character feature e.g. Age, so that it can split the data set into a form of n x m, where n stands for the number of character features (in most cases it's 2, but for age it's 3) and m stands for the number of voice features e.g. number of different emotions.  \n",
    "The frequency tables are then used as input for the stats.chi2_contingency() function.\n",
    "\n",
    "If the p-value is significant, residuals are computed to identify the cells, in which the groups differ, i.e. the data sets differ in the emotion 'anger', which contributes to the significant p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reduction operation 'argmax' not allowed for this dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3e2d4ed5897f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0memo_sex_chi2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_emotion_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0maff_sec_chi2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_affect_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mar_val_sec_chi2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_ar_val_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloi_sec_chi2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_loi_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Helper.py\u001b[0m in \u001b[0;36mchi2\u001b[1;34m(data, char_feature, type, shouldPrint)\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_feature\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                         \u001b[1;31m# Last zero stands for char_feature = Sex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                         \u001b[0mfre_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalcFrequencyTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_data_group0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_data_group1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m                         \u001b[0mfre_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Male'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Female'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32melif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_feature\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Academic Status'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Helper.py\u001b[0m in \u001b[0;36mcalcFrequencyTable\u001b[1;34m(data, voice_feature, char_feature)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;31m#0 stands for sex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_feature\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m                 \u001b[0mmaxValueIndex_male\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m                 \u001b[0mmax_ValueIndex_female\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[0mtemp_male\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaxValueIndex_male\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36midxmax\u001b[1;34m(self, axis, skipna)\u001b[0m\n\u001b[0;32m   7040\u001b[0m         \"\"\"\n\u001b[0;32m   7041\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7042\u001b[1;33m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnanops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanargmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7043\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7044\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobj_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'reduction operation {name!r} not allowed for this dtype'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nan'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: reduction operation 'argmax' not allowed for this dtype"
     ]
    }
   ],
   "source": [
    "emo_sex_chi2 = hp.chi2(df_emotion_char, 'Sex', 0, True)\n",
    "aff_sec_chi2 = hp.chi2(df_affect_char, 'Sex', 1, True)\n",
    "ar_val_sec_chi2 = hp.chi2(df_ar_val_char, 'Sex', 2, True)\n",
    "loi_sec_chi2 = hp.chi2(df_loi_char, 'Sex', 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now move on to academic status, the hypothesis being that the variables academic status and e.g. emotion are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_aca_chi2 = hp.chi2(df_emotion_char, 'Academic Status', 0, True)\n",
    "aff_aca_chi2 = hp.chi2(df_affect_char, 'Academic Status', 1, True)\n",
    "ar_val_aca_chi2 = hp.chi2(df_ar_val_char, 'Academic Status', 2, True)\n",
    "loi_aca_chi2 = hp.chi2(df_loi_char, 'Academic Status', 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look if age and e.g. emotion/ affect/ arousal-valence/ level of interest are independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_age_chi2 = hp.chi2(df_emotion_char, 'Age', 0, True)\n",
    "aff_age_chi2 = hp.chi2(df_affect_char, 'Age', 1, True)\n",
    "ar_val_age_chi2 = hp.chi2(df_ar_val_char, 'Age', 2, True)\n",
    "loi_age_chi2 = hp.chi2(df_loi_char, 'Age', 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Hoc tests for age, as it has three different groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('post-hoc emotions and different groups')\n",
    "emo_reject_list, emo_corrected_p_vals, emo_combinations, emo_residuals= hp.chi2_post_hoc(emo_age_chi2[1], 'bonferroni', True, True)\n",
    "print('\\n post-hoc affect and different groups')\n",
    "aff_reject_list, emo_corrected_p_vals, emo_combinations, aff_residuals = hp.chi2_post_hoc(aff_age_chi2[1], 'bonferroni', True, True)\n",
    "print('\\n post-hoc arousal-valence and different groups')\n",
    "ar_val_reject_list, ar_val_corrected_p_vals, ar_val_combinations, ar_val_residuals = hp.chi2_post_hoc(ar_val_age_chi2[1], 'bonferroni',True, True)\n",
    "print('\\n post-hoc level of intereset and different groups')\n",
    "loi_reject_list, loi_corrected_p_vals, loi_combinations, loi_residuals = hp.chi2_post_hoc(loi_age_chi2[1], 'bonferroni', True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[8.940363845820904,\n",
       "  0.20106734364852652,\n",
       "  3.116329600922195,\n",
       "  4.155098206181356,\n",
       "  8.418495087119116,\n",
       "  1.7030488881904489],\n",
       " [0.003039101449066641,\n",
       "  0.6542099781445709,\n",
       "  0.07860900530563346,\n",
       "  0.04245554779569083,\n",
       "  0.004011329140755848,\n",
       "  0.19296887812501648]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with Emotion and Sex\n",
    "emo_temp_sex = df_emotion_char.drop(['Char_ID','ID', 'Filename', 'Age', 'Academic Status'], axis = 1)\n",
    "anova_emo_sex = hp.f_anova(emo_temp_sex, emotion_label, 'Sex')\n",
    "#Affect and Sex\n",
    "aff_temp_sex = df_affect_char.drop(['Char_ID','ID', 'Filename', 'Age', 'Academic Status'], axis = 1)\n",
    "anova_aff_sex = hp.f_anova(aff_temp_sex, affect_label, 'Sex')\n",
    "#Level of Interest and Sex\n",
    "loi_temp_sex = df_loi_char.drop(['Char_ID','ID', 'Filename', 'Age', 'Academic Status'], axis = 1)\n",
    "anova_loi_sex = hp.f_anova(loi_temp_sex, loi_label, 'Sex')\n",
    "#Arousal-Valence and Sex\n",
    "arval_temp_sex = df_ar_val_char.drop(['Char_ID','ID', 'Filename', 'Age', 'Academic Status'], axis = 1)\n",
    "anova_arval_sex = hp.f_anova(arval_temp_sex, ['Valence', 'Arousal'], 'Sex')\n",
    "\n",
    "#Emotion and Age\n",
    "emo_temp_age = df_emotion_char.drop(['Char_ID','ID', 'Filename', 'Sex', 'Academic Status'], axis = 1)\n",
    "anova_emo_age = hp.f_anova(emo_temp_age, emotion_label, 'Age')\n",
    "#Affect and Age\n",
    "aff_temp_age = df_affect_char.drop(['Char_ID','ID', 'Filename', 'Sex', 'Academic Status'], axis = 1)\n",
    "anova_aff_age = hp.f_anova(aff_temp_age, affect_label, 'Age')\n",
    "#Level of Interest and Age\n",
    "loi_temp_age = df_loi_char.drop(['Char_ID','ID', 'Filename', 'Sex', 'Academic Status'], axis = 1)\n",
    "anova_loi_age = hp.f_anova(loi_temp_age, loi_label, 'Age')\n",
    "#Arousal-Valence and Age\n",
    "arval_temp_age = df_ar_val_char.drop(['Char_ID','ID', 'Filename', 'Sex', 'Academic Status'], axis = 1)\n",
    "anova_arval_age = hp.f_anova(arval_temp_age, ['Valence', 'Arousal'], 'Age')\n",
    "\n",
    "#Emotion and Academical Status\n",
    "\n",
    "print(affect_label)\n",
    "anova_aff_sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Now let's try to predict the character features (sex, age, academic status) using the voice features (emotion, affect, arousal-valence, level of interest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of Sex\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.366786\n",
      "         Iterations: 35\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.419493\n",
      "         Iterations: 35\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.462772\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.396618\n",
      "         Iterations 7\n",
      "Prediction of Academic Status\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 4\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1.176821\n",
      "         Iterations: 35\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 1.290644\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.264402\n",
      "         Iterations 7\n",
      "Prediction of Age\n",
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 7\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.549513\n",
      "         Iterations: 35\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.566953\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.558052\n",
      "         Iterations 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2128: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return eXB/eXB.sum(1)[:,None]\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:271: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Let's prepare the datasets containing spaces for logistic regression\n",
    "temp_emotion_char = df_emotion_char.rename(columns = {'Academic Status' : 'Academic'})\n",
    "temp_affect_char = df_affect_char.rename(columns = {'Academic Status' : 'Academic'})\n",
    "temp_loi_char = df_loi_char.rename(columns = {'Academic Status' : 'Academic', 'High Interest': 'High_Interest'})\n",
    "temp_arval_char = df_ar_val_char.rename(columns = {'Academic Status' : 'Academic'})\n",
    "#temp_arval_char = \n",
    "# Start with model and sex\n",
    "print('Prediction of Sex')\n",
    "#temp_emotion_char = temp_emotion_char.drop(['Char_ID','ID','Name','VideoTitle', 'Filename', 'Age', 'Academic'], axis = 1)\n",
    "logreg_emo_sex = hp.multiLogReg(temp_emotion_char, 'Emotion', 'Sex',True) #boolean set prohibitWarnings to True\n",
    "logreg_aff_sex = hp.multiLogReg(temp_affect_char, 'Affect', 'Sex', True)\n",
    "logreg_loi_sex = hp.multiLogReg(temp_loi_char, 'LOI', 'Sex', True) \n",
    "logreg_ar_val = hp.multiLogReg(temp_arval_char, 'Arousal-Valence', 'Sex', True) # Yields LinAlgError: Singular Matrix\n",
    "#print(logreg_ar_val.summary())\n",
    "\n",
    "# Then Academic Status\n",
    "print('Prediction of Academic Status')\n",
    "logreg_emo_aca = hp.multiNomiLogReg(temp_emotion_char, 'Emotion', 'Academic', True) \n",
    "logreg_aff_aca = hp.multiNomiLogReg(temp_affect_char, 'Affect', 'Academic', True) \n",
    "logreg_loi_aca = hp.multiNomiLogReg(temp_loi_char, 'LOI', 'Academic', True)\n",
    "logreg_ar_val_aca = hp.multiNomiLogReg(temp_arval_char, 'Arousal-Valence', 'Academic', True)\n",
    "\n",
    "print('Prediction of Age')\n",
    "logreg_emo_age = hp.multiNomiLogReg(temp_emotion_char, 'Emotion', 'Age', True)\n",
    "logreg_aff_age = hp.multiNomiLogReg(temp_affect_char, 'Affect', 'Age', True)\n",
    "logreg_loi_age = hp.multiNomiLogReg(temp_loi_char, 'LOI', 'Age', True)\n",
    "logreg_ar_cal_age = hp.multiNomiLogReg(temp_arval_char, 'Arousal-Valence', 'Age', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Emotion dataset and drop all character columns but gender\n",
    "df_test = df_emotion_char.drop(['CharacterID', 'file', 'Age', 'Academic Status'], axis = 1)\n",
    "\n",
    "test_sadness_m = df_test.loc[df_test['Sex'] == 0.0]['sadness']\n",
    "test_sadness_f = df_test.loc[df_test['Sex'] == 1.0]['sadness']\n",
    "test_m, counts_m = np.unique(np.around(test_sadness_m, 1), return_counts = True)\n",
    "test_f, counts_f = np.unique(np.around(test_sadness_f, 1), return_counts = True)\n",
    "data = ['Sex', '0.0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1.0']\n",
    "cont_table = pd.DataFrame(columns = data)\n",
    "test_m = np.around(np.arange(0, 1.1, 0.1),1)\n",
    "\n",
    "for i in range(0,11):\n",
    "    print()\n",
    "    #print(test_m[i])\n",
    "\n",
    "\n",
    "\n",
    "#row_m = ['male']\n",
    "#cont_table = cont_table['Sex'].append(row_m, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
