{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHI Square Test\n",
    "To further look into differences in our data, we conduct multiple chi² tests to see if there are any significant differences between females/males and grad students/PhDs regarding different emotion, affect, level of interest and arousal valence attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import sklearn.preprocessing as pp\n",
    "import statsmodels.api as sm\n",
    "#import nltk\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import Helper as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load .csv data with results of OpenSMILE Analysis\n",
    "First we load .csv data and clean it (removing of NaNs), then we store information of all files in seperate panda dataframes containing information about affect, emotion and valence/arousal for all participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"CHI_2019_FULL.csv\")\n",
    "\n",
    "#Set Labels \n",
    "emotion_label = ['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness']\n",
    "affect_label = ['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired']\n",
    "loi_label = ['Disinterest', 'Normal', 'High Interest']\n",
    "\n",
    "#Get specific data and save it into new data frames\n",
    "# We use the pandas .copy(deep=True) function to prevent the SettingWithCopyWarning we would otherwise get. Since we do\n",
    "# not write, but only read from the data, the warning does not affect the data frames\n",
    "df_emotion = data[['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness', 'Filename']].copy(deep=True)\n",
    "df_affect = data[['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired', 'Filename']].copy(deep=True)\n",
    "df_loi = data[['Disinterest', 'Normal', 'High Interest', 'Filename']].copy(deep=True)\n",
    "df_ar_val = data[['Arousal', 'Valence', 'Filename']].copy(deep=True)\n",
    "#For further usage, we want to append the CharacterID as a column, which is saved with other information in the filename\n",
    "#Since we only want the digits, we can remove all non-digit characters of the filename column and append the column to the df\n",
    "\n",
    "df_emotion['Char_ID'] = df_emotion['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_affect['Char_ID'] = df_affect['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_loi['Char_ID'] = df_loi['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load information about the speakers\n",
    "The speaker ID is saved in a single .csv file containing four important columns: ID, Age, Sex and Acadedmic Status. Since before loaded OpenSMILE csv files are named using the corresponding index (ex. speaker with id 0 has two files 0_a.csv and 0_b.csv), so that a link can be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_data = pd.read_csv(\"CHI_2019_CharacterData.csv\")  \n",
    "\n",
    "#Join above tables and Character Tables\n",
    "\n",
    "#To Join DataFrames we have to cast the column on which we want to join to int, so that both columns have the same data type\n",
    "char_data['ID'] = char_data['ID'].astype(int)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Char_ID'].astype(int)\n",
    "df_emotion['Char_ID'] = df_emotion['Char_ID'].astype(int)\n",
    "df_affect['Char_ID'] = df_affect['Char_ID'].astype(int)\n",
    "df_loi['Char_ID'] = df_loi['Char_ID'].astype(int)\n",
    "\n",
    "#Safe new data frames\n",
    "df_ar_val_char = df_ar_val.merge(char_data, how = 'left', left_on='Char_ID', right_on='ID')\n",
    "df_emotion_char = df_emotion.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_affect_char = df_affect.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_loi_char = df_loi.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "\n",
    "#Now, we only want to have data containing information about the answers\n",
    "#For that we need to extract from the filename column, whether the file was part of an answer\n",
    "#a = answer, p = presentation, q = question\n",
    "#sentence_type should be the same for all tables, but just to be sure\n",
    "arval_sentence_type = df_ar_val_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_ar_val_char['SentenceType'] = arval_sentence_type\n",
    "emo_sentence_type = df_emotion_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_emotion_char['SentenceType'] = emo_sentence_type\n",
    "aff_sentence_type = df_affect_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_affect_char['SentenceType'] = aff_sentence_type\n",
    "loi_sentence_type = df_loi_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_loi_char['SentenceType'] = loi_sentence_type\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'p']\n",
    "df_emotion_char = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'p']\n",
    "df_affect_char = df_affect_char.loc[df_affect_char['SentenceType'] == 'p']\n",
    "df_loi_char = df_loi_char.loc[df_loi_char['SentenceType'] == 'p']\n",
    "\n",
    "#For affect, we will have to drop the intoxication column and thus we will re-normalize the other values\n",
    "affect_label.remove('Intoxicated')\n",
    "df_affect_char = df_affect_char.drop(['Intoxicated'], axis = 1)\n",
    "norm_test = pp.normalize(df_affect_char[affect_label], norm = 'l1')\n",
    "df_affect_char[affect_label] = norm_test\n",
    "\n",
    "df_loi_char['Normal Interest'] = df_loi_char['Disinterest'] + df_loi_char['Normal']\n",
    "df_loi_char = df_loi_char.drop(['Disinterest', 'Normal'], axis = 1)\n",
    "loi_label = ['Normal Interest', 'High Interest']\n",
    "\n",
    "#Now let's compensate for multiple samples of the same person\n",
    "IDs = df_emotion_char['Char_ID'].copy()\n",
    "IDs.drop_duplicates()\n",
    "\n",
    "# I know that for loops make the following operations very very slow, but I could not find a way to get this\n",
    "# working with pd.apply and lambda functions... \n",
    "\n",
    "for i in IDs:\n",
    "    #first for emotion\n",
    "    for l in emotion_label:    \n",
    "        emo = df_emotion_char.loc[df_emotion_char.Char_ID == i,l]\n",
    "        emo_neu = hp.constructMedianSeries(emo)\n",
    "        df_emotion_char.loc[df_emotion_char.Char_ID == i,l] = emo_neu\n",
    "    #Then for affect\n",
    "    for l in affect_label:    \n",
    "        aff = df_affect_char.loc[df_affect_char.Char_ID == i,l]\n",
    "        aff_neu = hp.constructMedianSeries(aff)\n",
    "        df_affect_char.loc[df_affect_char.Char_ID == i,l] = aff_neu  \n",
    "    for l in loi_label:    \n",
    "        loi = df_loi_char.loc[df_loi_char.Char_ID == i,l]\n",
    "        loi_neu = hp.constructMedianSeries(loi)\n",
    "        df_loi_char.loc[df_loi_char.Char_ID == i,l] = loi_neu  \n",
    "    for l in ['Arousal', 'Valence']:    \n",
    "        arval = df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l]\n",
    "        arval_neu = hp.constructMedianSeries(arval)\n",
    "        df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l] = arval_neu  \n",
    "        \n",
    "#Now let's drop the duplicate values, since we only need one row now per person\n",
    "df_emotion_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_affect_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_loi_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_ar_val_char.drop_duplicates(subset=['ID'], inplace = True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared Test of Independence\n",
    "We Start with characteristic sex. The null hypothesis states that the two categorical variables sex and e.g. emotion are independent.\n",
    "\n",
    "Since we have float data and chi² needs integer data, such as observation counts, we have to convert our data. To illustrate how this is done, we'll look at a specific emotion, 'Anger'. We need to make sure that in our observation count, we do not have any cells with a value of less than 5, since this yields errors and may falsify the result. So we calculate the quantiles of our emotion 'Anger', which yields us three thresholds to compare the float data. This way, we can count how many samples were in the 1st, 2nd, 3rd or 4th Quantile. We want to compare two (or more) groups, so we compare only the female values and sort them into quartiles, then for male values. This yields a 2x4 table. An example table is printed below. This table is used to calculate the chi2 statistic. Note that the function 'calcFrequencyTable' takes in a pd.DataFrame, not a pd.Series and returns an array of pd.DataFrames. This means, that the function calculates these tables for all different emotions defined in e.g. emotion_label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Quartile</th>\n",
       "      <th>2nd Quartile</th>\n",
       "      <th>3rd Quartile</th>\n",
       "      <th>4th Quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1st Quartile 2nd Quartile 3rd Quartile 4th Quartile\n",
       "Male             10           11            9           10\n",
       "Female           11            9           11           10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example Frequency Table for the emotion 'Anger':\n",
    "#Since the function does the table calculation for all different emotions, we only want to select the first table\n",
    "#which holds the table for 'anger' (since it's the first element, see declaration of emotion_label at the start)\n",
    "anger_table = hp.calcFrequencyTable(df_emotion_char, emotion_label, 'Sex')[0]\n",
    "anger_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "\n",
      "Chi square of Anger : 0.43533972125435544 with p-value of: 0.9328491649308727\n",
      "Cramers V: 0.07331142107427951\n",
      "Chi square of Boredom : 1.9784320557491293 with p-value of: 0.5768952587117124\n",
      "Cramers V: 0.15628527476385592\n",
      "Chi square of Disgust : 20.4479137630662 with p-value of: 0.0001370628588903404\n",
      "Cramers V: 0.5024374386836044\n",
      "Chi square of Fear : 7.44593205574913 with p-value of: 0.05896408489675078\n",
      "Cramers V: 0.303191502367751\n",
      "Chi square of Happiness : 5.178919860627178 with p-value of: 0.15915488787442197\n",
      "Cramers V: 0.25285822555330323\n",
      "Chi square of Emo_Neutral : 3.321493902439025 with p-value of: 0.34466228008084693\n",
      "Cramers V: 0.2024996236069974\n",
      "Chi square of Sadness : 15.551929442508714 with p-value of: 0.001400876792680575\n",
      "Cramers V: 0.43817705202333523\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Chi square of Aggressiv : 8.046023519163763 with p-value of: 0.0450700529351656\n",
      "Cramers V: 0.3151723713991754\n",
      "Chi square of Cheerful : 1.416441637630662 with p-value of: 0.7016852861743752\n",
      "Cramers V: 0.1322381707295946\n",
      "Chi square of Nervous : 1.578371080139373 with p-value of: 0.6643039148381575\n",
      "Cramers V: 0.1395924880420506\n",
      "Chi square of Aff_Neutral : 3.435797038327527 with p-value of: 0.3291849901781681\n",
      "Cramers V: 0.20595447891890964\n",
      "Chi square of Tired : 5.036040940766552 with p-value of: 0.16917699282025617\n",
      "Cramers V: 0.2493458340292358\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Chi square of Arousal : 21.95290505226481 with p-value of: 6.671961314827394e-05\n",
      "Cramers V: 0.5205991924347972\n",
      "Chi square of Valence : 18.83814459930314 with p-value of: 0.0002952950736500699\n",
      "Cramers V: 0.4822547940779333\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Chi square of Normal Interest : 3.3214939024390246 with p-value of: 0.344662280080847\n",
      "Cramers V: 0.2024996236069974\n",
      "Chi square of High Interest : 4.416898954703832 with p-value of: 0.21982356769224315\n",
      "Cramers V: 0.23351577403836912\n",
      "\n",
      "Residuals of: Tired\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Quartile</th>\n",
       "      <th>2nd Quartile</th>\n",
       "      <th>3rd Quartile</th>\n",
       "      <th>4th Quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>0.319305</td>\n",
       "      <td>-1.997884</td>\n",
       "      <td>0.063627</td>\n",
       "      <td>1.60976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>-0.319305</td>\n",
       "      <td>1.997884</td>\n",
       "      <td>-0.063627</td>\n",
       "      <td>-1.60976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1st Quartile  2nd Quartile  3rd Quartile  4th Quartile\n",
       "Male        0.319305     -1.997884      0.063627       1.60976\n",
       "Female     -0.319305      1.997884     -0.063627      -1.60976"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('EMOTION\\n')\n",
    "emo_sex_chi2 = hp.chi2(df_emotion_char, emotion_label,'Sex',  True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_sec_chi2 = hp.chi2(df_affect_char, affect_label,'Sex',  True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_sec_chi2 = hp.chi2(df_ar_val_char, ['Arousal', 'Valence'], 'Sex', True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_sec_chi2 = hp.chi2(df_loi_char, ['Normal Interest', 'High Interest'], 'Sex', True)\n",
    "print('\\nResiduals of: '+ affect_label[4])\n",
    "aff_sec_chi2[1][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the above p-values, we see significant differences in emotion for disgust, fear and sadness. Regarding the residuals, we see that females are more disgusted than males (4th quartile ~6.25), 1st and 2nd quartile for males: ~4.70 and ~2.03. Further looking at fear, we see that females tend to have more 'extreme' values, meaning that the 1st quartile and 4th quartile are positive (~2.11 and ~0.92). Looking at sadness, we see that (just as in the previous analysis) males tend to be more sad than females (3rd quartile ~1.3, 4th quartile ~4.70).\n",
    "\n",
    "Looking at the p-values of affect, we can see significant difference for aggressive, cheerful, intoxicated and tired. Further analyzing the residuals, we can see that females tend to be more aggressive (4th quartile ~4.18) than males (1st quartile ~3.51, 2nd quartile ~1.44). Looking at cheerful we see that males tend to have higher values (4th quartile ~3.51) than females (1st to 3rd quartile positive). Regarding intoxication, we see that females tend to have values above the median (3rd and 4th quartile positive (~1.68 and ~2.70), while males tend to have values below the median (1st quartile ~2.92, 2nd quartile ~1.44). Lastly looking at tiredness, we see that males tend to be more tired than females, as males have positive values for the 3rd and 4th quartile, and females have positive values for the 1st and 2nd quartile.\n",
    "\n",
    "If we take a look at the p-values for arousal valence, we see arousal and valence show significant differences between males and females. Looking at the residuals, we can see that females have higher values of arousal than males (1st quartile for males ~6.18, 3rd Q for females ~2.27 and 4th Q for females ~3.59). Regarding valence, we see that females tend to have values below the median (positive values for 1st Q ~3.88 and 2nd Q ~1.22), whereas males tend to have values above the median (3rd Q ~3.68; 4th Q ~1.44).\n",
    "\n",
    "Lastly if we take a look at the p-values for level of interest, we can see significant differences for disinterest, normal and high interest. Further investigating the residuals tells us, that females tend to have lower values for disinterest than males (1st quartile ~3.88 for females). Furthermore females tend to have lower values for normal interest than males (1st quartile ~3.29 for females). This implies, that females will have higher values for high interest. By looking at the residuals we are able to confirm this: the only positive value for females is at the 4th quartile (~3.29).\n",
    "\n",
    "Now move on to academic status, the hypothesis being that the variables academic status and e.g. emotion are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "\n",
      "Chi square of Anger : 2.9518449030644147 with p-value of: 0.39910949093209325\n",
      "Cramers V: 0.19089926575935778\n",
      "Chi square of Boredom : 6.790334184429176 with p-value of: 0.07888943682072329\n",
      "Cramers V: 0.28953632971964105\n",
      "Chi square of Disgust : 6.554096310193872 with p-value of: 0.0875533198777855\n",
      "Cramers V: 0.2844552148610616\n",
      "Chi square of Fear : 5.353345841150719 with p-value of: 0.1476780745346126\n",
      "Cramers V: 0.25708109498156895\n",
      "Chi square of Happiness : 4.953095684803002 with p-value of: 0.17526410464554013\n",
      "Cramers V: 0.2472839045348734\n",
      "Chi square of Emo_Neutral : 6.790334184429176 with p-value of: 0.07888943682072329\n",
      "Cramers V: 0.28953632971964105\n",
      "Chi square of Sadness : 1.4320980688118046 with p-value of: 0.698028313491549\n",
      "Cramers V: 0.1329669999351368\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Chi square of Aggressiv : 4.152595372107567 with p-value of: 0.24545104939706014\n",
      "Cramers V: 0.22642130980142347\n",
      "Chi square of Cheerful : 3.75234521575985 with p-value of: 0.28947805322214165\n",
      "Cramers V: 0.21523301228501657\n",
      "Chi square of Nervous : 1.350844277673546 with p-value of: 0.7170964469463956\n",
      "Cramers V: 0.12913980737100994\n",
      "Chi square of Aff_Neutral : 7.354596622889305 with p-value of: 0.06141457436419687\n",
      "Cramers V: 0.3013262171990232\n",
      "Chi square of Tired : 2.6157952730481617 with p-value of: 0.4547271581405872\n",
      "Cramers V: 0.17970467106634633\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Chi square of Arousal : 2.951844903064415 with p-value of: 0.399109490932093\n",
      "Cramers V: 0.19089926575935778\n",
      "Chi square of Valence : 5.084004570525753 with p-value of: 0.16574825522506942\n",
      "Cramers V: 0.2505304143712082\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Chi square of Normal Interest : 4.5528455284552845 with p-value of: 0.2076247455220674\n",
      "Cramers V: 0.23708219985292503\n",
      "Chi square of High Interest : 3.4584271811486174 with p-value of: 0.32619413793286195\n",
      "Cramers V: 0.20663163326565542\n",
      "\n",
      "Residuals of: Nervous\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Quartile</th>\n",
       "      <th>2nd Quartile</th>\n",
       "      <th>3rd Quartile</th>\n",
       "      <th>4th Quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Grad Student</th>\n",
       "      <td>2.154194</td>\n",
       "      <td>-0.913259</td>\n",
       "      <td>-0.12914</td>\n",
       "      <td>-1.162258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhD</th>\n",
       "      <td>-2.154194</td>\n",
       "      <td>0.913259</td>\n",
       "      <td>0.12914</td>\n",
       "      <td>1.162258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1st Quartile  2nd Quartile  3rd Quartile  4th Quartile\n",
       "Grad Student      2.154194     -0.913259      -0.12914     -1.162258\n",
       "PhD              -2.154194      0.913259       0.12914      1.162258"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('EMOTION\\n')\n",
    "emo_aca_chi2 = hp.chi2(df_emotion_char, emotion_label,'Academic' , True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_aca_chi2 = hp.chi2(df_affect_char, affect_label,'Academic', True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_aca_chi2 = hp.chi2(df_ar_val_char, ['Arousal', 'Valence'],  'Academic',True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_aca_chi2 = hp.chi2(df_loi_char, ['Normal Interest', 'High Interest'],'Academic', True)\n",
    "print('\\nResiduals of: '+ affect_label[2])\n",
    "ar_val_aca_chi2[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the p-values for emotion, we see significant differences between Grad Students and PhDs for boredom and neutral (emotion). By further looking at the residuals, we are able to see that PhDs tend to have lower values (1st quartile ~3.21) for boredom than grad students (2nd quartile ~2.76). Looking at neutral (emotion), we see that PhDs tend to be more 'extreme', meaning a value of ~3.21 for the 1st quartile and a value of ~1.42 for the 4th quartile.\n",
    "\n",
    "If we take a look at the p-values for affect, we only see statistical significant differences in intoxication. Looking at the residuals we see that grad students tend to have lower values for intoxication (1st Q ~2.03) but also have a value of ~0.52 for the 4th quartile. But we can say that the main differences in intoxication between gard students and phds lies between the 1st and 3rd quartile, where phds tend to be more intoxicated (3rd Q ~2.47).\n",
    "\n",
    "Regarding the p-values of arousal-valence, we can only see a statistical significant difference between PhDs and grad students in valence. Looking at the residuals we can say that grad students (1st Q ~2.46, 3rd ~0.53) tend to have smaller valence values than PhDs (2nd Q ~1.26, 4th Q ~1.71)\n",
    "\n",
    "Now let's look at Native Speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "\n",
      "Chi square of Anger : 2.600965250965251 with p-value of: 0.8570013311381182\n",
      "Cramers V: 0.17919453705591057\n",
      "Chi square of Boredom : 8.587118287118287 with p-value of: 0.19816403314894113\n",
      "Cramers V: 0.3255976136488196\n",
      "Chi square of Disgust : 8.490926640926642 with p-value of: 0.20429622527018043\n",
      "Cramers V: 0.3237688292999418\n",
      "Chi square of Fear : 6.569936819936822 with p-value of: 0.3624541777587051\n",
      "Cramers V: 0.284798755457834\n",
      "Chi square of Happiness : 8.061618111618113 with p-value of: 0.23362368561135471\n",
      "Cramers V: 0.31547765297426306\n",
      "Chi square of Emo_Neutral : 6.667786942786944 with p-value of: 0.3526651557515303\n",
      "Cramers V: 0.2869117587662753\n",
      "Chi square of Sadness : 7.884161109161108 with p-value of: 0.24671342862313786\n",
      "Cramers V: 0.311986093176158\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Chi square of Aggressiv : 15.02864162864163 with p-value of: 0.02003511358751028\n",
      "Cramers V: 0.4307421334612921\n",
      "Chi square of Cheerful : 2.5057213057213055 with p-value of: 0.8678268114920646\n",
      "Cramers V: 0.17588300354164677\n",
      "Chi square of Nervous : 2.799745524745525 with p-value of: 0.8335284861685102\n",
      "Cramers V: 0.18591600136825115\n",
      "Chi square of Aff_Neutral : 4.513425763425762 with p-value of: 0.6075489983359894\n",
      "Cramers V: 0.23605360772779074\n",
      "Chi square of Tired : 3.9042909792909795 with p-value of: 0.6896267221550094\n",
      "Cramers V: 0.2195475420065622\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Chi square of Arousal : 5.632897507897509 with p-value of: 0.465541948416751\n",
      "Cramers V: 0.2637080668882629\n",
      "Chi square of Valence : 2.356458406458406 with p-value of: 0.8841736967468727\n",
      "Cramers V: 0.17056400291995696\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Chi square of Normal Interest : 3.757397332397333 with p-value of: 0.7094676389181351\n",
      "Cramers V: 0.21537785723611746\n",
      "Chi square of High Interest : 7.5782906282906275 with p-value of: 0.27065440390169365\n",
      "Cramers V: 0.3058743918002021\n"
     ]
    }
   ],
   "source": [
    "print('EMOTION\\n')\n",
    "emo_age_chi2 = hp.chi2(df_emotion_char, emotion_label,'IsNativeSpeaker', True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_age_chi2 = hp.chi2(df_affect_char, affect_label, 'IsNativeSpeaker', True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_age_chi2 = hp.chi2(df_ar_val_char, ['Arousal', 'Valence'],'IsNativeSpeaker' ,True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_age_chi2 = hp.chi2(df_loi_char, ['Normal Interest', 'High Interest'], 'IsNativeSpeaker',  True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Hoc tests for age and native speaker, as they have three different groups\n",
    "\n",
    "If a significant p-value for the category 'NativeSpeaker' is found, we do not yet know which groups differ significantly from each other, so post-hoc testing is done for this character feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "\n",
      "post-hoc emotions and different groups\n",
      "Anger\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Boredom\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Disgust\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [0.94972434 1.         1.        ]\n",
      "Fear\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Happiness\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Emo_Neutral\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Sadness\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [0.81463864 1.         1.        ]\n",
      "\n",
      "AFFECT\n",
      "\n",
      "\n",
      " post-hoc affect and different groups\n",
      "Aggressiv\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [0.56340714 0.64241875 1.        ]\n",
      "Cheerful\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Nervous\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Aff_Neutral\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Tired\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "\n",
      " post-hoc arousal-valence and different groups\n",
      "Arousal\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Valence\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "\n",
      " post-hoc level of intereset and different groups\n",
      "Normal Interest\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "High Interest\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1.       0.717396 1.      ]\n"
     ]
    }
   ],
   "source": [
    "print('EMOTION\\n')\n",
    "print('post-hoc emotions and different groups')\n",
    "emo_reject_list, emo_corrected_p_vals, emo_combinations, emo_residuals= hp.chi2_post_hoc(df_emotion_char,emotion_label, 'IsNativeSpeaker', 'bonferroni', True, True)\n",
    "print('\\nAFFECT\\n')\n",
    "print('\\n post-hoc affect and different groups')\n",
    "aff_reject_list, emo_corrected_p_vals, emo_combinations, aff_residuals = hp.chi2_post_hoc(df_affect_char, affect_label, 'IsNativeSpeaker' ,'bonferroni', True, True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "print('\\n post-hoc arousal-valence and different groups')\n",
    "ar_val_reject_list, ar_val_corrected_p_vals, ar_val_combinations, ar_val_residuals = hp.chi2_post_hoc(df_ar_val_char, ['Arousal', 'Valence'], 'IsNativeSpeaker', 'bonferroni',True, True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "print('\\n post-hoc level of intereset and different groups')\n",
    "loi_reject_list, loi_corrected_p_vals, loi_combinations, loi_residuals = hp.chi2_post_hoc(df_loi_char, ['Normal Interest', 'High Interest'], 'IsNativeSpeaker', 'bonferroni', True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
