{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHI Square Test\n",
    "To further look into differences in our data, we conduct multiple chi² tests to see if there are any significant differences between females/males and grad students/PhDs regarding different emotion, affect, level of interest and arousal valence attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import sklearn.preprocessing as pp\n",
    "import statsmodels.api as sm\n",
    "#import nltk\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import Helper as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load .csv data with results of OpenSMILE Analysis\n",
    "First we load .csv data and clean it (removing of NaNs), then we store information of all files in seperate panda dataframes containing information about affect, emotion and valence/arousal for all participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"CHI_2019_FULL.csv\")\n",
    "\n",
    "#Set Labels \n",
    "emotion_label = ['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness']\n",
    "affect_label = ['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired']\n",
    "loi_label = ['Disinterest', 'Normal', 'High Interest']\n",
    "\n",
    "#Get specific data and save it into new data frames\n",
    "# We use the pandas .copy(deep=True) function to prevent the SettingWithCopyWarning we would otherwise get. Since we do\n",
    "# not write, but only read from the data, the warning does not affect the data frames\n",
    "df_emotion = data[['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness', 'Filename']].copy(deep=True)\n",
    "df_affect = data[['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired', 'Filename']].copy(deep=True)\n",
    "df_loi = data[['Disinterest', 'Normal', 'High Interest', 'Filename']].copy(deep=True)\n",
    "df_ar_val = data[['Arousal', 'Valence', 'Filename']].copy(deep=True)\n",
    "#For further usage, we want to append the CharacterID as a column, which is saved with other information in the filename\n",
    "#Since we only want the digits, we can remove all non-digit characters of the filename column and append the column to the df\n",
    "\n",
    "df_emotion['Char_ID'] = df_emotion['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_affect['Char_ID'] = df_affect['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_loi['Char_ID'] = df_loi['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load information about the speakers\n",
    "The speaker ID is saved in a single .csv file containing four important columns: ID, Age, Sex and Acadedmic Status. Since before loaded OpenSMILE csv files are named using the corresponding index (ex. speaker with id 0 has two files 0_a.csv and 0_b.csv), so that a link can be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_data = pd.read_csv(\"CHI_2019_CharacterData.csv\")  \n",
    "\n",
    "#Join above tables and Character Tables\n",
    "\n",
    "#To Join DataFrames we have to cast the column on which we want to join to int, so that both columns have the same data type\n",
    "char_data['ID'] = char_data['ID'].astype(int)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Char_ID'].astype(int)\n",
    "df_emotion['Char_ID'] = df_emotion['Char_ID'].astype(int)\n",
    "df_affect['Char_ID'] = df_affect['Char_ID'].astype(int)\n",
    "df_loi['Char_ID'] = df_loi['Char_ID'].astype(int)\n",
    "\n",
    "#Safe new data frames\n",
    "df_ar_val_char = df_ar_val.merge(char_data, how = 'left', left_on='Char_ID', right_on='ID')\n",
    "df_emotion_char = df_emotion.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_affect_char = df_affect.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_loi_char = df_loi.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "\n",
    "#Now, we only want to have data containing information about the answers\n",
    "#For that we need to extract from the filename column, whether the file was part of an answer\n",
    "#a = answer, p = presentation, q = question\n",
    "#sentence_type should be the same for all tables, but just to be sure\n",
    "arval_sentence_type = df_ar_val_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_ar_val_char['SentenceType'] = arval_sentence_type\n",
    "emo_sentence_type = df_emotion_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_emotion_char['SentenceType'] = emo_sentence_type\n",
    "aff_sentence_type = df_affect_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_affect_char['SentenceType'] = aff_sentence_type\n",
    "loi_sentence_type = df_loi_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_loi_char['SentenceType'] = loi_sentence_type\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'p']\n",
    "df_emotion_char = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'p']\n",
    "df_affect_char = df_affect_char.loc[df_affect_char['SentenceType'] == 'p']\n",
    "df_loi_char = df_loi_char.loc[df_loi_char['SentenceType'] == 'p']\n",
    "\n",
    "#For affect, we will have to drop the intoxication column and thus we will re-normalize the other values\n",
    "affect_label.remove('Intoxicated')\n",
    "df_affect_char = df_affect_char.drop(['Intoxicated'], axis = 1)\n",
    "norm_test = pp.normalize(df_affect_char[affect_label], norm = 'l1')\n",
    "df_affect_char[affect_label] = norm_test\n",
    "\n",
    "df_loi_char['Normal Interest'] = df_loi_char['Disinterest'] + df_loi_char['Normal']\n",
    "df_loi_char = df_loi_char.drop(['Disinterest', 'Normal'], axis = 1)\n",
    "loi_label = ['Normal Interest', 'High Interest']\n",
    "\n",
    "#Now let's compensate for multiple samples of the same person\n",
    "IDs = df_emotion_char['Char_ID'].copy()\n",
    "IDs.drop_duplicates()\n",
    "\n",
    "# I know that for loops make the following operations very very slow, but I could not find a way to get this\n",
    "# working with pd.apply and lambda functions... \n",
    "\n",
    "for i in IDs:\n",
    "    #first for emotion\n",
    "    for l in emotion_label:    \n",
    "        emo = df_emotion_char.loc[df_emotion_char.Char_ID == i,l]\n",
    "        emo_neu = hp.constructMedianSeries(emo)\n",
    "        df_emotion_char.loc[df_emotion_char.Char_ID == i,l] = emo_neu\n",
    "    #Then for affect\n",
    "    for l in affect_label:    \n",
    "        aff = df_affect_char.loc[df_affect_char.Char_ID == i,l]\n",
    "        aff_neu = hp.constructMedianSeries(aff)\n",
    "        df_affect_char.loc[df_affect_char.Char_ID == i,l] = aff_neu  \n",
    "    for l in loi_label:    \n",
    "        loi = df_loi_char.loc[df_loi_char.Char_ID == i,l]\n",
    "        loi_neu = hp.constructMedianSeries(loi)\n",
    "        df_loi_char.loc[df_loi_char.Char_ID == i,l] = loi_neu  \n",
    "    for l in ['Arousal', 'Valence']:    \n",
    "        arval = df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l]\n",
    "        arval_neu = hp.constructMedianSeries(arval)\n",
    "        df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l] = arval_neu  \n",
    "        \n",
    "#Now let's drop the duplicate values, since we only need one row now per person\n",
    "df_emotion_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_affect_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_loi_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_ar_val_char.drop_duplicates(subset=['ID'], inplace = True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared Test of Independence\n",
    "We Start with characteristic sex. The null hypothesis states that the two categorical variables sex and e.g. emotion are independent.\n",
    "\n",
    "Since we have float data and chi² needs integer data, such as observation counts, we have to convert our data. To illustrate how this is done, we'll look at a specific emotion, 'Anger'. We need to make sure that in our observation count, we do not have any cells with a value of less than 5, since this yields errors and may falsify the result. So we calculate the quantiles of our emotion 'Anger', which yields us three thresholds to compare the float data. This way, we can count how many samples were in the 1st, 2nd, 3rd or 4th Quantile. We want to compare two (or more) groups, so we compare only the female values and sort them into quartiles, then for male values. This yields a 2x4 table. An example table is printed below. This table is used to calculate the chi2 statistic. Note that the function 'calcFrequencyTable' takes in a pd.DataFrame, not a pd.Series and returns an array of pd.DataFrames. This means, that the function calculates these tables for all different emotions defined in e.g. emotion_label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Quartile</th>\n",
       "      <th>2nd Quartile</th>\n",
       "      <th>3rd Quartile</th>\n",
       "      <th>4th Quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1st Quartile  2nd Quartile  3rd Quartile  4th Quartile\n",
       "Male              34            31            28            27\n",
       "Female            27            30            32            34"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example Frequency Table for the emotion 'Anger':\n",
    "#Since the function does the table calculation for all different emotions, we only want to select the first table\n",
    "#which holds the table for 'anger' (since it's the first element, see declaration of emotion_label at the start)\n",
    "anger_table = hp.calcFrequencyTable(df_emotion_char, emotion_label, 'Sex')[0]\n",
    "anger_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "\n",
      "Chi square of Anger : 1.852862854858057 with p-value of: 0.6034994971411449\n",
      "Chi square of Boredom : 5.071932726909235 with p-value of: 0.16660502111256176\n",
      "Chi square of Disgust : 49.07317473010795 with p-value of: 1.2584955346502562e-10\n",
      "Chi square of Fear : 8.41123950419832 with p-value of: 0.038234923728513295\n",
      "Chi square of Happiness : 2.504328268692523 with p-value of: 0.4745093760896385\n",
      "Chi square of Emo_Neutral : 5.919056377449019 with p-value of: 0.11561540839176661\n",
      "Chi square of Sadness : 35.96953818472611 with p-value of: 7.600252668627796e-08\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Chi square of Aggressiv : 26.394308276689326 with p-value of: 7.885894974468189e-06\n",
      "Chi square of Cheerful : 9.985249900039983 with p-value of: 0.018691933731315072\n",
      "Chi square of Nervous : 3.4979223310675724 with p-value of: 0.3210316874895997\n",
      "Chi square of Aff_Neutral : 4.538518092762895 with p-value of: 0.20888018638911474\n",
      "Chi square of Tired : 9.587375049980007 with p-value of: 0.022419775548845385\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Chi square of Arousal : 42.186879248300684 with p-value of: 3.66197639188191e-09\n",
      "Chi square of Valence : 24.173204718112753 with p-value of: 2.298406054917918e-05\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Chi square of Normal Interest : 11.254295781687325 with p-value of: 0.010427353744000094\n",
      "Chi square of High Interest : 11.034590163934427 with p-value of: 0.011540296363718828\n",
      "\n",
      "Residuals of: Tired\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Quartile</th>\n",
       "      <th>2nd Quartile</th>\n",
       "      <th>3rd Quartile</th>\n",
       "      <th>4th Quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>-0.332447</td>\n",
       "      <td>-2.403845</td>\n",
       "      <td>0.110205</td>\n",
       "      <td>2.626694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>0.332447</td>\n",
       "      <td>2.403845</td>\n",
       "      <td>-0.110205</td>\n",
       "      <td>-2.626694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1st Quartile  2nd Quartile  3rd Quartile  4th Quartile\n",
       "Male       -0.332447     -2.403845      0.110205      2.626694\n",
       "Female      0.332447      2.403845     -0.110205     -2.626694"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('EMOTION\\n')\n",
    "emo_sex_chi2 = hp.chi2(df_emotion_char, emotion_label,'Sex',  True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_sec_chi2 = hp.chi2(df_affect_char, affect_label,'Sex',  True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_sec_chi2 = hp.chi2(df_ar_val_char, ['Arousal', 'Valence'], 'Sex', True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_sec_chi2 = hp.chi2(df_loi_char, ['Normal Interest', 'High Interest'], 'Sex', True)\n",
    "print('\\nResiduals of: '+ affect_label[4])\n",
    "aff_sec_chi2[1][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the above p-values, we see significant differences in emotion for disgust, fear and sadness. Regarding the residuals, we see that females are more disgusted than males (4th quartile ~6.25), 1st and 2nd quartile for males: ~4.70 and ~2.03. Further looking at fear, we see that females tend to have more 'extreme' values, meaning that the 1st quartile and 4th quartile are positive (~2.11 and ~0.92). Looking at sadness, we see that (just as in the previous analysis) males tend to be more sad than females (3rd quartile ~1.3, 4th quartile ~4.70).\n",
    "\n",
    "Looking at the p-values of affect, we can see significant difference for aggressive, cheerful, intoxicated and tired. Further analyzing the residuals, we can see that females tend to be more aggressive (4th quartile ~4.18) than males (1st quartile ~3.51, 2nd quartile ~1.44). Looking at cheerful we see that males tend to have higher values (4th quartile ~3.51) than females (1st to 3rd quartile positive). Regarding intoxication, we see that females tend to have values above the median (3rd and 4th quartile positive (~1.68 and ~2.70), while males tend to have values below the median (1st quartile ~2.92, 2nd quartile ~1.44). Lastly looking at tiredness, we see that males tend to be more tired than females, as males have positive values for the 3rd and 4th quartile, and females have positive values for the 1st and 2nd quartile.\n",
    "\n",
    "If we take a look at the p-values for arousal valence, we see arousal and valence show significant differences between males and females. Looking at the residuals, we can see that females have higher values of arousal than males (1st quartile for males ~6.18, 3rd Q for females ~2.27 and 4th Q for females ~3.59). Regarding valence, we see that females tend to have values below the median (positive values for 1st Q ~3.88 and 2nd Q ~1.22), whereas males tend to have values above the median (3rd Q ~3.68; 4th Q ~1.44).\n",
    "\n",
    "Lastly if we take a look at the p-values for level of interest, we can see significant differences for disinterest, normal and high interest. Further investigating the residuals tells us, that females tend to have lower values for disinterest than males (1st quartile ~3.88 for females). Furthermore females tend to have lower values for normal interest than males (1st quartile ~3.29 for females). This implies, that females will have higher values for high interest. By looking at the residuals we are able to confirm this: the only positive value for females is at the 4th quartile (~3.29).\n",
    "\n",
    "Now move on to academic status, the hypothesis being that the variables academic status and e.g. emotion are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "\n",
      "Chi square of Anger : 3.4865219492385586 with p-value of: 0.3225143905851229\n",
      "Chi square of Boredom : 14.325620179278717 with p-value of: 0.0024938227522766205\n",
      "Chi square of Disgust : 4.059207439924119 with p-value of: 0.25514136264208975\n",
      "Chi square of Fear : 5.0209254267292085 with p-value of: 0.17027127876206108\n",
      "Chi square of Happiness : 5.921386334644762 with p-value of: 0.11549822467643807\n",
      "Chi square of Emo_Neutral : 17.527621430060456 with p-value of: 0.0005503842074200204\n",
      "Chi square of Sadness : 1.5291070302286158 with p-value of: 0.6755689192799226\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Chi square of Aggressiv : 6.027650831798139 with p-value of: 0.1102726742789971\n",
      "Chi square of Cheerful : 4.416317764082106 with p-value of: 0.2198771126758322\n",
      "Chi square of Nervous : 2.199556369612484 with p-value of: 0.5320357578490797\n",
      "Chi square of Aff_Neutral : 6.818836862543517 with p-value of: 0.0779017889860497\n",
      "Chi square of Tired : 4.582277905224589 with p-value of: 0.20506765441019834\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Chi square of Arousal : 2.147053680338671 with p-value of: 0.5424522890973964\n",
      "Chi square of Valence : 8.148767148218216 with p-value of: 0.04303514008476428\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Chi square of Normal Interest : 1.7004468674648052 with p-value of: 0.6368344513484914\n",
      "Chi square of High Interest : 1.6671019553934179 with p-value of: 0.6442723782880364\n",
      "\n",
      "Residuals of: Nervous\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Quartile</th>\n",
       "      <th>2nd Quartile</th>\n",
       "      <th>3rd Quartile</th>\n",
       "      <th>4th Quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Grad Student</th>\n",
       "      <td>2.460444</td>\n",
       "      <td>-1.264283</td>\n",
       "      <td>0.52861</td>\n",
       "      <td>-1.714855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhD</th>\n",
       "      <td>-2.460444</td>\n",
       "      <td>1.264283</td>\n",
       "      <td>-0.52861</td>\n",
       "      <td>1.714855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1st Quartile  2nd Quartile  3rd Quartile  4th Quartile\n",
       "Grad Student      2.460444     -1.264283       0.52861     -1.714855\n",
       "PhD              -2.460444      1.264283      -0.52861      1.714855"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('EMOTION\\n')\n",
    "emo_aca_chi2 = hp.chi2(df_emotion_char, emotion_label,'Academic' , True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_aca_chi2 = hp.chi2(df_affect_char, affect_label,'Academic', True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_aca_chi2 = hp.chi2(df_ar_val_char, ['Arousal', 'Valence'],  'Academic',True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_aca_chi2 = hp.chi2(df_loi_char, ['Normal Interest', 'High Interest'],'Academic', True)\n",
    "print('\\nResiduals of: '+ affect_label[2])\n",
    "ar_val_aca_chi2[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the p-values for emotion, we see significant differences between Grad Students and PhDs for boredom and neutral (emotion). By further looking at the residuals, we are able to see that PhDs tend to have lower values (1st quartile ~3.21) for boredom than grad students (2nd quartile ~2.76). Looking at neutral (emotion), we see that PhDs tend to be more 'extreme', meaning a value of ~3.21 for the 1st quartile and a value of ~1.42 for the 4th quartile.\n",
    "\n",
    "If we take a look at the p-values for affect, we only see statistical significant differences in intoxication. Looking at the residuals we see that grad students tend to have lower values for intoxication (1st Q ~2.03) but also have a value of ~0.52 for the 4th quartile. But we can say that the main differences in intoxication between gard students and phds lies between the 1st and 3rd quartile, where phds tend to be more intoxicated (3rd Q ~2.47).\n",
    "\n",
    "Regarding the p-values of arousal-valence, we can only see a statistical significant difference between PhDs and grad students in valence. Looking at the residuals we can say that grad students (1st Q ~2.46, 3rd ~0.53) tend to have smaller valence values than PhDs (2nd Q ~1.26, 4th Q ~1.71)\n",
    "\n",
    "Now let's look at Native Speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "\n",
      "Chi square of Anger : 6.4785850653572545 with p-value of: 0.37176381692808363\n",
      "Chi square of Boredom : 11.755506837474051 with p-value of: 0.067650756540378\n",
      "Chi square of Disgust : 11.626748842642147 with p-value of: 0.07083274759732817\n",
      "Chi square of Fear : 4.80715759404284 with p-value of: 0.5687740020632577\n",
      "Chi square of Happiness : 7.111307941155313 with p-value of: 0.31067613394676324\n",
      "Chi square of Emo_Neutral : 5.94815807930562 with p-value of: 0.42902247507469005\n",
      "Chi square of Sadness : 9.535061560624218 with p-value of: 0.14564680721979234\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Chi square of Aggressiv : 18.43985561684923 with p-value of: 0.0052220394778411975\n",
      "Chi square of Cheerful : 5.2922537478783935 with p-value of: 0.5069122775374593\n",
      "Chi square of Nervous : 3.2009993701106736 with p-value of: 0.7832293493762938\n",
      "Chi square of Aff_Neutral : 3.4366456932878644 with p-value of: 0.7523787429324115\n",
      "Chi square of Tired : 7.619268479641573 with p-value of: 0.2673441330670959\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Chi square of Arousal : 8.143462017315866 with p-value of: 0.22778024554288429\n",
      "Chi square of Valence : 6.654020337821397 with p-value of: 0.3540309217744874\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Chi square of Normal Interest : 9.19098248549916 with p-value of: 0.16311881291778246\n",
      "Chi square of High Interest : 9.32725062761184 with p-value of: 0.15599289030522448\n"
     ]
    }
   ],
   "source": [
    "print('EMOTION\\n')\n",
    "emo_age_chi2 = hp.chi2(df_emotion_char, emotion_label,'IsNativeSpeaker', True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_age_chi2 = hp.chi2(df_affect_char, affect_label, 'IsNativeSpeaker', True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_age_chi2 = hp.chi2(df_ar_val_char, ['Arousal', 'Valence'],'IsNativeSpeaker' ,True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_age_chi2 = hp.chi2(df_loi_char, ['Normal Interest', 'High Interest'], 'IsNativeSpeaker',  True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Hoc tests for age and native speaker, as they have three different groups\n",
    "\n",
    "If a significant p-value for the category 'NativeSpeaker' is found, we do not yet know which groups differ significantly from each other, so post-hoc testing is done for this character feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "\n",
      "post-hoc emotions and different groups\n",
      "Anger\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1.         1.         0.81143585]\n",
      "Boredom\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1.         0.43215994 0.56231893]\n",
      "Disgust\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [0.12305687 0.96552376 1.        ]\n",
      "Fear\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1.         1.         0.95569894]\n",
      "Happiness\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1.        1.        0.7781254]\n",
      "Emo_Neutral\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1.         1.         0.92659519]\n",
      "Sadness\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [0.28091346 1.         1.        ]\n",
      "\n",
      "AFFECT\n",
      "\n",
      "\n",
      " post-hoc affect and different groups\n",
      "Aggressiv\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [0.17113836 0.18629867 0.42572397]\n",
      "Cheerful\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Nervous\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Aff_Neutral\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Tired\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [0.55549024 1.         1.        ]\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "\n",
      " post-hoc arousal-valence and different groups\n",
      "Arousal\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [0.66878733 0.87434428 1.        ]\n",
      "Valence\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [0.72258197 0.99769889 1.        ]\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "\n",
      " post-hoc level of intereset and different groups\n",
      "Normal Interest\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1.         0.19685863 1.        ]\n",
      "High Interest\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1.         0.19685863 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print('EMOTION\\n')\n",
    "print('post-hoc emotions and different groups')\n",
    "emo_reject_list, emo_corrected_p_vals, emo_combinations, emo_residuals= hp.chi2_post_hoc(df_emotion_char,emotion_label, 'IsNativeSpeaker', 'bonferroni', True, True)\n",
    "print('\\nAFFECT\\n')\n",
    "print('\\n post-hoc affect and different groups')\n",
    "aff_reject_list, emo_corrected_p_vals, emo_combinations, aff_residuals = hp.chi2_post_hoc(df_affect_char, affect_label, 'IsNativeSpeaker' ,'bonferroni', True, True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "print('\\n post-hoc arousal-valence and different groups')\n",
    "ar_val_reject_list, ar_val_corrected_p_vals, ar_val_combinations, ar_val_residuals = hp.chi2_post_hoc(df_ar_val_char, ['Arousal', 'Valence'], 'IsNativeSpeaker', 'bonferroni',True, True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "print('\\n post-hoc level of intereset and different groups')\n",
    "loi_reject_list, loi_corrected_p_vals, loi_combinations, loi_residuals = hp.chi2_post_hoc(df_loi_char, ['Normal Interest', 'High Interest'], 'IsNativeSpeaker', 'bonferroni', True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
