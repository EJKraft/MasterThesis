{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kruska Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import statsmodels.api as sm\n",
    "import sklearn.preprocessing as pp\n",
    "#import nltk\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import Helper as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load .csv data with results of OpenSMILE Analysis\n",
    "First we load .csv data and clean it (removing of NaNs), then we store information of all files in seperate panda dataframes containing information about affect, emotion and valence/arousal for all participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"CHI_2019_FULL.csv\")\n",
    "\n",
    "#Set Labels \n",
    "emotion_label = ['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness']\n",
    "affect_label = ['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired']\n",
    "loi_label = ['Disinterest', 'Normal', 'High Interest']\n",
    "\n",
    "#Get specific data and save it into new data frames\n",
    "# We use the pandas .copy(deep=True) function to prevent the SettingWithCopyWarning we would otherwise get. Since we do\n",
    "# not write, but only read from the data, the warning does not affect the data frames\n",
    "df_emotion = data[['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness', 'Filename']].copy(deep=True)\n",
    "df_affect = data[['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired', 'Filename']].copy(deep=True)\n",
    "df_loi = data[['Disinterest', 'Normal', 'High Interest', 'Filename']].copy(deep=True)\n",
    "df_ar_val = data[['Arousal', 'Valence', 'Filename']].copy(deep=True)\n",
    "#For further usage, we want to append the CharacterID as a column, which is saved with other information in the filename\n",
    "#Since we only want the digits, we can remove all non-digit characters of the filename column and append the column to the df\n",
    "\n",
    "df_emotion['Char_ID'] = df_emotion['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_affect['Char_ID'] = df_affect['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_loi['Char_ID'] = df_loi['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Filename'].replace('\\D+','', regex = True).copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load information about the speakers\n",
    "The speaker ID is saved in a single .csv file containing four important columns: ID, Age, Sex and Acadedmic Status. Since before loaded OpenSMILE csv files are named using the corresponding index (ex. speaker with id 0 has two files 0_a.csv and 0_b.csv), so that a link can be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_data = pd.read_csv(\"CHI_2019_CharacterData.csv\")  \n",
    "\n",
    "#Join above tables and Character Tables\n",
    "\n",
    "#To Join DataFrames we have to cast the column on which we want to join to int, so that both columns have the same data type\n",
    "char_data['ID'] = char_data['ID'].astype(int)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Char_ID'].astype(int)\n",
    "df_emotion['Char_ID'] = df_emotion['Char_ID'].astype(int)\n",
    "df_affect['Char_ID'] = df_affect['Char_ID'].astype(int)\n",
    "df_loi['Char_ID'] = df_loi['Char_ID'].astype(int)\n",
    "\n",
    "#Safe new data frames\n",
    "df_ar_val_char = df_ar_val.merge(char_data, how = 'left', left_on='Char_ID', right_on='ID')\n",
    "df_emotion_char = df_emotion.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_affect_char = df_affect.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_loi_char = df_loi.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "\n",
    "arval_sentence_type = df_ar_val_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_ar_val_char['SentenceType'] = arval_sentence_type\n",
    "emo_sentence_type = df_emotion_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_emotion_char['SentenceType'] = emo_sentence_type\n",
    "aff_sentence_type = df_affect_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_affect_char['SentenceType'] = aff_sentence_type\n",
    "loi_sentence_type = df_loi_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_loi_char['SentenceType'] = loi_sentence_type\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'p']\n",
    "df_emotion_char = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'p']\n",
    "df_affect_char = df_affect_char.loc[df_affect_char['SentenceType'] == 'p']\n",
    "df_loi_char = df_loi_char.loc[df_loi_char['SentenceType'] == 'p']\n",
    "\n",
    "#For affect, we will have to drop the intoxication column and thus we will re-normalize the other values\n",
    "affect_label.remove('Intoxicated')\n",
    "df_affect_char = df_affect_char.drop(['Intoxicated'], axis = 1)\n",
    "norm_test = pp.normalize(df_affect_char[affect_label], norm = 'l1')\n",
    "df_affect_char[affect_label] = norm_test\n",
    "\n",
    "df_loi_char['Normal Interest'] = df_loi_char['Disinterest'] + df_loi_char['Normal']\n",
    "df_loi_char = df_loi_char.drop(['Disinterest', 'Normal'], axis = 1)\n",
    "loi_label = ['Normal Interest', 'High Interest']\n",
    "\n",
    "#Now let's compensate for multiple samples of the same person\n",
    "IDs = df_emotion_char['Char_ID'].copy()\n",
    "IDs.drop_duplicates()\n",
    "\n",
    "# I know that for loops make the following operations very very slow, but I could not find a way to get this\n",
    "# working with pd.apply and lambda functions... \n",
    "\n",
    "for i in IDs:\n",
    "    #first for emotion\n",
    "    for l in emotion_label:    \n",
    "        emo = df_emotion_char.loc[df_emotion_char.Char_ID == i,l]\n",
    "        emo_neu = hp.constructMedianSeries(emo)\n",
    "        df_emotion_char.loc[df_emotion_char.Char_ID == i,l] = emo_neu\n",
    "    #Then for affect\n",
    "    for l in affect_label:    \n",
    "        aff = df_affect_char.loc[df_affect_char.Char_ID == i,l]\n",
    "        aff_neu = hp.constructMedianSeries(aff)\n",
    "        df_affect_char.loc[df_affect_char.Char_ID == i,l] = aff_neu  \n",
    "    for l in loi_label:    \n",
    "        loi = df_loi_char.loc[df_loi_char.Char_ID == i,l]\n",
    "        loi_neu = hp.constructMedianSeries(loi)\n",
    "        df_loi_char.loc[df_loi_char.Char_ID == i,l] = loi_neu  \n",
    "    for l in ['Arousal', 'Valence']:    \n",
    "        arval = df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l]\n",
    "        arval_neu = hp.constructMedianSeries(arval)\n",
    "        df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l] = arval_neu  \n",
    "        \n",
    "#Now let's drop the duplicate values, since we only need one row now per person\n",
    "df_emotion_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_affect_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_loi_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_ar_val_char.drop_duplicates(subset=['ID'], inplace = True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kruskal-Wallis Test\n",
    "\n",
    "Scipy-Stats says that the input data is the measurement data, meaning it does not have to be ranked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kruskal-Wallis Test\n",
    "\n",
    "The below cells use the helper function kruskal_wallis(), which works as described above in Method 1. If a new input method has to be used, this function will be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOF: 1\n",
      "EMOTION\n",
      "\n",
      "Anger: \t\tKruskalResult(statistic=2.2377076224608694, pvalue=0.1346805167003844)\n",
      "Boredom: \tKruskalResult(statistic=0.9096577313053625, pvalue=0.3402052489794761)\n",
      "Disgust: \tKruskalResult(statistic=44.220475143276076, pvalue=2.9339634837815125e-11)\n",
      "Fear: \t\tKruskalResult(statistic=0.04406585446225373, pvalue=0.8337311383343785)\n",
      "Happiness: \tKruskalResult(statistic=0.989689113733388, pvalue=0.31981836967995125)\n",
      "Emo_Neutral: \tKruskalResult(statistic=2.5598500895986773, pvalue=0.10960897655754918)\n",
      "Sadness: \tKruskalResult(statistic=37.63936333347394, pvalue=8.510951189898231e-10)\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Aggressiv: \tKruskalResult(statistic=29.470465147274467, pvalue=5.677534017967844e-08)\n",
      "Cheerful: \tKruskalResult(statistic=6.4655771024922615, pvalue=0.010998391862470092)\n",
      "Nervous: \tKruskalResult(statistic=2.2843662534986606, pvalue=0.13068351220340688)\n",
      "Aff_Neutral: \tKruskalResult(statistic=3.638627882180458, pvalue=0.05645344196049059)\n",
      "Tired: \t\tKruskalResult(statistic=6.144755431160888, pvalue=0.013180239257387594)\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Arousal: \tKruskalResult(statistic=43.5674263627883, pvalue=4.09600440151529e-11)\n",
      "Valence: \tKruskalResult(statistic=15.373530587765003, pvalue=8.8215424220828e-05)\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Normal Interest: \tKruskalResult(statistic=9.20379848060793, pvalue=0.00241513461598178)\n",
      "High Interest: \tKruskalResult(statistic=9.203798480607702, pvalue=0.00241513461598208)\n"
     ]
    }
   ],
   "source": [
    "print('DOF: 1') #Because of two groups, DOF is 1\n",
    "print('EMOTION\\n')\n",
    "emo_sex = hp.kruskal_wallis(df_emotion_char, emotion_label, 'Sex', True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_sex = hp.kruskal_wallis(df_affect_char, affect_label,'Sex',  True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_sex = hp.kruskal_wallis(df_ar_val_char, ['Arousal', 'Valence'], 'Sex', True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_sex = hp.kruskal_wallis(df_loi_char, ['Normal Interest', 'High Interest'], 'Sex', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now move on to academic status, the hypothesis being that the variables academic status and e.g. emotion are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOF: 1\n",
      "EMOTION\n",
      "\n",
      "Anger: \t\tKruskalResult(statistic=3.961331274144849, pvalue=0.0465568696266298)\n",
      "Boredom: \tKruskalResult(statistic=1.4416707942447984, pvalue=0.22986916089648768)\n",
      "Disgust: \tKruskalResult(statistic=1.6022470821579873, pvalue=0.20558505693226062)\n",
      "Fear: \t\tKruskalResult(statistic=2.858922062989056, pvalue=0.09086837325108689)\n",
      "Happiness: \tKruskalResult(statistic=3.8510460783436797, pvalue=0.04971497485146177)\n",
      "Emo_Neutral: \tKruskalResult(statistic=1.28747146654525, pvalue=0.2565144505547385)\n",
      "Sadness: \tKruskalResult(statistic=0.7417121629225464, pvalue=0.3891129627283194)\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Aggressiv: \tKruskalResult(statistic=0.7855955961410928, pvalue=0.3754352520584273)\n",
      "Cheerful: \tKruskalResult(statistic=0.07425889451997136, pvalue=0.7852338608178387)\n",
      "Nervous: \tKruskalResult(statistic=2.7684323795041337, pvalue=0.09614027327250488)\n",
      "Aff_Neutral: \tKruskalResult(statistic=2.7314175439870496, pvalue=0.09839191876619842)\n",
      "Tired: \t\tKruskalResult(statistic=2.6460183880484465, pvalue=0.10380961385877377)\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Arousal: \tKruskalResult(statistic=0.7790147196077442, pvalue=0.3774426430112602)\n",
      "Valence: \tKruskalResult(statistic=5.762212205588412, pvalue=0.016374443030881206)\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Normal Interest: \tKruskalResult(statistic=2.455913403691852, pvalue=0.11708304314477401)\n",
      "High Interest: \tKruskalResult(statistic=2.455913403691852, pvalue=0.11708304314477401)\n"
     ]
    }
   ],
   "source": [
    "print('DOF: 1') # Only two groups, so 2-1 = DOF\n",
    "print('EMOTION\\n')\n",
    "emo_aca = hp.kruskal_wallis(df_emotion_char, emotion_label, 'Academic Status', True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_aca = hp.kruskal_wallis(df_affect_char, affect_label,'Academic Status',  True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_aca = hp.kruskal_wallis(df_ar_val_char, ['Arousal', 'Valence'], 'Academic Status', True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_aca = hp.kruskal_wallis(df_loi_char, ['Normal Interest', 'High Interest'], 'Academic Status', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
