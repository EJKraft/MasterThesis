{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import statsmodels.api as sm\n",
    "import sklearn.preprocessing as pp\n",
    "#import nltk\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import Helper as hp\n",
    "\n",
    "#Load Data\n",
    "data = pd.read_csv(\"CHI_2019_FULL.csv\")\n",
    "\n",
    "#Set Labels \n",
    "emotion_label = ['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness']\n",
    "affect_label = ['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired']\n",
    "loi_label = ['Disinterest', 'Normal', 'High Interest']\n",
    "\n",
    "#Get specific data and save it into new data frames\n",
    "# We use the pandas .copy(deep=True) function to prevent the SettingWithCopyWarning we would otherwise get. Since we do\n",
    "# not write, but only read from the data, the warning does not affect the data frames\n",
    "df_emotion = data[['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness', 'Filename']].copy(deep=True)\n",
    "df_affect = data[['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired', 'Filename']].copy(deep=True)\n",
    "df_loi = data[['Disinterest', 'Normal', 'High Interest', 'Filename']].copy(deep=True)\n",
    "df_ar_val = data[['Arousal', 'Valence', 'Filename']].copy(deep=True)\n",
    "#For further usage, we want to append the CharacterID as a column, which is saved with other information in the filename\n",
    "#Since we only want the digits, we can remove all non-digit characters of the filename column and append the column to the df\n",
    "\n",
    "df_emotion['Char_ID'] = df_emotion['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_affect['Char_ID'] = df_affect['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_loi['Char_ID'] = df_loi['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "\n",
    "#Load data about speakers\n",
    "char_data = pd.read_csv(\"CHI_2019_CharacterData.csv\")  \n",
    "\n",
    "#Join above tables and Character Tables\n",
    "\n",
    "#To Join DataFrames we have to cast the column on which we want to join to int, so that both columns have the same data type\n",
    "char_data['ID'] = char_data['ID'].astype(int)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Char_ID'].astype(int)\n",
    "df_emotion['Char_ID'] = df_emotion['Char_ID'].astype(int)\n",
    "df_affect['Char_ID'] = df_affect['Char_ID'].astype(int)\n",
    "df_loi['Char_ID'] = df_loi['Char_ID'].astype(int)\n",
    "\n",
    "#Save new data frames\n",
    "df_ar_val_char = df_ar_val.merge(char_data, how = 'left', left_on='Char_ID', right_on='ID')\n",
    "df_emotion_char = df_emotion.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_affect_char = df_affect.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_loi_char = df_loi.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "\n",
    "#Now, we only want to have data containing information about the answers\n",
    "#For that we need to extract from the filename column, whether the file was part of an answer\n",
    "#a = answer, p = presentation, q = question\n",
    "#sentence_type should be the same for all tables, but just to be sure\n",
    "arval_sentence_type = df_ar_val_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_ar_val_char['SentenceType'] = arval_sentence_type\n",
    "emo_sentence_type = df_emotion_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_emotion_char['SentenceType'] = emo_sentence_type\n",
    "aff_sentence_type = df_affect_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_affect_char['SentenceType'] = aff_sentence_type\n",
    "loi_sentence_type = df_loi_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_loi_char['SentenceType'] = loi_sentence_type\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'p']\n",
    "df_emotion_char = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'p']\n",
    "df_affect_char = df_affect_char.loc[df_affect_char['SentenceType'] == 'p']\n",
    "df_loi_char = df_loi_char.loc[df_loi_char['SentenceType'] == 'p']\n",
    "\n",
    "#For affect, we will have to drop the intoxication column and thus we will re-normalize the other values\n",
    "affect_label.remove('Intoxicated')\n",
    "df_affect_char = df_affect_char.drop(['Intoxicated'], axis = 1)\n",
    "norm_test = pp.normalize(df_affect_char[affect_label], norm = 'l1')\n",
    "df_affect_char[affect_label] = norm_test\n",
    "\n",
    "df_loi_char['Normal Interest'] = df_loi_char['Disinterest'] + df_loi_char['Normal']\n",
    "df_loi_char = df_loi_char.drop(['Disinterest', 'Normal'], axis = 1)\n",
    "loi_label = ['Normal Interest', 'High Interest']\n",
    "\n",
    "#Now let's compensate for multiple samples of the same person\n",
    "IDs = df_emotion_char['Char_ID'].copy()\n",
    "IDs.drop_duplicates()\n",
    "\n",
    "# I know that for loops make the following operations very very slow, but I could not find a way to get this\n",
    "# working with pd.apply and lambda functions... \n",
    "\n",
    "for i in IDs:\n",
    "    #first for emotion\n",
    "    for l in emotion_label:    \n",
    "        emo = df_emotion_char.loc[df_emotion_char.Char_ID == i,l]\n",
    "        emo_neu = hp.constructMedianSeries(emo)\n",
    "        df_emotion_char.loc[df_emotion_char.Char_ID == i,l] = emo_neu\n",
    "    #Then for affect\n",
    "    for l in affect_label:    \n",
    "        aff = df_affect_char.loc[df_affect_char.Char_ID == i,l]\n",
    "        aff_neu = hp.constructMedianSeries(aff)\n",
    "        df_affect_char.loc[df_affect_char.Char_ID == i,l] = aff_neu  \n",
    "    for l in loi_label:    \n",
    "        loi = df_loi_char.loc[df_loi_char.Char_ID == i,l]\n",
    "        loi_neu = hp.constructMedianSeries(loi)\n",
    "        df_loi_char.loc[df_loi_char.Char_ID == i,l] = loi_neu  \n",
    "    for l in ['Arousal', 'Valence']:    \n",
    "        arval = df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l]\n",
    "        arval_neu = hp.constructMedianSeries(arval)\n",
    "        df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l] = arval_neu  \n",
    "        \n",
    "#Now let's drop the duplicate values, since we only need one row now per person\n",
    "df_emotion_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_affect_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_loi_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_ar_val_char.drop_duplicates(subset=['ID'], inplace = True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start with the character feature 'sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.516328\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    Sex   No. Observations:                   81\n",
      "Model:                          Logit   Df Residuals:                       74\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Thu, 12 Nov 2020   Pseudo R-squ.:                  0.2550\n",
      "Time:                        13:47:32   Log-Likelihood:                -41.823\n",
      "converged:                       True   LL-Null:                       -56.139\n",
      "                                        LLR p-value:                 7.140e-05\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.3053      3.429     -0.381      0.703      -8.027       5.416\n",
      "Anger        -39.5900     33.830     -1.170      0.242    -105.896      26.716\n",
      "Boredom      -14.8258      9.542     -1.554      0.120     -33.528       3.876\n",
      "Disgust        6.1586      4.065      1.515      0.130      -1.809      14.127\n",
      "Fear         201.1034    141.873      1.417      0.156     -76.962     479.169\n",
      "Happiness    -25.1025    133.903     -0.187      0.851    -287.548     237.343\n",
      "Sadness        0.0306      3.516      0.009      0.993      -6.860       6.922\n",
      "==============================================================================\n",
      "\n",
      "Affect\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.611302\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    Sex   No. Observations:                   81\n",
      "Model:                          Logit   Df Residuals:                       76\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Thu, 12 Nov 2020   Pseudo R-squ.:                  0.1180\n",
      "Time:                        13:47:32   Log-Likelihood:                -49.515\n",
      "converged:                       True   LL-Null:                       -56.139\n",
      "                                        LLR p-value:                   0.01013\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -9.8303      7.499     -1.311      0.190     -24.528       4.867\n",
      "Aggressiv     16.9975      8.220      2.068      0.039       0.887      33.108\n",
      "Cheerful       7.1970      7.980      0.902      0.367      -8.444      22.838\n",
      "Nervous       20.1749     33.659      0.599      0.549     -45.796      86.146\n",
      "Tired          9.7530      7.437      1.311      0.190      -4.823      24.329\n",
      "==============================================================================\n",
      "Level of Interest\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670693\n",
      "         Iterations 4\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    Sex   No. Observations:                   81\n",
      "Model:                          Logit   Df Residuals:                       79\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Thu, 12 Nov 2020   Pseudo R-squ.:                 0.03229\n",
      "Time:                        13:47:32   Log-Likelihood:                -54.326\n",
      "converged:                       True   LL-Null:                       -56.139\n",
      "                                        LLR p-value:                   0.05691\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept             -0.7489      0.472     -1.586      0.113      -1.674       0.176\n",
      "Q(\"High Interest\")     1.5795      0.847      1.864      0.062      -0.081       3.240\n",
      "======================================================================================\n",
      "Arousal-Valence\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.511056\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    Sex   No. Observations:                   81\n",
      "Model:                          Logit   Df Residuals:                       78\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Thu, 12 Nov 2020   Pseudo R-squ.:                  0.2626\n",
      "Time:                        13:47:32   Log-Likelihood:                -41.396\n",
      "converged:                       True   LL-Null:                       -56.139\n",
      "                                        LLR p-value:                 3.955e-07\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.3394      0.635     -2.110      0.035      -2.583      -0.095\n",
      "Arousal       15.1634      3.862      3.927      0.000       7.595      22.732\n",
      "Valence      -12.2220      4.510     -2.710      0.007     -21.062      -3.382\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print('Emotion')\n",
    "emotion_label.append('Sex')\n",
    "df_emotion_char.replace({'Male': 0.0, 'Female':1.0}, inplace = True)\n",
    "emo_sex_model = smf.logit(\"Sex ~ Anger + Boredom + Disgust + Fear + Happiness + Sadness\", data = df_emotion_char[emotion_label])\n",
    "emo_sex_results = emo_sex_model.fit()\n",
    "print(emo_sex_results.summary())\n",
    "\n",
    "print('\\nAffect')\n",
    "affect_label.append('Sex')\n",
    "df_affect_char.replace({'Male': 0.0, 'Female':1.0}, inplace = True)\n",
    "aff_sex_model = smf.logit(\"Sex ~ Aggressiv + Cheerful + Nervous + Tired\", data = df_affect_char[affect_label])\n",
    "aff_sex_results = aff_sex_model.fit()\n",
    "print(aff_sex_results.summary())\n",
    "\n",
    "print('Level of Interest')\n",
    "loi_label.append('Sex')\n",
    "df_loi_char.replace({'Male': 0.0, 'Female':1.0}, inplace = True)\n",
    "loi_sex_model = smf.logit('Sex ~ Q(\"High Interest\")', data = df_loi_char[['Normal Interest', 'High Interest', 'Sex']])\n",
    "loi_sex_results = loi_sex_model.fit()\n",
    "print(loi_sex_results.summary())\n",
    "\n",
    "print('Arousal-Valence')\n",
    "df_ar_val_char.replace({'Male': 0.0, 'Female':1.0}, inplace = True)\n",
    "ar_val_sex_model = smf.logit('Sex ~ Arousal + Valence', data = df_ar_val_char[['Arousal','Valence','Sex']])\n",
    "ar_val_sex_results = ar_val_sex_model.fit()\n",
    "print(ar_val_sex_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High Interest</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Char_ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>VideoTitle</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Academic Status</th>\n",
       "      <th>VideoID</th>\n",
       "      <th>IsNativeSpeaker</th>\n",
       "      <th>SentenceType</th>\n",
       "      <th>Normal Interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.943855</td>\n",
       "      <td>192_a_p.wav</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>23 Ways to Nudge: Review of Technology-Mediate...</td>\n",
       "      <td>Ana Caraban</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>-U3Bo7KR108</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.056145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.188775</td>\n",
       "      <td>197_a_p.wav</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>A Badge, Not a Barrier: Designing for- and Trh...</td>\n",
       "      <td>Caroline Pitt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>HxMSkH5ZpZI</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.811226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.425940</td>\n",
       "      <td>200_a_p.wav</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>A Change of Perspective: Designing Automated v...</td>\n",
       "      <td>Lenja Sorokin</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>SmnSU4QceSk</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.574060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.344827</td>\n",
       "      <td>203_a_p.wav</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>A Design Space for Gaze Interaction on HMD</td>\n",
       "      <td>Teresa Hirzle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>91VMIz6MAZ8</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.655173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.464366</td>\n",
       "      <td>207_a_p.wav</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>Analyzing Value Discovery in Design Decisions ...</td>\n",
       "      <td>Sai Shruthi Chivukula</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>3lV3YQUvyyY</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.535634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.371143</td>\n",
       "      <td>211_a_p.wav</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>Apprise: Supporting the Critical-Agency of Vic...</td>\n",
       "      <td>Hannah Thinyane</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>VZSn47dkw8Y</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.628857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.515540</td>\n",
       "      <td>214_a_p.wav</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>Assisted Shifting of Electricity Use: Long Ter...</td>\n",
       "      <td>Rikke Hagensby Jensen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>giD37cbtetY</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.484461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.862047</td>\n",
       "      <td>219_a_p.wav</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>Augmenting Couples' Communication with Lifelin...</td>\n",
       "      <td>Carla F. Griggio</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wFb8w7mPEsQ</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.137952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.593669</td>\n",
       "      <td>221_a_p.wav</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>Beyond Behaviour: The Coach's Perspective on T...</td>\n",
       "      <td>Heleen Rutjes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>oxorAXoEmf8</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.406331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.864195</td>\n",
       "      <td>223_a_p.wav</td>\n",
       "      <td>223</td>\n",
       "      <td>223</td>\n",
       "      <td>Bringing Shades of Feminism to Human Centered ...</td>\n",
       "      <td>Neha Kumar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>SN7xUEYCKmU</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.135806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.661688</td>\n",
       "      <td>226_a_p.wav</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>Career Mentoring in Online Communities: Seekin...</td>\n",
       "      <td>Maria Tomprou</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>bP_XQz5v9Cc</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.338312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.803897</td>\n",
       "      <td>229_a_p.wav</td>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "      <td>Caring for Vincent: A Chatbot for Self-Comparison</td>\n",
       "      <td>Minha Lee</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>AQZo1JpxkcA</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.196103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.750963</td>\n",
       "      <td>234_a_p.wav</td>\n",
       "      <td>234</td>\n",
       "      <td>234</td>\n",
       "      <td>Children's Reflection in Action with DIY</td>\n",
       "      <td>Silvia Torsi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>MvgGzZD-cQs</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.249037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.980336</td>\n",
       "      <td>237_a_p.wav</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>Communication Breakdowns Between Families and ...</td>\n",
       "      <td>Erin Beneteau</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>OWheOorTI88</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.019664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.129672</td>\n",
       "      <td>239_a_p.wav</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>Comparing Data from Chatbot and Web Surveys</td>\n",
       "      <td>Soomin Kim</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>IbdzG56UUTk</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.870328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.180117</td>\n",
       "      <td>241_a_p.wav</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>Co-Performing Agent: Design for Building User-...</td>\n",
       "      <td>Da-jung Kim</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>glSj2c315N4</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.819884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.477702</td>\n",
       "      <td>243_a_p.wav</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>Designing an Informal Learning Curriculum to D...</td>\n",
       "      <td>Srinjita Bhaduri</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>9N1zyJ65Zhk</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.522299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.884053</td>\n",
       "      <td>246_a_p.wav</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>Designing Theory-Driven User-Centric Explainab...</td>\n",
       "      <td>Danding Wang</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>RS7jP-6AHck</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.115947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.164880</td>\n",
       "      <td>250_a_p.wav</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>Digital Behaviour Change Interventions to Brea...</td>\n",
       "      <td>Charlie Pinder</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>83_ahNFFt1M</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.835120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.209569</td>\n",
       "      <td>254_a_p.wav</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>Effects of Participatory Evaluation</td>\n",
       "      <td>Katta Spiel</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>cMXf91FWQGU</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.790431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.274587</td>\n",
       "      <td>258_a_p.wav</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>Emotion Work in Experience-centred Design</td>\n",
       "      <td>Rachel E. Clarke</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>dfZy625qb1M</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.725413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.658119</td>\n",
       "      <td>262_a_p.wav</td>\n",
       "      <td>262</td>\n",
       "      <td>262</td>\n",
       "      <td>Expression of Curiosity in Social Robots: Desi...</td>\n",
       "      <td>Jessy Ceha</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>sQEO8m9S3_Q</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.341881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.218076</td>\n",
       "      <td>265_a_p.wav</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>From Gender Biases to Gender-Inclusive Design:...</td>\n",
       "      <td>Mihaela Vorvoreanu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>WUiUwsVJ39c</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.781924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.283666</td>\n",
       "      <td>269_a_p.wav</td>\n",
       "      <td>269</td>\n",
       "      <td>269</td>\n",
       "      <td>Geppetto: Enabling Semantic Design of Expressi...</td>\n",
       "      <td>Ruta Desai</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>B7_x0v_g8ZE</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.716334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.638346</td>\n",
       "      <td>272_a_p.wav</td>\n",
       "      <td>272</td>\n",
       "      <td>272</td>\n",
       "      <td>HCI and Menopause: Designing With and Around t...</td>\n",
       "      <td>Agatha Tutia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>wDtIjySKaaU</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.361654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.502434</td>\n",
       "      <td>276_a_p.wav</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>How to Work in the Car of the Future? A Neuroe...</td>\n",
       "      <td>Kathrin Pollman</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>6FByK43a-AI</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.497566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.423966</td>\n",
       "      <td>281_a_p.wav</td>\n",
       "      <td>281</td>\n",
       "      <td>281</td>\n",
       "      <td>i'sFree: Eyes-Free Gesture Typing via a Touch-...</td>\n",
       "      <td>Suwen Zhu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>hddqVTPiP38</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.576034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.625461</td>\n",
       "      <td>283_a_p.wav</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>Lessons Learned from Research via Private Soci...</td>\n",
       "      <td>Cassie Kresnye</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>bwWrOZdxIsw</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.374539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0.887412</td>\n",
       "      <td>286_a_p.wav</td>\n",
       "      <td>286</td>\n",
       "      <td>286</td>\n",
       "      <td>Managerial Visions: Stories of Upgrading and M...</td>\n",
       "      <td>Sarah E. Fox</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>63RiUC3mhpE</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.112588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.910482</td>\n",
       "      <td>289_a_p.wav</td>\n",
       "      <td>289</td>\n",
       "      <td>289</td>\n",
       "      <td>May AI? Design Ideation with Cooperative Conte...</td>\n",
       "      <td>Janin Koch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>77-UFZZD3GQ</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.089518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.580958</td>\n",
       "      <td>358_a_p.wav</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "      <td>Design Guideline for Developing Safe Systems t...</td>\n",
       "      <td>Michinari Kono</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>LEkOauR1Kog</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.419042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.562280</td>\n",
       "      <td>361_a_p.wav</td>\n",
       "      <td>361</td>\n",
       "      <td>361</td>\n",
       "      <td>Designing Second-Screening Experiences for Soc...</td>\n",
       "      <td>Tom Feltwell</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>Bf1BDRRKATk</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.437721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.190233</td>\n",
       "      <td>364_a_p.wav</td>\n",
       "      <td>364</td>\n",
       "      <td>364</td>\n",
       "      <td>Direct Finger Manipulation of 3D Object Image ...</td>\n",
       "      <td>Atsushi Matsubayashi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>DrUfwi_0huU</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.809767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.695036</td>\n",
       "      <td>366_a_p.wav</td>\n",
       "      <td>366</td>\n",
       "      <td>366</td>\n",
       "      <td>Egocentric Smaller-person Experience through a...</td>\n",
       "      <td>Jun Nishida</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>qiGOvoS83Qs</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.304963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.057026</td>\n",
       "      <td>370_a_p.wav</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>Empowering Expression for Users with Aphasia t...</td>\n",
       "      <td>Timothy Neate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>xHkhdD-Ek58</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.942974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.035083</td>\n",
       "      <td>374_a_p.wav</td>\n",
       "      <td>374</td>\n",
       "      <td>374</td>\n",
       "      <td>Encumbered Interaction: a Study of Musicians P...</td>\n",
       "      <td>Juan Pablo Martinez</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>bh3YuiMqx84</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.964917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.958202</td>\n",
       "      <td>376_a_p.wav</td>\n",
       "      <td>376</td>\n",
       "      <td>376</td>\n",
       "      <td>Evaluation of Appearance-Based Methods and Imp...</td>\n",
       "      <td>Xucong Zhang</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>l8S1bQGYJdk</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.041798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.185452</td>\n",
       "      <td>380_a_p.wav</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>Experimental Analysis of Barehand Mid-air Mode...</td>\n",
       "      <td>Hemant Bhaskar Surale</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>-Dc3O10xP1g</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.814548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.264122</td>\n",
       "      <td>383_a_p.wav</td>\n",
       "      <td>383</td>\n",
       "      <td>383</td>\n",
       "      <td>Explaining Decision-Making Algorithms through ...</td>\n",
       "      <td>Hao-Fei Cheng</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>asIS1InULmQ</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.735877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.658491</td>\n",
       "      <td>386_a_p.wav</td>\n",
       "      <td>386</td>\n",
       "      <td>386</td>\n",
       "      <td>Explorations on Single Usability Metrics</td>\n",
       "      <td>Michael Van Waardhuizen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>WQSJi95wEOk</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.341510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0.814439</td>\n",
       "      <td>390_a_p.wav</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>Exploring Virtual Agents for Augmented Reality</td>\n",
       "      <td>Isaac Wang</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>UO7m89mFM2A</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.185561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.059448</td>\n",
       "      <td>394_a_p.wav</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>Face and Ecological Validity in Simulations: L...</td>\n",
       "      <td>Lorin Dole</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>osZ5BxMpyNE</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.940552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.676263</td>\n",
       "      <td>398_a_p.wav</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>ForceRay: Extending Thumb Reach via Force Inpu...</td>\n",
       "      <td>Christian Corsten</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>j0-WKQkVLW8</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.323737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.367968</td>\n",
       "      <td>402_a_p.wav</td>\n",
       "      <td>402</td>\n",
       "      <td>402</td>\n",
       "      <td>From Being There to Watching: Shared and Dedic...</td>\n",
       "      <td>Carman Neustaedter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>wgXZHEgsK1E</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.632031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.825650</td>\n",
       "      <td>405_a_p.wav</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "      <td>From the Lab to the UB Truck: Object-Based Bro...</td>\n",
       "      <td>Thomas Röggla</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>0dbr23kR4Pg</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.174351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.259339</td>\n",
       "      <td>409_a_p.wav</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>FTVR in VR: Evaluating 3D Performance with a S...</td>\n",
       "      <td>Dylan Fafard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>071I_uohryQ</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.740661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.098530</td>\n",
       "      <td>414_a_p.wav</td>\n",
       "      <td>414</td>\n",
       "      <td>414</td>\n",
       "      <td>Gabber: Supporting Voice in Participatory Qual...</td>\n",
       "      <td>Jay Rainey</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>w7FcZBXccO4</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.901469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0.618775</td>\n",
       "      <td>418_a_p.wav</td>\n",
       "      <td>418</td>\n",
       "      <td>418</td>\n",
       "      <td>Gamification in Science: A Study of Requiremen...</td>\n",
       "      <td>Sebastian S. Feger</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>IlC0LxNNFAw</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.381224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>0.404306</td>\n",
       "      <td>421_a_p.wav</td>\n",
       "      <td>421</td>\n",
       "      <td>421</td>\n",
       "      <td>Gamified Ads: Bridging the Gap Between User En...</td>\n",
       "      <td>Maximilian Altmeyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>_ChjZ7FDUg0</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.595695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.767650</td>\n",
       "      <td>425_a_p.wav</td>\n",
       "      <td>425</td>\n",
       "      <td>425</td>\n",
       "      <td>Gehna: Exploring the Design Space of Jewelry a...</td>\n",
       "      <td>Jatin Arora</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>gYRPXoRYtXU</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.232349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.274398</td>\n",
       "      <td>428_a_p.wav</td>\n",
       "      <td>428</td>\n",
       "      <td>428</td>\n",
       "      <td>Hands Holding Clues for Object Recognitiion in...</td>\n",
       "      <td>Kyungjun Lee</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>4NBuqmwUryk</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.725602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.238826</td>\n",
       "      <td>431_a_p.wav</td>\n",
       "      <td>431</td>\n",
       "      <td>431</td>\n",
       "      <td>HapTwist: Creating Interactive Haptic Proxies ...</td>\n",
       "      <td>Kening Zhu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>nnqTJJIsPcs</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.761174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.033464</td>\n",
       "      <td>434_a_p.wav</td>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>HCI and Affective Health: Taking stock of a de...</td>\n",
       "      <td>Pedro Sanches</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>IlAAXSIb4WA</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.966536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0.487784</td>\n",
       "      <td>438_a_p.wav</td>\n",
       "      <td>438</td>\n",
       "      <td>438</td>\n",
       "      <td>HotStrokes: Word-Gesture Shortcuts on a Trackpad</td>\n",
       "      <td>Wenzhe Cui</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>iSQYejYs1fg</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.512216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0.453894</td>\n",
       "      <td>442_a_p.wav</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>How to Carry Out Usability Studies with Visual...</td>\n",
       "      <td>Carlos Alberto Martinez Sandoval</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>4FPuZj3tHJ4</td>\n",
       "      <td>Latin America</td>\n",
       "      <td>p</td>\n",
       "      <td>0.546106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>0.519661</td>\n",
       "      <td>447_a_p.wav</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>Implementing Multi-Touch Gestures with Touch G...</td>\n",
       "      <td>Brad Myers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>didYdY83zoc</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.480339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>0.360658</td>\n",
       "      <td>451_a_p.wav</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>Improving Early Navigation in Time-Lapse Video...</td>\n",
       "      <td>Michael Van Der Kamp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>G-LMD3Ro_hQ</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.639342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>0.519538</td>\n",
       "      <td>455_a_p.wav</td>\n",
       "      <td>455</td>\n",
       "      <td>455</td>\n",
       "      <td>In a Silent Way: Communication Between AI and ...</td>\n",
       "      <td>Jon McCormack</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>r5KA1Jo_vYU</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.480461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>0.693863</td>\n",
       "      <td>457_a_p.wav</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "      <td>Interferi: Gesture Sensing using On-Body Acous...</td>\n",
       "      <td>Yasha Iravantchi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>xBpBBpQh7GI</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>p</td>\n",
       "      <td>0.306136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>0.450139</td>\n",
       "      <td>464_a_p.wav</td>\n",
       "      <td>464</td>\n",
       "      <td>464</td>\n",
       "      <td>Interpreting the Diversity in Subjective Judgm...</td>\n",
       "      <td>Jean-Bernard Martens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>pS7CzHfawDU</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>p</td>\n",
       "      <td>0.549861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     High Interest     Filename  Char_ID   ID  \\\n",
       "1         0.943855  192_a_p.wav      192  192   \n",
       "12        0.188775  197_a_p.wav      197  197   \n",
       "19        0.425940  200_a_p.wav      200  200   \n",
       "26        0.344827  203_a_p.wav      203  203   \n",
       "35        0.464366  207_a_p.wav      207  207   \n",
       "44        0.371143  211_a_p.wav      211  211   \n",
       "51        0.515540  214_a_p.wav      214  214   \n",
       "60        0.862047  219_a_p.wav      219  219   \n",
       "65        0.593669  221_a_p.wav      221  221   \n",
       "70        0.864195  223_a_p.wav      223  223   \n",
       "77        0.661688  226_a_p.wav      226  226   \n",
       "84        0.803897  229_a_p.wav      229  229   \n",
       "95        0.750963  234_a_p.wav      234  234   \n",
       "101       0.980336  237_a_p.wav      237  237   \n",
       "107       0.129672  239_a_p.wav      239  239   \n",
       "112       0.180117  241_a_p.wav      241  241   \n",
       "117       0.477702  243_a_p.wav      243  243   \n",
       "124       0.884053  246_a_p.wav      246  246   \n",
       "133       0.164880  250_a_p.wav      250  250   \n",
       "142       0.209569  254_a_p.wav      254  254   \n",
       "152       0.274587  258_a_p.wav      258  258   \n",
       "160       0.658119  262_a_p.wav      262  262   \n",
       "167       0.218076  265_a_p.wav      265  265   \n",
       "176       0.283666  269_a_p.wav      269  269   \n",
       "183       0.638346  272_a_p.wav      272  272   \n",
       "192       0.502434  276_a_p.wav      276  276   \n",
       "203       0.423966  281_a_p.wav      281  281   \n",
       "210       0.625461  283_a_p.wav      283  283   \n",
       "217       0.887412  286_a_p.wav      286  286   \n",
       "224       0.910482  289_a_p.wav      289  289   \n",
       "..             ...          ...      ...  ...   \n",
       "388       0.580958  358_a_p.wav      358  358   \n",
       "395       0.562280  361_a_p.wav      361  361   \n",
       "402       0.190233  364_a_p.wav      364  364   \n",
       "407       0.695036  366_a_p.wav      366  366   \n",
       "414       0.057026  370_a_p.wav      370  370   \n",
       "423       0.035083  374_a_p.wav      374  374   \n",
       "428       0.958202  376_a_p.wav      376  376   \n",
       "437       0.185452  380_a_p.wav      380  380   \n",
       "444       0.264122  383_a_p.wav      383  383   \n",
       "453       0.658491  386_a_p.wav      386  386   \n",
       "462       0.814439  390_a_p.wav      390  390   \n",
       "471       0.059448  394_a_p.wav      394  394   \n",
       "480       0.676263  398_a_p.wav      398  398   \n",
       "489       0.367968  402_a_p.wav      402  402   \n",
       "496       0.825650  405_a_p.wav      405  405   \n",
       "505       0.259339  409_a_p.wav      409  409   \n",
       "516       0.098530  414_a_p.wav      414  414   \n",
       "525       0.618775  418_a_p.wav      418  418   \n",
       "532       0.404306  421_a_p.wav      421  421   \n",
       "543       0.767650  425_a_p.wav      425  425   \n",
       "550       0.274398  428_a_p.wav      428  428   \n",
       "557       0.238826  431_a_p.wav      431  431   \n",
       "564       0.033464  434_a_p.wav      434  434   \n",
       "573       0.487784  438_a_p.wav      438  438   \n",
       "582       0.453894  442_a_p.wav      442  442   \n",
       "593       0.519661  447_a_p.wav      447  447   \n",
       "602       0.360658  451_a_p.wav      451  451   \n",
       "611       0.519538  455_a_p.wav      455  455   \n",
       "616       0.693863  457_a_p.wav      457  457   \n",
       "631       0.450139  464_a_p.wav      464  464   \n",
       "\n",
       "                                            VideoTitle  \\\n",
       "1    23 Ways to Nudge: Review of Technology-Mediate...   \n",
       "12   A Badge, Not a Barrier: Designing for- and Trh...   \n",
       "19   A Change of Perspective: Designing Automated v...   \n",
       "26          A Design Space for Gaze Interaction on HMD   \n",
       "35   Analyzing Value Discovery in Design Decisions ...   \n",
       "44   Apprise: Supporting the Critical-Agency of Vic...   \n",
       "51   Assisted Shifting of Electricity Use: Long Ter...   \n",
       "60   Augmenting Couples' Communication with Lifelin...   \n",
       "65   Beyond Behaviour: The Coach's Perspective on T...   \n",
       "70   Bringing Shades of Feminism to Human Centered ...   \n",
       "77   Career Mentoring in Online Communities: Seekin...   \n",
       "84   Caring for Vincent: A Chatbot for Self-Comparison   \n",
       "95            Children's Reflection in Action with DIY   \n",
       "101  Communication Breakdowns Between Families and ...   \n",
       "107        Comparing Data from Chatbot and Web Surveys   \n",
       "112  Co-Performing Agent: Design for Building User-...   \n",
       "117  Designing an Informal Learning Curriculum to D...   \n",
       "124  Designing Theory-Driven User-Centric Explainab...   \n",
       "133  Digital Behaviour Change Interventions to Brea...   \n",
       "142                Effects of Participatory Evaluation   \n",
       "152          Emotion Work in Experience-centred Design   \n",
       "160  Expression of Curiosity in Social Robots: Desi...   \n",
       "167  From Gender Biases to Gender-Inclusive Design:...   \n",
       "176  Geppetto: Enabling Semantic Design of Expressi...   \n",
       "183  HCI and Menopause: Designing With and Around t...   \n",
       "192  How to Work in the Car of the Future? A Neuroe...   \n",
       "203  i'sFree: Eyes-Free Gesture Typing via a Touch-...   \n",
       "210  Lessons Learned from Research via Private Soci...   \n",
       "217  Managerial Visions: Stories of Upgrading and M...   \n",
       "224  May AI? Design Ideation with Cooperative Conte...   \n",
       "..                                                 ...   \n",
       "388  Design Guideline for Developing Safe Systems t...   \n",
       "395  Designing Second-Screening Experiences for Soc...   \n",
       "402  Direct Finger Manipulation of 3D Object Image ...   \n",
       "407  Egocentric Smaller-person Experience through a...   \n",
       "414  Empowering Expression for Users with Aphasia t...   \n",
       "423  Encumbered Interaction: a Study of Musicians P...   \n",
       "428  Evaluation of Appearance-Based Methods and Imp...   \n",
       "437  Experimental Analysis of Barehand Mid-air Mode...   \n",
       "444  Explaining Decision-Making Algorithms through ...   \n",
       "453           Explorations on Single Usability Metrics   \n",
       "462     Exploring Virtual Agents for Augmented Reality   \n",
       "471  Face and Ecological Validity in Simulations: L...   \n",
       "480  ForceRay: Extending Thumb Reach via Force Inpu...   \n",
       "489  From Being There to Watching: Shared and Dedic...   \n",
       "496  From the Lab to the UB Truck: Object-Based Bro...   \n",
       "505  FTVR in VR: Evaluating 3D Performance with a S...   \n",
       "516  Gabber: Supporting Voice in Participatory Qual...   \n",
       "525  Gamification in Science: A Study of Requiremen...   \n",
       "532  Gamified Ads: Bridging the Gap Between User En...   \n",
       "543  Gehna: Exploring the Design Space of Jewelry a...   \n",
       "550  Hands Holding Clues for Object Recognitiion in...   \n",
       "557  HapTwist: Creating Interactive Haptic Proxies ...   \n",
       "564  HCI and Affective Health: Taking stock of a de...   \n",
       "573   HotStrokes: Word-Gesture Shortcuts on a Trackpad   \n",
       "582  How to Carry Out Usability Studies with Visual...   \n",
       "593  Implementing Multi-Touch Gestures with Touch G...   \n",
       "602  Improving Early Navigation in Time-Lapse Video...   \n",
       "611  In a Silent Way: Communication Between AI and ...   \n",
       "616  Interferi: Gesture Sensing using On-Body Acous...   \n",
       "631  Interpreting the Diversity in Subjective Judgm...   \n",
       "\n",
       "                                 Name  Sex Academic Status      VideoID  \\\n",
       "1                         Ana Caraban  1.0    Grad Student  -U3Bo7KR108   \n",
       "12                      Caroline Pitt  1.0    Grad Student  HxMSkH5ZpZI   \n",
       "19                      Lenja Sorokin  1.0             PhD  SmnSU4QceSk   \n",
       "26                      Teresa Hirzle  1.0    Grad Student  91VMIz6MAZ8   \n",
       "35              Sai Shruthi Chivukula  1.0    Grad Student  3lV3YQUvyyY   \n",
       "44                    Hannah Thinyane  1.0    Grad Student  VZSn47dkw8Y   \n",
       "51              Rikke Hagensby Jensen  1.0             PhD  giD37cbtetY   \n",
       "60                   Carla F. Griggio  1.0             NaN  wFb8w7mPEsQ   \n",
       "65                      Heleen Rutjes  1.0    Grad Student  oxorAXoEmf8   \n",
       "70                         Neha Kumar  1.0             PhD  SN7xUEYCKmU   \n",
       "77                      Maria Tomprou  1.0             PhD  bP_XQz5v9Cc   \n",
       "84                          Minha Lee  1.0    Grad Student  AQZo1JpxkcA   \n",
       "95                       Silvia Torsi  1.0             PhD  MvgGzZD-cQs   \n",
       "101                     Erin Beneteau  1.0    Grad Student  OWheOorTI88   \n",
       "107                        Soomin Kim  1.0    Grad Student  IbdzG56UUTk   \n",
       "112                       Da-jung Kim  1.0             PhD  glSj2c315N4   \n",
       "117                  Srinjita Bhaduri  1.0    Grad Student  9N1zyJ65Zhk   \n",
       "124                      Danding Wang  1.0    Grad Student  RS7jP-6AHck   \n",
       "133                    Charlie Pinder  1.0             PhD  83_ahNFFt1M   \n",
       "142                       Katta Spiel  1.0             PhD  cMXf91FWQGU   \n",
       "152                  Rachel E. Clarke  1.0             PhD  dfZy625qb1M   \n",
       "160                        Jessy Ceha  1.0    Grad Student  sQEO8m9S3_Q   \n",
       "167                Mihaela Vorvoreanu  1.0             PhD  WUiUwsVJ39c   \n",
       "176                        Ruta Desai  1.0             PhD  B7_x0v_g8ZE   \n",
       "183                      Agatha Tutia  1.0    Grad Student  wDtIjySKaaU   \n",
       "192                   Kathrin Pollman  1.0             PhD  6FByK43a-AI   \n",
       "203                         Suwen Zhu  1.0             PhD  hddqVTPiP38   \n",
       "210                    Cassie Kresnye  1.0    Grad Student  bwWrOZdxIsw   \n",
       "217                      Sarah E. Fox  1.0             PhD  63RiUC3mhpE   \n",
       "224                        Janin Koch  1.0    Grad Student  77-UFZZD3GQ   \n",
       "..                                ...  ...             ...          ...   \n",
       "388                    Michinari Kono  0.0             PhD  LEkOauR1Kog   \n",
       "395                      Tom Feltwell  0.0    Grad Student  Bf1BDRRKATk   \n",
       "402              Atsushi Matsubayashi  0.0    Grad Student  DrUfwi_0huU   \n",
       "407                       Jun Nishida  0.0             PhD  qiGOvoS83Qs   \n",
       "414                     Timothy Neate  0.0             PhD  xHkhdD-Ek58   \n",
       "423               Juan Pablo Martinez  0.0    Grad Student  bh3YuiMqx84   \n",
       "428                      Xucong Zhang  0.0    Grad Student  l8S1bQGYJdk   \n",
       "437             Hemant Bhaskar Surale  0.0    Grad Student  -Dc3O10xP1g   \n",
       "444                     Hao-Fei Cheng  0.0    Grad Student  asIS1InULmQ   \n",
       "453           Michael Van Waardhuizen  0.0             PhD  WQSJi95wEOk   \n",
       "462                        Isaac Wang  0.0    Grad Student  UO7m89mFM2A   \n",
       "471                        Lorin Dole  0.0             PhD  osZ5BxMpyNE   \n",
       "480                 Christian Corsten  0.0             PhD  j0-WKQkVLW8   \n",
       "489                Carman Neustaedter  0.0             PhD  wgXZHEgsK1E   \n",
       "496                     Thomas Röggla  0.0             PhD  0dbr23kR4Pg   \n",
       "505                      Dylan Fafard  0.0    Grad Student  071I_uohryQ   \n",
       "516                        Jay Rainey  0.0             PhD  w7FcZBXccO4   \n",
       "525                Sebastian S. Feger  0.0    Grad Student  IlC0LxNNFAw   \n",
       "532               Maximilian Altmeyer  0.0    Grad Student  _ChjZ7FDUg0   \n",
       "543                       Jatin Arora  0.0    Grad Student  gYRPXoRYtXU   \n",
       "550                      Kyungjun Lee  0.0    Grad Student  4NBuqmwUryk   \n",
       "557                        Kening Zhu  0.0             PhD  nnqTJJIsPcs   \n",
       "564                     Pedro Sanches  0.0             PhD  IlAAXSIb4WA   \n",
       "573                        Wenzhe Cui  0.0    Grad Student  iSQYejYs1fg   \n",
       "582  Carlos Alberto Martinez Sandoval  0.0             PhD  4FPuZj3tHJ4   \n",
       "593                        Brad Myers  0.0             PhD  didYdY83zoc   \n",
       "602              Michael Van Der Kamp  0.0    Grad Student  G-LMD3Ro_hQ   \n",
       "611                     Jon McCormack  0.0             PhD  r5KA1Jo_vYU   \n",
       "616                  Yasha Iravantchi  0.0    Grad Student  xBpBBpQh7GI   \n",
       "631              Jean-Bernard Martens  0.0             PhD  pS7CzHfawDU   \n",
       "\n",
       "       IsNativeSpeaker SentenceType  Normal Interest  \n",
       "1    Europ. Non-Native            p         0.056145  \n",
       "12      Native Speaker            p         0.811226  \n",
       "19   Europ. Non-Native            p         0.574060  \n",
       "26   Europ. Non-Native            p         0.655173  \n",
       "35    Asian Non-Native            p         0.535634  \n",
       "44      Native Speaker            p         0.628857  \n",
       "51   Europ. Non-Native            p         0.484461  \n",
       "60   Europ. Non-Native            p         0.137952  \n",
       "65   Europ. Non-Native            p         0.406331  \n",
       "70      Native Speaker            p         0.135806  \n",
       "77      Native Speaker            p         0.338312  \n",
       "84      Native Speaker            p         0.196103  \n",
       "95   Europ. Non-Native            p         0.249037  \n",
       "101     Native Speaker            p         0.019664  \n",
       "107   Asian Non-Native            p         0.870328  \n",
       "112   Asian Non-Native            p         0.819884  \n",
       "117   Asian Non-Native            p         0.522299  \n",
       "124   Asian Non-Native            p         0.115947  \n",
       "133     Native Speaker            p         0.835120  \n",
       "142     Native Speaker            p         0.790431  \n",
       "152     Native Speaker            p         0.725413  \n",
       "160     Native Speaker            p         0.341881  \n",
       "167     Native Speaker            p         0.781924  \n",
       "176   Asian Non-Native            p         0.716334  \n",
       "183     Native Speaker            p         0.361654  \n",
       "192  Europ. Non-Native            p         0.497566  \n",
       "203   Asian Non-Native            p         0.576034  \n",
       "210     Native Speaker            p         0.374539  \n",
       "217     Native Speaker            p         0.112588  \n",
       "224  Europ. Non-Native            p         0.089518  \n",
       "..                 ...          ...              ...  \n",
       "388   Asian Non-Native            p         0.419042  \n",
       "395     Native Speaker            p         0.437721  \n",
       "402   Asian Non-Native            p         0.809767  \n",
       "407   Asian Non-Native            p         0.304963  \n",
       "414     Native Speaker            p         0.942974  \n",
       "423  Europ. Non-Native            p         0.964917  \n",
       "428   Asian Non-Native            p         0.041798  \n",
       "437   Asian Non-Native            p         0.814548  \n",
       "444   Asian Non-Native            p         0.735877  \n",
       "453     Native Speaker            p         0.341510  \n",
       "462     Native Speaker            p         0.185561  \n",
       "471     Native Speaker            p         0.940552  \n",
       "480  Europ. Non-Native            p         0.323737  \n",
       "489     Native Speaker            p         0.632031  \n",
       "496  Europ. Non-Native            p         0.174351  \n",
       "505     Native Speaker            p         0.740661  \n",
       "516     Native Speaker            p         0.901469  \n",
       "525  Europ. Non-Native            p         0.381224  \n",
       "532  Europ. Non-Native            p         0.595695  \n",
       "543   Asian Non-Native            p         0.232349  \n",
       "550   Asian Non-Native            p         0.725602  \n",
       "557   Asian Non-Native            p         0.761174  \n",
       "564  Europ. Non-Native            p         0.966536  \n",
       "573   Asian Non-Native            p         0.512216  \n",
       "582      Latin America            p         0.546106  \n",
       "593     Native Speaker            p         0.480339  \n",
       "602     Native Speaker            p         0.639342  \n",
       "611     Native Speaker            p         0.480461  \n",
       "616     Native Speaker            p         0.306136  \n",
       "631  Europ. Non-Native            p         0.549861  \n",
       "\n",
       "[81 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loi_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character feature = academic status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.596540\n",
      "         Iterations 8\n",
      "                            Logit Regression Results                            \n",
      "================================================================================\n",
      "Dep. Variable:     Q(\"Academic Status\")   No. Observations:                   80\n",
      "Model:                            Logit   Df Residuals:                       73\n",
      "Method:                             MLE   Df Model:                            6\n",
      "Date:                  Thu, 12 Nov 2020   Pseudo R-squ.:                  0.1390\n",
      "Time:                          13:47:32   Log-Likelihood:                -47.723\n",
      "converged:                         True   LL-Null:                       -55.427\n",
      "                                          LLR p-value:                   0.01732\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.9320      3.331      0.580      0.562      -4.596       8.460\n",
      "Anger         21.0533     33.512      0.628      0.530     -44.629      86.736\n",
      "Boredom       30.2402     14.476      2.089      0.037       1.869      58.612\n",
      "Disgust       -2.1091      3.662     -0.576      0.565      -9.286       5.068\n",
      "Fear         -64.1198    147.129     -0.436      0.663    -352.487     224.247\n",
      "Happiness   -206.5746    153.552     -1.345      0.179    -507.531      94.382\n",
      "Sadness       -1.7260      3.418     -0.505      0.614      -8.424       4.972\n",
      "==============================================================================\n",
      "\n",
      "Affect\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678760\n",
      "         Iterations 5\n",
      "                            Logit Regression Results                            \n",
      "================================================================================\n",
      "Dep. Variable:     Q(\"Academic Status\")   No. Observations:                   80\n",
      "Model:                            Logit   Df Residuals:                       75\n",
      "Method:                             MLE   Df Model:                            4\n",
      "Date:                  Thu, 12 Nov 2020   Pseudo R-squ.:                 0.02031\n",
      "Time:                          13:47:32   Log-Likelihood:                -54.301\n",
      "converged:                         True   LL-Null:                       -55.427\n",
      "                                          LLR p-value:                    0.6895\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.9520      7.114      0.415      0.678     -10.991      16.895\n",
      "Aggressiv     -4.4916      7.422     -0.605      0.545     -19.039      10.055\n",
      "Cheerful      -4.4092      7.546     -0.584      0.559     -19.199      10.381\n",
      "Nervous       23.6622     38.286      0.618      0.537     -51.378      98.702\n",
      "Tired         -3.9220      7.010     -0.559      0.576     -17.662       9.818\n",
      "==============================================================================\n",
      "Level of Interest\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680192\n",
      "         Iterations 4\n",
      "                            Logit Regression Results                            \n",
      "================================================================================\n",
      "Dep. Variable:     Q(\"Academic Status\")   No. Observations:                   80\n",
      "Model:                            Logit   Df Residuals:                       78\n",
      "Method:                             MLE   Df Model:                            1\n",
      "Date:                  Thu, 12 Nov 2020   Pseudo R-squ.:                 0.01825\n",
      "Time:                          13:47:32   Log-Likelihood:                -54.415\n",
      "converged:                         True   LL-Null:                       -55.427\n",
      "                                          LLR p-value:                    0.1549\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept              0.5238      0.466      1.124      0.261      -0.389       1.437\n",
      "Q(\"High Interest\")    -1.1834      0.842     -1.405      0.160      -2.834       0.467\n",
      "======================================================================================\n",
      "Arousal-Valence\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.665758\n",
      "         Iterations 5\n",
      "                            Logit Regression Results                            \n",
      "================================================================================\n",
      "Dep. Variable:     Q(\"Academic Status\")   No. Observations:                   80\n",
      "Model:                            Logit   Df Residuals:                       77\n",
      "Method:                             MLE   Df Model:                            2\n",
      "Date:                  Thu, 12 Nov 2020   Pseudo R-squ.:                 0.03908\n",
      "Time:                          13:47:32   Log-Likelihood:                -53.261\n",
      "converged:                         True   LL-Null:                       -55.427\n",
      "                                          LLR p-value:                    0.1146\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.3236      0.540     -0.599      0.549      -1.382       0.734\n",
      "Arousal       -1.4423      2.699     -0.534      0.593      -6.732       3.847\n",
      "Valence        7.0308      3.690      1.905      0.057      -0.202      14.263\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "emotion_label.remove('Sex')\n",
    "affect_label.remove('Sex')\n",
    "loi_label.remove('Sex')\n",
    "emotion_label.append('Academic Status')\n",
    "affect_label.append('Academic Status')\n",
    "loi_label.append('Academic Status')\n",
    "\n",
    "print('Emotion')\n",
    "df_emotion_char.replace({'Grad Student': 0.0, 'PhD':1.0}, inplace = True)\n",
    "emo_aca_model = smf.logit('Q(\"Academic Status\") ~ Anger + Boredom + Disgust + Fear + Happiness + Sadness', data = df_emotion_char[emotion_label])\n",
    "emo_aca_results = emo_aca_model.fit()\n",
    "print(emo_aca_results.summary())\n",
    "\n",
    "print('\\nAffect')\n",
    "df_affect_char.replace({'Grad Student': 0.0, 'PhD':1.0}, inplace = True)\n",
    "aff_aca_model = smf.logit('Q(\"Academic Status\") ~ Aggressiv + Cheerful + Nervous + Tired', data = df_affect_char[affect_label])\n",
    "aff_aca_results = aff_aca_model.fit()\n",
    "print(aff_aca_results.summary())\n",
    "\n",
    "print('Level of Interest')\n",
    "df_loi_char.replace({'Grad Student': 0.0, 'PhD':1.0}, inplace = True)\n",
    "loi_aca_model = smf.logit('Q(\"Academic Status\") ~ Q(\"High Interest\")', data = df_loi_char[['Normal Interest', 'High Interest', 'Academic Status']])\n",
    "loi_aca_results = loi_aca_model.fit()\n",
    "print(loi_aca_results.summary())\n",
    "\n",
    "print('Arousal-Valence')\n",
    "df_ar_val_char.replace({'Grad Student': 0.0, 'PhD':1.0}, inplace = True)\n",
    "ar_val_aca_model = smf.logit('Q(\"Academic Status\") ~ Arousal + Valence', data = df_ar_val_char[['Arousal','Valence','Academic Status']])\n",
    "ar_val_aca_results = ar_val_aca_model.fit()\n",
    "print(ar_val_aca_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Academic Status'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5841a5aa7fe7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Start with model and sex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Emotion'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdf_emo_nat_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_emotion_nat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0memotion_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mdf_emo_nat_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_emo_nat_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdf_emo_nat_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_emotion_nat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'IsNativeSpeaker'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Academic Status'] not in index\""
     ]
    }
   ],
   "source": [
    "df_emotion_nat = df_emotion_char.drop(['Char_ID', 'ID', 'Filename', 'Name','Academic Status', 'VideoID','VideoTitle', 'Sex'], axis = 1)\n",
    "df_emotion_nat.dropna(inplace = True)\n",
    "df_affect_nat = df_affect_char.drop(['Char_ID', 'ID', 'Filename', 'Name','Academic Status', 'VideoID','VideoTitle', 'Sex'], axis = 1)\n",
    "df_affect_nat.dropna(inplace = True)\n",
    "df_loi_nat = df_loi_char.drop(['Char_ID', 'ID', 'Filename', 'Name', 'VideoID','Academic Status','VideoTitle', 'Sex'], axis = 1)\n",
    "df_loi_nat.dropna(inplace = True)\n",
    "df_arval_nat = df_ar_val_char.drop(['Char_ID', 'ID', 'Filename', 'Name', 'Academic Status','VideoID','VideoTitle', 'Sex'], axis = 1)\n",
    "df_arval_nat.dropna(inplace = True)\n",
    "\n",
    "# Start with model and sex\n",
    "print('Emotion')\n",
    "df_emo_nat_X = df_emotion_nat[emotion_label]\n",
    "df_emo_nat_X = sm.add_constant(df_emo_nat_X)\n",
    "df_emo_nat_Y = df_emotion_nat['IsNativeSpeaker']\n",
    "logreg_emo_nat = sm.MNLogit(df_emo_nat_Y, df_emo_nat_X).fit()\n",
    "print(logreg_emo_nat.summary())\n",
    "\n",
    "print('\\nAffect')\n",
    "df_aff_nat_X = df_affect_nat[affect_label]\n",
    "df_aff_nat_X = sm.add_constant(df_aff_nat_X)\n",
    "df_aff_nat_Y = df_affect_nat['IsNativeSpeaker']\n",
    "logreg_aff_nat = sm.MNLogit(df_aff_nat_Y, df_aff_nat_X).fit()\n",
    "print(logreg_aff_nat.summary())\n",
    "\n",
    "print('Level of Interest')\n",
    "df_loi_nat_X = df_loi_nat[loi_label]\n",
    "df_loi_nat_X = sm.add_constant(df_loi_nat_X)\n",
    "df_loi_nat_Y = df_loi_nat['IsNativeSpeaker']\n",
    "logreg_loi_nat = sm.MNLogit(df_loi_nat_Y, df_loi_nat_X).fit()\n",
    "print(logreg_loi_nat.summary())\n",
    "\n",
    "print('Arousal-Valence')\n",
    "df_arval_nat_X = df_arval_nat[['Arousal', 'Valence']]\n",
    "df_arval_nat_X = sm.add_constant(df_arval_nat_X)\n",
    "df_arval_nat_Y = df_arval_nat['IsNativeSpeaker']\n",
    "logreg_ar_val_aca = sm.MNLogit(df_arval_nat_Y, df_arval_nat_X).fit()\n",
    "print(logreg_ar_val_aca.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
