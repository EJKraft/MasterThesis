{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import statsmodels.api as sm\n",
    "import sklearn.preprocessing as pp\n",
    "#import nltk\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import Helper as hp\n",
    "\n",
    "#Load Data\n",
    "data = pd.read_csv(\"CHI_2019_FULL.csv\")\n",
    "\n",
    "#Set Labels \n",
    "emotion_label = ['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness']\n",
    "affect_label = ['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired']\n",
    "loi_label = ['Disinterest', 'Normal', 'High Interest']\n",
    "\n",
    "#Get specific data and save it into new data frames\n",
    "# We use the pandas .copy(deep=True) function to prevent the SettingWithCopyWarning we would otherwise get. Since we do\n",
    "# not write, but only read from the data, the warning does not affect the data frames\n",
    "df_emotion = data[['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness', 'Filename']].copy(deep=True)\n",
    "df_affect = data[['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired', 'Filename']].copy(deep=True)\n",
    "df_loi = data[['Disinterest', 'Normal', 'High Interest', 'Filename']].copy(deep=True)\n",
    "df_ar_val = data[['Arousal', 'Valence', 'Filename']].copy(deep=True)\n",
    "#For further usage, we want to append the CharacterID as a column, which is saved with other information in the filename\n",
    "#Since we only want the digits, we can remove all non-digit characters of the filename column and append the column to the df\n",
    "\n",
    "df_emotion['Char_ID'] = df_emotion['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_affect['Char_ID'] = df_affect['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_loi['Char_ID'] = df_loi['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "\n",
    "#Load data about speakers\n",
    "char_data = pd.read_csv(\"CHI_2019_CharacterData.csv\")  \n",
    "\n",
    "#Join above tables and Character Tables\n",
    "\n",
    "#To Join DataFrames we have to cast the column on which we want to join to int, so that both columns have the same data type\n",
    "char_data['ID'] = char_data['ID'].astype(int)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Char_ID'].astype(int)\n",
    "df_emotion['Char_ID'] = df_emotion['Char_ID'].astype(int)\n",
    "df_affect['Char_ID'] = df_affect['Char_ID'].astype(int)\n",
    "df_loi['Char_ID'] = df_loi['Char_ID'].astype(int)\n",
    "\n",
    "#Save new data frames\n",
    "df_ar_val_char = df_ar_val.merge(char_data, how = 'left', left_on='Char_ID', right_on='ID')\n",
    "df_emotion_char = df_emotion.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_affect_char = df_affect.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_loi_char = df_loi.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "\n",
    "#Now, we only want to have data containing information about the answers\n",
    "#For that we need to extract from the filename column, whether the file was part of an answer\n",
    "#a = answer, p = presentation, q = question\n",
    "#sentence_type should be the same for all tables, but just to be sure\n",
    "arval_sentence_type = df_ar_val_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_ar_val_char['SentenceType'] = arval_sentence_type\n",
    "emo_sentence_type = df_emotion_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_emotion_char['SentenceType'] = emo_sentence_type\n",
    "aff_sentence_type = df_affect_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_affect_char['SentenceType'] = aff_sentence_type\n",
    "loi_sentence_type = df_loi_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_loi_char['SentenceType'] = loi_sentence_type\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'q']\n",
    "df_emotion_char = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'q']\n",
    "df_affect_char = df_affect_char.loc[df_affect_char['SentenceType'] == 'q']\n",
    "df_loi_char = df_loi_char.loc[df_loi_char['SentenceType'] == 'q']\n",
    "\n",
    "#For affect, we will have to drop the intoxication column and thus we will re-normalize the other values\n",
    "affect_label.remove('Intoxicated')\n",
    "df_affect_char = df_affect_char.drop(['Intoxicated'], axis = 1)\n",
    "norm_test = pp.normalize(df_affect_char[affect_label], norm = 'l1')\n",
    "df_affect_char[affect_label] = norm_test\n",
    "\n",
    "df_loi_char['Normal Interest'] = df_loi_char['Disinterest'] + df_loi_char['Normal']\n",
    "df_loi_char = df_loi_char.drop(['Disinterest', 'Normal'], axis = 1)\n",
    "loi_label = ['Normal Interest', 'High Interest']\n",
    "\n",
    "#Now let's compensate for multiple samples of the same person\n",
    "IDs = df_emotion_char['Char_ID'].copy()\n",
    "IDs.drop_duplicates()\n",
    "\n",
    "# I know that for loops make the following operations very very slow, but I could not find a way to get this\n",
    "# working with pd.apply and lambda functions... \n",
    "\n",
    "for i in IDs:\n",
    "    #first for emotion\n",
    "    for l in emotion_label:    \n",
    "        emo = df_emotion_char.loc[df_emotion_char.Char_ID == i,l]\n",
    "        emo_neu = hp.constructMedianSeries(emo)\n",
    "        df_emotion_char.loc[df_emotion_char.Char_ID == i,l] = emo_neu\n",
    "    #Then for affect\n",
    "    for l in affect_label:    \n",
    "        aff = df_affect_char.loc[df_affect_char.Char_ID == i,l]\n",
    "        aff_neu = hp.constructMedianSeries(aff)\n",
    "        df_affect_char.loc[df_affect_char.Char_ID == i,l] = aff_neu  \n",
    "    for l in loi_label:    \n",
    "        loi = df_loi_char.loc[df_loi_char.Char_ID == i,l]\n",
    "        loi_neu = hp.constructMedianSeries(loi)\n",
    "        df_loi_char.loc[df_loi_char.Char_ID == i,l] = loi_neu  \n",
    "    for l in ['Arousal', 'Valence']:    \n",
    "        arval = df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l]\n",
    "        arval_neu = hp.constructMedianSeries(arval)\n",
    "        df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l] = arval_neu  \n",
    "        \n",
    "#Now let's drop the duplicate values, since we only need one row now per person\n",
    "df_emotion_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_affect_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_loi_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_ar_val_char.drop_duplicates(subset=['ID'], inplace = True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start with the character feature 'sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.512488\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    Sex   No. Observations:                  193\n",
      "Model:                          Logit   Df Residuals:                      186\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Tue, 10 Nov 2020   Pseudo R-squ.:                  0.2175\n",
      "Time:                        16:42:43   Log-Likelihood:                -98.910\n",
      "converged:                       True   LL-Null:                       -126.41\n",
      "                                        LLR p-value:                 4.654e-10\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   -106.8628     34.660     -3.083      0.002    -174.794     -38.931\n",
      "Anger          1.0099     20.260      0.050      0.960     -38.700      40.720\n",
      "Boredom      110.1746     37.065      2.972      0.003      37.529     182.820\n",
      "Disgust      108.3254     34.638      3.127      0.002      40.436     176.215\n",
      "Fear          56.4779     22.116      2.554      0.011      13.131      99.825\n",
      "Happiness    505.6237    148.166      3.413      0.001     215.223     796.024\n",
      "Sadness      105.3977     34.607      3.046      0.002      37.570     173.226\n",
      "==============================================================================\n",
      "\n",
      "Affect\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.597462\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    Sex   No. Observations:                  193\n",
      "Model:                          Logit   Df Residuals:                      188\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 10 Nov 2020   Pseudo R-squ.:                 0.08778\n",
      "Time:                        16:42:43   Log-Likelihood:                -115.31\n",
      "converged:                       True   LL-Null:                       -126.41\n",
      "                                        LLR p-value:                 0.0001836\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -9.9777      5.609     -1.779      0.075     -20.972       1.016\n",
      "Aggressiv     14.1572      6.127      2.311      0.021       2.148      26.167\n",
      "Cheerful      10.9156      6.085      1.794      0.073      -1.012      22.843\n",
      "Nervous      -13.7329     16.048     -0.856      0.392     -45.185      17.720\n",
      "Tired          9.6156      5.530      1.739      0.082      -1.224      20.455\n",
      "==============================================================================\n",
      "Level of Interest\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.650952\n",
      "         Iterations: 35\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    Sex   No. Observations:                  193\n",
      "Model:                          Logit   Df Residuals:                      190\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 10 Nov 2020   Pseudo R-squ.:                0.006109\n",
      "Time:                        16:42:44   Log-Likelihood:                -125.63\n",
      "converged:                      False   LL-Null:                       -126.41\n",
      "                                        LLR p-value:                    0.4620\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept            -3407.2075   2.98e+05     -0.011      0.991   -5.87e+05     5.8e+05\n",
      "Q(\"Normal Interest\")  3406.3654   2.98e+05      0.011      0.991    -5.8e+05    5.87e+05\n",
      "Q(\"High Interest\")    3406.9992   2.98e+05      0.011      0.991    -5.8e+05    5.87e+05\n",
      "========================================================================================\n",
      "Arousal-Valence\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.616669\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    Sex   No. Observations:                  193\n",
      "Model:                          Logit   Df Residuals:                      190\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 10 Nov 2020   Pseudo R-squ.:                 0.05845\n",
      "Time:                        16:42:44   Log-Likelihood:                -119.02\n",
      "converged:                       True   LL-Null:                       -126.41\n",
      "                                        LLR p-value:                 0.0006181\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.9913      0.218     -4.540      0.000      -1.419      -0.563\n",
      "Arousal        4.9030      1.525      3.215      0.001       1.914       7.892\n",
      "Valence       -5.4279      2.061     -2.634      0.008      -9.467      -1.389\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "print('Emotion')\n",
    "emotion_label.append('Sex')\n",
    "df_emotion_char.replace({'Male': 0.0, 'Female':1.0}, inplace = True)\n",
    "emo_sex_model = smf.logit(\"Sex ~ Anger + Boredom + Disgust + Fear + Happiness + Sadness\", data = df_emotion_char[emotion_label])\n",
    "emo_sex_results = emo_sex_model.fit()\n",
    "print(emo_sex_results.summary())\n",
    "\n",
    "print('\\nAffect')\n",
    "affect_label.append('Sex')\n",
    "df_affect_char.replace({'Male': 0.0, 'Female':1.0}, inplace = True)\n",
    "aff_sex_model = smf.logit(\"Sex ~ Aggressiv + Cheerful + Nervous + Tired\", data = df_affect_char[affect_label])\n",
    "aff_sex_results = aff_sex_model.fit()\n",
    "print(aff_sex_results.summary())\n",
    "\n",
    "print('Level of Interest')\n",
    "loi_label.append('Sex')\n",
    "df_loi_char.replace({'Male': 0.0, 'Female':1.0}, inplace = True)\n",
    "loi_sex_model = smf.logit('Sex ~ Q(\"Normal Interest\") + Q(\"High Interest\")', data = df_loi_char[['Normal Interest', 'High Interest', 'Sex']])\n",
    "loi_sex_results = loi_sex_model.fit()\n",
    "print(loi_sex_results.summary())\n",
    "\n",
    "print('Arousal-Valence')\n",
    "df_ar_val_char.replace({'Male': 0.0, 'Female':1.0}, inplace = True)\n",
    "ar_val_sex_model = smf.logit('Sex ~ Arousal + Valence', data = df_ar_val_char[['Arousal','Valence','Sex']])\n",
    "ar_val_sex_results = ar_val_sex_model.fit()\n",
    "print(ar_val_sex_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_emotion_nat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7d9c61663f71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Start with model and sex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Emotion'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_emo_nat_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_emotion_nat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0memotion_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_emo_nat_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_emo_nat_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_emo_nat_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_emotion_nat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'IsNativeSpeaker'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_emotion_nat' is not defined"
     ]
    }
   ],
   "source": [
    "# Start with model and sex\n",
    "print('Emotion')\n",
    "df_emo_nat_X = df_emotion_nat[emotion_label]\n",
    "df_emo_nat_X = sm.add_constant(df_emo_nat_X)\n",
    "df_emo_nat_Y = df_emotion_nat['IsNativeSpeaker']\n",
    "logreg_emo_nat = sm.MNLogit(df_emo_nat_Y, df_emo_nat_X).fit()\n",
    "print(logreg_emo_nat.summary())\n",
    "\n",
    "print('\\nAffect')\n",
    "df_aff_nat_X = df_affect_nat[affect_label]\n",
    "df_aff_nat_X = sm.add_constant(df_aff_nat_X)\n",
    "df_aff_nat_Y = df_affect_nat['IsNativeSpeaker']\n",
    "logreg_aff_nat = sm.MNLogit(df_aff_nat_Y, df_aff_nat_X).fit()\n",
    "print(logreg_aff_nat.summary())\n",
    "\n",
    "print('Level of Interest')\n",
    "df_loi_nat_X = df_loi_nat[loi_label]\n",
    "df_loi_nat_X = sm.add_constant(df_loi_nat_X)\n",
    "df_loi_nat_Y = df_loi_nat['IsNativeSpeaker']\n",
    "logreg_loi_nat = sm.MNLogit(df_loi_nat_Y, df_loi_nat_X).fit()\n",
    "print(logreg_loi_nat.summary())\n",
    "\n",
    "print('Arousal-Valence')\n",
    "df_arval_nat_X = df_arval_nat[['Arousal', 'Valence']]\n",
    "df_arval_nat_X = sm.add_constant(df_arval_nat_X)\n",
    "df_arval_nat_Y = df_arval_nat['IsNativeSpeaker']\n",
    "logreg_ar_val_aca = sm.MNLogit(df_arval_nat_Y, df_arval_nat_X).fit()\n",
    "print(logreg_ar_val_aca.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
