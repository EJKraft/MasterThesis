{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import sklearn.preprocessing as pp\n",
    "import statsmodels.api as sm\n",
    "#import nltk\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import Helper as hp\n",
    "\n",
    "#Load Data\n",
    "data = pd.read_csv(\"CHI_2019_FULL.csv\")\n",
    "\n",
    "#Set Labels \n",
    "emotion_label = ['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness']\n",
    "affect_label = ['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired']\n",
    "loi_label = ['Disinterest', 'Normal', 'High Interest']\n",
    "\n",
    "#Get specific data and save it into new data frames\n",
    "# We use the pandas .copy(deep=True) function to prevent the SettingWithCopyWarning we would otherwise get. Since we do\n",
    "# not write, but only read from the data, the warning does not affect the data frames\n",
    "df_emotion = data[['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness', 'Filename']].copy(deep=True)\n",
    "df_affect = data[['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired', 'Filename']].copy(deep=True)\n",
    "df_loi = data[['Disinterest', 'Normal', 'High Interest', 'Filename']].copy(deep=True)\n",
    "df_ar_val = data[['Arousal', 'Valence', 'Filename']].copy(deep=True)\n",
    "#For further usage, we want to append the CharacterID as a column, which is saved with other information in the filename\n",
    "#Since we only want the digits, we can remove all non-digit characters of the filename column and append the column to the df\n",
    "\n",
    "df_emotion['Char_ID'] = df_emotion['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_affect['Char_ID'] = df_affect['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_loi['Char_ID'] = df_loi['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "\n",
    "#Load data about speakers\n",
    "char_data = pd.read_csv(\"CHI_2019_CharacterData.csv\")  \n",
    "\n",
    "#Join above tables and Character Tables\n",
    "\n",
    "#To Join DataFrames we have to cast the column on which we want to join to int, so that both columns have the same data type\n",
    "char_data['ID'] = char_data['ID'].astype(int)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Char_ID'].astype(int)\n",
    "df_emotion['Char_ID'] = df_emotion['Char_ID'].astype(int)\n",
    "df_affect['Char_ID'] = df_affect['Char_ID'].astype(int)\n",
    "df_loi['Char_ID'] = df_loi['Char_ID'].astype(int)\n",
    "\n",
    "#Save new data frames\n",
    "df_ar_val_char = df_ar_val.merge(char_data, how = 'left', left_on='Char_ID', right_on='ID')\n",
    "df_emotion_char = df_emotion.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_affect_char = df_affect.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_loi_char = df_loi.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "\n",
    "#Now, we only want to have data containing information about the answers\n",
    "#For that we need to extract from the filename column, whether the file was part of an answer\n",
    "#a = answer, p = presentation, q = question\n",
    "#sentence_type should be the same for all tables, but just to be sure\n",
    "arval_sentence_type = df_ar_val_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_ar_val_char['SentenceType'] = arval_sentence_type\n",
    "emo_sentence_type = df_emotion_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_emotion_char['SentenceType'] = emo_sentence_type\n",
    "aff_sentence_type = df_affect_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_affect_char['SentenceType'] = aff_sentence_type\n",
    "loi_sentence_type = df_loi_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_loi_char['SentenceType'] = loi_sentence_type\n",
    "\n",
    "#For affect, we will have to drop the intoxication column and thus we will re-normalize the other values\n",
    "affect_label.remove('Intoxicated')\n",
    "df_affect_char = df_affect_char.drop(['Intoxicated'], axis = 1)\n",
    "norm_test = pp.normalize(df_affect_char[affect_label], norm = 'l1')\n",
    "df_affect_char[affect_label] = norm_test\n",
    "\n",
    "df_loi_char['Normal Interest'] = df_loi_char['Disinterest'] + df_loi_char['Normal']\n",
    "df_loi_char = df_loi_char.drop(['Disinterest', 'Normal'], axis = 1)\n",
    "loi_label = ['Normal Interest', 'High Interest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High Interest</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Char_ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>VideoTitle</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Academic Status</th>\n",
       "      <th>VideoID</th>\n",
       "      <th>IsNativeSpeaker</th>\n",
       "      <th>SentenceType</th>\n",
       "      <th>Normal Interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.982720</td>\n",
       "      <td>192_a_a.wav</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>23 Ways to Nudge: Review of Technology-Mediate...</td>\n",
       "      <td>Ana Caraban</td>\n",
       "      <td>Female</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>-U3Bo7KR108</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>a</td>\n",
       "      <td>0.017280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.979165</td>\n",
       "      <td>192_b_a.wav</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>23 Ways to Nudge: Review of Technology-Mediate...</td>\n",
       "      <td>Ana Caraban</td>\n",
       "      <td>Female</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>-U3Bo7KR108</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>a</td>\n",
       "      <td>0.020835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997420</td>\n",
       "      <td>192_c_a.wav</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>23 Ways to Nudge: Review of Technology-Mediate...</td>\n",
       "      <td>Ana Caraban</td>\n",
       "      <td>Female</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>-U3Bo7KR108</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>a</td>\n",
       "      <td>0.002579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.848274</td>\n",
       "      <td>192_d_a.wav</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>23 Ways to Nudge: Review of Technology-Mediate...</td>\n",
       "      <td>Ana Caraban</td>\n",
       "      <td>Female</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>-U3Bo7KR108</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>a</td>\n",
       "      <td>0.151726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.341174</td>\n",
       "      <td>197_a_a.wav</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>A Badge, Not a Barrier: Designing for- and Trh...</td>\n",
       "      <td>Caroline Pitt</td>\n",
       "      <td>Female</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>HxMSkH5ZpZI</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>a</td>\n",
       "      <td>0.658826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0.973040</td>\n",
       "      <td>457_c_a.wav</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "      <td>Interferi: Gesture Sensing using On-Body Acous...</td>\n",
       "      <td>Yasha Iravantchi</td>\n",
       "      <td>Male</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>xBpBBpQh7GI</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>a</td>\n",
       "      <td>0.026960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0.978778</td>\n",
       "      <td>457_d_a.wav</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "      <td>Interferi: Gesture Sensing using On-Body Acous...</td>\n",
       "      <td>Yasha Iravantchi</td>\n",
       "      <td>Male</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>xBpBBpQh7GI</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>a</td>\n",
       "      <td>0.021222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>0.904425</td>\n",
       "      <td>457_e_a.wav</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "      <td>Interferi: Gesture Sensing using On-Body Acous...</td>\n",
       "      <td>Yasha Iravantchi</td>\n",
       "      <td>Male</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>xBpBBpQh7GI</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>a</td>\n",
       "      <td>0.095575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>0.964798</td>\n",
       "      <td>457_f_a.wav</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "      <td>Interferi: Gesture Sensing using On-Body Acous...</td>\n",
       "      <td>Yasha Iravantchi</td>\n",
       "      <td>Male</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>xBpBBpQh7GI</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>a</td>\n",
       "      <td>0.035202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0.466249</td>\n",
       "      <td>464_a_a.wav</td>\n",
       "      <td>464</td>\n",
       "      <td>464</td>\n",
       "      <td>Interpreting the Diversity in Subjective Judgm...</td>\n",
       "      <td>Jean-Bernard Martens</td>\n",
       "      <td>Male</td>\n",
       "      <td>PhD</td>\n",
       "      <td>pS7CzHfawDU</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>a</td>\n",
       "      <td>0.533752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     High Interest     Filename  Char_ID   ID  \\\n",
       "0         0.982720  192_a_a.wav      192  192   \n",
       "2         0.979165  192_b_a.wav      192  192   \n",
       "4         0.997420  192_c_a.wav      192  192   \n",
       "6         0.848274  192_d_a.wav      192  192   \n",
       "11        0.341174  197_a_a.wav      197  197   \n",
       "..             ...          ...      ...  ...   \n",
       "617       0.973040  457_c_a.wav      457  457   \n",
       "619       0.978778  457_d_a.wav      457  457   \n",
       "620       0.904425  457_e_a.wav      457  457   \n",
       "621       0.964798  457_f_a.wav      457  457   \n",
       "628       0.466249  464_a_a.wav      464  464   \n",
       "\n",
       "                                            VideoTitle                  Name  \\\n",
       "0    23 Ways to Nudge: Review of Technology-Mediate...           Ana Caraban   \n",
       "2    23 Ways to Nudge: Review of Technology-Mediate...           Ana Caraban   \n",
       "4    23 Ways to Nudge: Review of Technology-Mediate...           Ana Caraban   \n",
       "6    23 Ways to Nudge: Review of Technology-Mediate...           Ana Caraban   \n",
       "11   A Badge, Not a Barrier: Designing for- and Trh...         Caroline Pitt   \n",
       "..                                                 ...                   ...   \n",
       "617  Interferi: Gesture Sensing using On-Body Acous...      Yasha Iravantchi   \n",
       "619  Interferi: Gesture Sensing using On-Body Acous...      Yasha Iravantchi   \n",
       "620  Interferi: Gesture Sensing using On-Body Acous...      Yasha Iravantchi   \n",
       "621  Interferi: Gesture Sensing using On-Body Acous...      Yasha Iravantchi   \n",
       "628  Interpreting the Diversity in Subjective Judgm...  Jean-Bernard Martens   \n",
       "\n",
       "        Sex Academic Status      VideoID    IsNativeSpeaker SentenceType  \\\n",
       "0    Female    Grad Student  -U3Bo7KR108  Europ. Non-Native            a   \n",
       "2    Female    Grad Student  -U3Bo7KR108  Europ. Non-Native            a   \n",
       "4    Female    Grad Student  -U3Bo7KR108  Europ. Non-Native            a   \n",
       "6    Female    Grad Student  -U3Bo7KR108  Europ. Non-Native            a   \n",
       "11   Female    Grad Student  HxMSkH5ZpZI     Native Speaker            a   \n",
       "..      ...             ...          ...                ...          ...   \n",
       "617    Male    Grad Student  xBpBBpQh7GI     Native Speaker            a   \n",
       "619    Male    Grad Student  xBpBBpQh7GI     Native Speaker            a   \n",
       "620    Male    Grad Student  xBpBBpQh7GI     Native Speaker            a   \n",
       "621    Male    Grad Student  xBpBBpQh7GI     Native Speaker            a   \n",
       "628    Male             PhD  pS7CzHfawDU  Europ. Non-Native            a   \n",
       "\n",
       "     Normal Interest  \n",
       "0           0.017280  \n",
       "2           0.020835  \n",
       "4           0.002579  \n",
       "6           0.151726  \n",
       "11          0.658826  \n",
       "..               ...  \n",
       "617         0.026960  \n",
       "619         0.021222  \n",
       "620         0.095575  \n",
       "621         0.035202  \n",
       "628         0.533752  \n",
       "\n",
       "[195 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char_a = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'a']\n",
    "df_emotion_char_a = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'a']\n",
    "df_affect_char_a = df_affect_char.loc[df_affect_char['SentenceType'] == 'a']\n",
    "df_loi_char_a = df_loi_char.loc[df_loi_char['SentenceType'] == 'a']\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char_p = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'p'].copy()\n",
    "df_emotion_char_p = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'p'].copy()\n",
    "df_affect_char_p = df_affect_char.loc[df_affect_char['SentenceType'] == 'p'].copy()\n",
    "df_loi_char_p = df_loi_char.loc[df_loi_char['SentenceType'] == 'p'].copy()\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char_q = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'q']\n",
    "df_emotion_char_q = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'q']\n",
    "df_affect_char_q = df_affect_char.loc[df_affect_char['SentenceType'] == 'q']\n",
    "df_loi_char_q = df_loi_char.loc[df_loi_char['SentenceType'] == 'q']\n",
    "df_loi_char_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = df_emotion_char_p['Char_ID'].copy()\n",
    "IDs.drop_duplicates()\n",
    "\n",
    "# For presentations we need an aggregate, e.g. median for the presenters\n",
    "for i in IDs:\n",
    "    #first for emotion\n",
    "    for l in emotion_label:    \n",
    "        emo = df_emotion_char_p.loc[df_emotion_char_p.Char_ID == i,l]\n",
    "        emo_neu = hp.constructMedianSeries(emo)\n",
    "        df_emotion_char_p.loc[df_emotion_char_p.Char_ID == i,l] = emo_neu\n",
    "    #Then for affect\n",
    "    for l in affect_label:    \n",
    "        aff = df_affect_char_p.loc[df_affect_char_p.Char_ID == i,l]\n",
    "        aff_neu = hp.constructMedianSeries(aff)\n",
    "        df_affect_char_p.loc[df_affect_char_p.Char_ID == i,l] = aff_neu  \n",
    "    for l in loi_label:    \n",
    "        loi = df_loi_char_p.loc[df_loi_char_p.Char_ID == i,l]\n",
    "        loi_neu = hp.constructMedianSeries(loi)\n",
    "        df_loi_char_p.loc[df_loi_char_p.Char_ID == i,l] = loi_neu  \n",
    "    for l in ['Arousal', 'Valence']:    \n",
    "        arval = df_ar_val_char_p.loc[df_ar_val_char_p.Char_ID == i,l]\n",
    "        arval_neu = hp.constructMedianSeries(arval)\n",
    "        df_ar_val_char_p.loc[df_ar_val_char_p.Char_ID == i,l] = arval_neu \n",
    "        \n",
    "#Now let's drop the duplicate values, since we only need one row now per person\n",
    "df_emotion_char_p.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_affect_char_p.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_loi_char_p.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_ar_val_char_p.drop_duplicates(subset=['ID'], inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_label.extend(['Sex', 'Academic Status', 'IsNativeSpeaker'])\n",
    "affect_label.extend(['Sex', 'Academic Status', 'IsNativeSpeaker'])\n",
    "loi_label.extend(['Sex', 'Academic Status', 'IsNativeSpeaker'])\n",
    "\n",
    "df_emotion_char_p.columns = df_emotion_char_p.columns.map(lambda x: 'P_' + x if x in emotion_label else x)\n",
    "df_affect_char_p.columns = df_affect_char_p.columns.map(lambda x: 'P_' + x if x in affect_label else x)\n",
    "df_loi_char_p.columns = df_loi_char_p.columns.map(lambda x: 'P_' + x if x in loi_label else x)\n",
    "df_ar_val_char_p.columns = df_ar_val_char_p.columns.map(lambda x: 'P_' + x if x in ['Arousal', 'Valence', 'Sex', 'Academic Status', 'IsNativeSpeaker'] else x)\n",
    "\n",
    "df_emotion_char_a.columns = df_emotion_char_a.columns.map(lambda x: 'A_' + x if x in emotion_label else x)\n",
    "df_affect_char_a.columns = df_affect_char_a.columns.map(lambda x: 'A_' + x if x in affect_label else x)\n",
    "df_loi_char_a.columns = df_loi_char_a.columns.map(lambda x: 'A_' + x if x in loi_label else x)\n",
    "df_ar_val_char_a.columns = df_ar_val_char_a.columns.map(lambda x: 'A_' + x if x in ['Arousal', 'Valence', 'Sex', 'Academic Status', 'IsNativeSpeaker'] else x)\n",
    "\n",
    "df_emotion_char_q.columns = df_emotion_char_q.columns.map(lambda x: 'Q_' + x if x in emotion_label else x)\n",
    "df_affect_char_q.columns = df_affect_char_q.columns.map(lambda x: 'Q_' + x if x in affect_label else x)\n",
    "df_loi_char_q.columns = df_loi_char_q.columns.map(lambda x: 'Q_' + x if x in loi_label else x)\n",
    "df_ar_val_char_q.columns = df_ar_val_char_q.columns.map(lambda x: 'Q_' + x if x in ['Arousal', 'Valence', 'Sex', 'Academic Status', 'IsNativeSpeaker'] else x)\n",
    "\n",
    "df_emotion_char_p = df_emotion_char_p.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType'], axis = 1)\n",
    "df_affect_char_p = df_affect_char_p.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType'], axis = 1)\n",
    "df_loi_char_p = df_loi_char_p.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType'], axis = 1)\n",
    "df_ar_val_char_p = df_ar_val_char_p.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType'], axis = 1)\n",
    "\n",
    "df_emotion_char_a = df_emotion_char_a.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType'], axis = 1)\n",
    "df_affect_char_a = df_affect_char_a.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType'], axis = 1)\n",
    "df_loi_char_a = df_loi_char_a.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType'], axis = 1)\n",
    "df_ar_val_char_a = df_ar_val_char_a.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType'], axis = 1)\n",
    "\n",
    "df_emotion_char_q = df_emotion_char_q.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType'], axis = 1)\n",
    "df_affect_char_q = df_affect_char_q.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType'], axis = 1)\n",
    "df_loi_char_q = df_loi_char_q.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType'], axis = 1)\n",
    "df_ar_val_char_q = df_ar_val_char_q.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do: Merge Data Frames; First Question and Presentation, then answer and question\n",
    "ar_val_char = df_ar_val_char_q.merge(df_ar_val_char_p, how = 'left', left_on='VideoID', right_on='VideoID')\n",
    "loi_char = df_loi_char_q.merge(df_loi_char_p, how = 'left', left_on='VideoID', right_on='VideoID')\n",
    "affect_char = df_affect_char_q.merge(df_affect_char_p, how = 'left', left_on='VideoID', right_on='VideoID')\n",
    "emotion_char = df_emotion_char_q.merge(df_emotion_char_p, how = 'left', left_on='VideoID', right_on='VideoID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar_val_char_a.reset_index(drop = True, inplace = True)\n",
    "df_ar_val_char_q.reset_index(drop = True, inplace = True)\n",
    "arval = pd.concat([ar_val_char, df_ar_val_char_a], axis = 1)\n",
    "\n",
    "df_loi_char_a.reset_index(drop = True, inplace = True)\n",
    "df_loi_char_q.reset_index(drop = True, inplace = True)\n",
    "loi = pd.concat([loi_char, df_loi_char_a], axis = 1)\n",
    "\n",
    "df_affect_char_a.reset_index(drop = True, inplace = True)\n",
    "df_affect_char_q.reset_index(drop = True, inplace = True)\n",
    "affect = pd.concat([affect_char, df_affect_char_a], axis = 1)\n",
    "\n",
    "df_emotion_char_a.reset_index(drop = True, inplace = True)\n",
    "df_emotion_char_q.reset_index(drop = True, inplace = True)\n",
    "emotion = pd.concat([emotion_char, df_emotion_char_a], axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
