{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import sklearn.preprocessing as pp\n",
    "import statsmodels.api as sm\n",
    "#import nltk\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import Helper as hp\n",
    "\n",
    "#Load Data\n",
    "data = pd.read_csv(\"CHI_2019_FULL.csv\")\n",
    "\n",
    "#Set Labels \n",
    "emotion_label = ['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness']\n",
    "affect_label = ['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired']\n",
    "loi_label = ['Disinterest', 'Normal', 'High Interest']\n",
    "\n",
    "#Get specific data and save it into new data frames\n",
    "# We use the pandas .copy(deep=True) function to prevent the SettingWithCopyWarning we would otherwise get. Since we do\n",
    "# not write, but only read from the data, the warning does not affect the data frames\n",
    "df_emotion = data[['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness', 'Filename']].copy(deep=True)\n",
    "df_affect = data[['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired', 'Filename']].copy(deep=True)\n",
    "df_loi = data[['Disinterest', 'Normal', 'High Interest', 'Filename']].copy(deep=True)\n",
    "df_ar_val = data[['Arousal', 'Valence', 'Filename']].copy(deep=True)\n",
    "#For further usage, we want to append the CharacterID as a column, which is saved with other information in the filename\n",
    "#Since we only want the digits, we can remove all non-digit characters of the filename column and append the column to the df\n",
    "\n",
    "df_emotion['Char_ID'] = df_emotion['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_affect['Char_ID'] = df_affect['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_loi['Char_ID'] = df_loi['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "\n",
    "#Load data about speakers\n",
    "char_data = pd.read_csv(\"CHI_2019_CharacterData.csv\")  \n",
    "char_data.replace({'Male': 0.0, 'Female': 1.0}, inplace = True)\n",
    "\n",
    "#Join above tables and Character Tables\n",
    "#To Join DataFrames we have to cast the column on which we want to join to int, so that both columns have the same data type\n",
    "char_data['ID'] = char_data['ID'].astype(int)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Char_ID'].astype(int)\n",
    "df_emotion['Char_ID'] = df_emotion['Char_ID'].astype(int)\n",
    "df_affect['Char_ID'] = df_affect['Char_ID'].astype(int)\n",
    "df_loi['Char_ID'] = df_loi['Char_ID'].astype(int)\n",
    "\n",
    "#Save new data frames\n",
    "df_ar_val_char = df_ar_val.merge(char_data, how = 'left', left_on='Char_ID', right_on='ID')\n",
    "df_emotion_char = df_emotion.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_affect_char = df_affect.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_loi_char = df_loi.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "\n",
    "#Now, we only want to have data containing information about the answers\n",
    "#For that we need to extract from the filename column, whether the file was part of an answer\n",
    "#a = answer, p = presentation, q = question\n",
    "#sentence_type should be the same for all tables, but just to be sure\n",
    "arval_sentence_type = df_ar_val_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_ar_val_char['SentenceType'] = arval_sentence_type\n",
    "emo_sentence_type = df_emotion_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_emotion_char['SentenceType'] = emo_sentence_type\n",
    "aff_sentence_type = df_affect_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_affect_char['SentenceType'] = aff_sentence_type\n",
    "loi_sentence_type = df_loi_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_loi_char['SentenceType'] = loi_sentence_type\n",
    "\n",
    "#For affect, we will have to drop the intoxication column and thus we will re-normalize the other values\n",
    "affect_label.remove('Intoxicated')\n",
    "df_affect_char = df_affect_char.drop(['Intoxicated'], axis = 1)\n",
    "norm_test = pp.normalize(df_affect_char[affect_label], norm = 'l1')\n",
    "df_affect_char[affect_label] = norm_test\n",
    "\n",
    "df_loi_char['Normal Interest'] = df_loi_char['Disinterest'] + df_loi_char['Normal']\n",
    "df_loi_char = df_loi_char.drop(['Disinterest', 'Normal'], axis = 1)\n",
    "loi_label = ['Normal Interest', 'High Interest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char_a = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'a']\n",
    "df_emotion_char_a = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'a']\n",
    "df_affect_char_a = df_affect_char.loc[df_affect_char['SentenceType'] == 'a']\n",
    "df_loi_char_a = df_loi_char.loc[df_loi_char['SentenceType'] == 'a']\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char_p = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'p'].copy()\n",
    "df_emotion_char_p = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'p'].copy()\n",
    "df_affect_char_p = df_affect_char.loc[df_affect_char['SentenceType'] == 'p'].copy()\n",
    "df_loi_char_p = df_loi_char.loc[df_loi_char['SentenceType'] == 'p'].copy()\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char_q = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'q']\n",
    "df_emotion_char_q = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'q']\n",
    "df_affect_char_q = df_affect_char.loc[df_affect_char['SentenceType'] == 'q']\n",
    "df_loi_char_q = df_loi_char.loc[df_loi_char['SentenceType'] == 'q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = df_emotion_char_p['Char_ID'].copy()\n",
    "IDs.drop_duplicates()\n",
    "\n",
    "# For presentations we need an aggregate, e.g. median for the presenters\n",
    "for i in IDs:\n",
    "    #first for emotion\n",
    "    for l in emotion_label:    \n",
    "        emo = df_emotion_char_p.loc[df_emotion_char_p.Char_ID == i,l]\n",
    "        emo_neu = hp.constructMedianSeries(emo)\n",
    "        df_emotion_char_p.loc[df_emotion_char_p.Char_ID == i,l] = emo_neu\n",
    "    #Then for affect\n",
    "    for l in affect_label:    \n",
    "        aff = df_affect_char_p.loc[df_affect_char_p.Char_ID == i,l]\n",
    "        aff_neu = hp.constructMedianSeries(aff)\n",
    "        df_affect_char_p.loc[df_affect_char_p.Char_ID == i,l] = aff_neu  \n",
    "    for l in loi_label:    \n",
    "        loi = df_loi_char_p.loc[df_loi_char_p.Char_ID == i,l]\n",
    "        loi_neu = hp.constructMedianSeries(loi)\n",
    "        df_loi_char_p.loc[df_loi_char_p.Char_ID == i,l] = loi_neu  \n",
    "    for l in ['Arousal', 'Valence']:    \n",
    "        arval = df_ar_val_char_p.loc[df_ar_val_char_p.Char_ID == i,l]\n",
    "        arval_neu = hp.constructMedianSeries(arval)\n",
    "        df_ar_val_char_p.loc[df_ar_val_char_p.Char_ID == i,l] = arval_neu \n",
    "        \n",
    "#Now let's drop the duplicate values, since we only need one row now per person\n",
    "df_emotion_char_p.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_affect_char_p.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_loi_char_p.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_ar_val_char_p.drop_duplicates(subset=['ID'], inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_label.extend(['Sex', 'Academic Status', 'IsNativeSpeaker'])\n",
    "affect_label.extend(['Sex', 'Academic Status', 'IsNativeSpeaker'])\n",
    "loi_label.extend(['Sex', 'Academic Status', 'IsNativeSpeaker'])\n",
    "\n",
    "df_emotion_char_p.columns = df_emotion_char_p.columns.map(lambda x: 'P_' + x if x in emotion_label else x)\n",
    "df_affect_char_p.columns = df_affect_char_p.columns.map(lambda x: 'P_' + x if x in affect_label else x)\n",
    "df_loi_char_p.columns = df_loi_char_p.columns.map(lambda x: 'P_' + x if x in loi_label else x)\n",
    "df_ar_val_char_p.columns = df_ar_val_char_p.columns.map(lambda x: 'P_' + x if x in ['Arousal', 'Valence', 'Sex', 'Academic Status', 'IsNativeSpeaker'] else x)\n",
    "\n",
    "df_emotion_char_a.columns = df_emotion_char_a.columns.map(lambda x: 'A_' + x if x in emotion_label else x)\n",
    "df_affect_char_a.columns = df_affect_char_a.columns.map(lambda x: 'A_' + x if x in affect_label else x)\n",
    "df_loi_char_a.columns = df_loi_char_a.columns.map(lambda x: 'A_' + x if x in loi_label else x)\n",
    "df_ar_val_char_a.columns = df_ar_val_char_a.columns.map(lambda x: 'A_' + x if x in ['Arousal', 'Valence', 'Sex', 'Academic Status', 'IsNativeSpeaker'] else x)\n",
    "\n",
    "df_emotion_char_q.columns = df_emotion_char_q.columns.map(lambda x: 'Q_' + x if x in emotion_label else x)\n",
    "df_affect_char_q.columns = df_affect_char_q.columns.map(lambda x: 'Q_' + x if x in affect_label else x)\n",
    "df_loi_char_q.columns = df_loi_char_q.columns.map(lambda x: 'Q_' + x if x in loi_label else x)\n",
    "df_ar_val_char_q.columns = df_ar_val_char_q.columns.map(lambda x: 'Q_' + x if x in ['Arousal', 'Valence', 'Sex', 'Academic Status', 'IsNativeSpeaker'] else x)\n",
    "\n",
    "df_emotion_char_p = df_emotion_char_p.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_affect_char_p = df_affect_char_p.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_loi_char_p = df_loi_char_p.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_ar_val_char_p = df_ar_val_char_p.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "\n",
    "df_emotion_char_a = df_emotion_char_a.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_affect_char_a = df_affect_char_a.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_loi_char_a = df_loi_char_a.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_ar_val_char_a = df_ar_val_char_a.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "\n",
    "df_emotion_char_q = df_emotion_char_q.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_affect_char_q = df_affect_char_q.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_loi_char_q = df_loi_char_q.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_ar_val_char_q = df_ar_val_char_q.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do: Merge Data Frames; First Question and Presentation, then answer and question\n",
    "ar_val_char = df_ar_val_char_q.merge(df_ar_val_char_p, how = 'left', left_on='VideoID', right_on='VideoID')\n",
    "loi_char = df_loi_char_q.merge(df_loi_char_p, how = 'left', left_on='VideoID', right_on='VideoID')\n",
    "affect_char = df_affect_char_q.merge(df_affect_char_p, how = 'left', left_on='VideoID', right_on='VideoID')\n",
    "emotion_char = df_emotion_char_q.merge(df_emotion_char_p, how = 'left', left_on='VideoID', right_on='VideoID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_Anger</th>\n",
       "      <th>Q_Boredom</th>\n",
       "      <th>Q_Disgust</th>\n",
       "      <th>Q_Fear</th>\n",
       "      <th>Q_Happiness</th>\n",
       "      <th>Q_Emo_Neutral</th>\n",
       "      <th>Q_Sadness</th>\n",
       "      <th>Q_Sex</th>\n",
       "      <th>P_Anger</th>\n",
       "      <th>P_Boredom</th>\n",
       "      <th>...</th>\n",
       "      <th>P_Emo_Neutral</th>\n",
       "      <th>P_Sadness</th>\n",
       "      <th>A_Anger</th>\n",
       "      <th>A_Boredom</th>\n",
       "      <th>A_Disgust</th>\n",
       "      <th>A_Fear</th>\n",
       "      <th>A_Happiness</th>\n",
       "      <th>A_Emo_Neutral</th>\n",
       "      <th>A_Sadness</th>\n",
       "      <th>A_Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.959199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.144437</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.848510</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.152280</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.827121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.006929</td>\n",
       "      <td>0.163217</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.823060</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>0.014762</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.970133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.071035</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.927761</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.151633</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.840536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>0.009743</td>\n",
       "      <td>0.036144</td>\n",
       "      <td>0.171343</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>0.003127</td>\n",
       "      <td>0.769477</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.043610</td>\n",
       "      <td>0.119756</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>0.803436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.016413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.921682</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.015522</td>\n",
       "      <td>0.088884</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.886391</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.052537</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.925487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>0.210241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028904</td>\n",
       "      <td>0.413051</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.012959</td>\n",
       "      <td>0.096147</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.886665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.966359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>0.210241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028904</td>\n",
       "      <td>0.413051</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.013194</td>\n",
       "      <td>0.072456</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.907778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.020095</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.960965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>0.210241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028904</td>\n",
       "      <td>0.413051</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.088773</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.893822</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.992159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>0.210241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028904</td>\n",
       "      <td>0.413051</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>0.194922</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.006281</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.741597</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.615869</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.375736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.880614</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>0.032786</td>\n",
       "      <td>0.062670</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.886593</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q_Anger  Q_Boredom  Q_Disgust    Q_Fear  Q_Happiness  Q_Emo_Neutral  \\\n",
       "0    0.002253   0.005161   0.028762  0.002877     0.001428       0.000320   \n",
       "1    0.007885   0.004149   0.152280  0.004555     0.003764       0.000246   \n",
       "2    0.003784   0.006456   0.014762  0.002672     0.001569       0.000624   \n",
       "3    0.004143   0.000882   0.151633  0.000632     0.002108       0.000065   \n",
       "4    0.008246   0.043610   0.119756  0.005309     0.007007       0.012636   \n",
       "..        ...        ...        ...       ...          ...            ...   \n",
       "190  0.001621   0.052537   0.003183  0.011076     0.002419       0.003676   \n",
       "191  0.002563   0.004989   0.018547  0.005339     0.001827       0.000377   \n",
       "192  0.001638   0.009019   0.005033  0.020095     0.002618       0.000631   \n",
       "193  0.000195   0.004939   0.001564  0.000372     0.000364       0.000408   \n",
       "194  0.004666   0.001716   0.615869  0.000343     0.001429       0.000241   \n",
       "\n",
       "     Q_Sadness  Q_Sex   P_Anger  P_Boredom  ...  P_Emo_Neutral  P_Sadness  \\\n",
       "0     0.959199    0.0  0.005758   0.026247  ...       0.003056   0.550885   \n",
       "1     0.827121    1.0  0.005758   0.026247  ...       0.003056   0.550885   \n",
       "2     0.970133    0.0  0.005758   0.026247  ...       0.003056   0.550885   \n",
       "3     0.840536    0.0  0.005758   0.026247  ...       0.003056   0.550885   \n",
       "4     0.803436    0.0  0.005346   0.016413  ...       0.002316   0.921682   \n",
       "..         ...    ...       ...        ...  ...            ...        ...   \n",
       "190   0.925487    0.0  0.051643   0.210241  ...       0.028904   0.413051   \n",
       "191   0.966359    0.0  0.051643   0.210241  ...       0.028904   0.413051   \n",
       "192   0.960965    0.0  0.051643   0.210241  ...       0.028904   0.413051   \n",
       "193   0.992159    0.0  0.051643   0.210241  ...       0.028904   0.413051   \n",
       "194   0.375736    0.0  0.004142   0.021997  ...       0.003280   0.880614   \n",
       "\n",
       "      A_Anger  A_Boredom  A_Disgust    A_Fear  A_Happiness  A_Emo_Neutral  \\\n",
       "0    0.002512   0.001862   0.144437  0.001235     0.001340       0.000104   \n",
       "1    0.003424   0.006929   0.163217  0.001225     0.001768       0.000377   \n",
       "2    0.000404   0.000340   0.071035  0.000072     0.000371       0.000017   \n",
       "3    0.009743   0.036144   0.171343  0.004482     0.005685       0.003127   \n",
       "4    0.004123   0.015522   0.088884  0.002106     0.001884       0.001089   \n",
       "..        ...        ...        ...       ...          ...            ...   \n",
       "190  0.001201   0.012959   0.096147  0.001087     0.001077       0.000864   \n",
       "191  0.002432   0.013194   0.072456  0.001132     0.002074       0.000934   \n",
       "192  0.001550   0.012946   0.088773  0.001038     0.001073       0.000799   \n",
       "193  0.010152   0.039024   0.194922  0.003860     0.006281       0.004162   \n",
       "194  0.006230   0.032786   0.062670  0.003007     0.004283       0.004431   \n",
       "\n",
       "     A_Sadness  A_Sex  \n",
       "0     0.848510    1.0  \n",
       "1     0.823060    1.0  \n",
       "2     0.927761    1.0  \n",
       "3     0.769477    1.0  \n",
       "4     0.886391    1.0  \n",
       "..         ...    ...  \n",
       "190   0.886665    0.0  \n",
       "191   0.907778    0.0  \n",
       "192   0.893822    0.0  \n",
       "193   0.741597    0.0  \n",
       "194   0.886593    0.0  \n",
       "\n",
       "[195 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ar_val_char_a.reset_index(drop = True, inplace = True)\n",
    "df_ar_val_char_q.reset_index(drop = True, inplace = True)\n",
    "arval = pd.concat([ar_val_char, df_ar_val_char_a], axis = 1)\n",
    "arval.drop(['ID_x', 'ID_y', 'VideoID', 'ID', 'Q_Academic Status','Q_IsNativeSpeaker', 'A_IsNativeSpeaker', 'A_Academic Status', 'P_Academic Status', 'P_IsNativeSpeaker', 'P_Sex'], axis = 1, inplace = True)\n",
    "\n",
    "df_loi_char_a.reset_index(drop = True, inplace = True)\n",
    "df_loi_char_q.reset_index(drop = True, inplace = True)\n",
    "loi = pd.concat([loi_char, df_loi_char_a], axis = 1)\n",
    "loi.drop(['ID_x', 'ID_y', 'VideoID', 'ID', 'Q_Academic Status','Q_IsNativeSpeaker', 'A_IsNativeSpeaker', 'A_Academic Status', 'P_Academic Status', 'P_IsNativeSpeaker', 'P_Sex'], axis = 1, inplace = True)\n",
    "\n",
    "df_affect_char_a.reset_index(drop = True, inplace = True)\n",
    "df_affect_char_q.reset_index(drop = True, inplace = True)\n",
    "affect = pd.concat([affect_char, df_affect_char_a], axis = 1)\n",
    "affect.drop(['ID_x', 'ID_y', 'VideoID', 'ID', 'Q_Academic Status','Q_IsNativeSpeaker', 'A_IsNativeSpeaker', 'A_Academic Status', 'P_Academic Status', 'P_IsNativeSpeaker', 'P_Sex'], axis = 1, inplace = True)\n",
    "\n",
    "df_emotion_char_a.reset_index(drop = True, inplace = True)\n",
    "df_emotion_char_q.reset_index(drop = True, inplace = True)\n",
    "emotion = pd.concat([emotion_char, df_emotion_char_a], axis = 1)\n",
    "emotion.drop(['ID_x', 'ID_y', 'VideoID', 'ID', 'Q_Academic Status','Q_IsNativeSpeaker', 'A_IsNativeSpeaker', 'A_Academic Status', 'P_Academic Status', 'P_IsNativeSpeaker', 'P_Sex'], axis = 1, inplace = True)\n",
    "#Now we have our dataframe ready for logsitic regression:\n",
    "#Each row resembles an interaction between one question, the corresponding answer and the median of the presenter\n",
    "#We could do this since both dataframes are default sorted by filenames (emotion_char and df_emotion_char_a)\n",
    "#So each question is in the same line as the corresponding answer\n",
    "emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have constructed our data frame, let's do Logistic Regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.353546\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>A_Sex</td>      <th>  No. Observations:  </th>  <td>   195</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   165</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    29</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 18 Nov 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.4897</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:30:29</td>     <th>  Log-Likelihood:    </th> <td> -68.942</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>False</td>      <th>  LL-Null:           </th> <td> -135.10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.797e-15</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td> -234.5379</td> <td> 4.44e+05</td> <td>   -0.001</td> <td> 1.000</td> <td> -8.7e+05</td> <td> 8.69e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex</th>               <td> -568.2432</td> <td> 6.75e+05</td> <td>   -0.001</td> <td> 0.999</td> <td>-1.32e+06</td> <td> 1.32e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Anger</th>             <td>  295.2443</td> <td> 3.86e+05</td> <td>    0.001</td> <td> 0.999</td> <td>-7.57e+05</td> <td> 7.58e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Boredom</th>           <td>  616.0915</td> <td> 3.86e+05</td> <td>    0.002</td> <td> 0.999</td> <td>-7.57e+05</td> <td> 7.58e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Disgust</th>           <td>  642.6281</td> <td> 3.86e+05</td> <td>    0.002</td> <td> 0.999</td> <td>-7.57e+05</td> <td> 7.58e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sadness</th>           <td>  639.6734</td> <td> 3.86e+05</td> <td>    0.002</td> <td> 0.999</td> <td>-7.57e+05</td> <td> 7.58e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Fear</th>              <td>  545.3659</td> <td> 3.86e+05</td> <td>    0.001</td> <td> 0.999</td> <td>-7.57e+05</td> <td> 7.58e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Happiness</th>         <td> 1277.0616</td> <td> 3.86e+05</td> <td>    0.003</td> <td> 0.997</td> <td>-7.56e+05</td> <td> 7.59e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Emo_Neutral</th>       <td>  693.0392</td> <td> 3.86e+05</td> <td>    0.002</td> <td> 0.999</td> <td>-7.57e+05</td> <td> 7.58e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Anger</th>       <td>  546.1131</td> <td> 6.75e+05</td> <td>    0.001</td> <td> 0.999</td> <td>-1.32e+06</td> <td> 1.32e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Boredom</th>     <td>  617.7946</td> <td> 6.75e+05</td> <td>    0.001</td> <td> 0.999</td> <td>-1.32e+06</td> <td> 1.32e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Disgust</th>     <td>  569.4702</td> <td> 6.75e+05</td> <td>    0.001</td> <td> 0.999</td> <td>-1.32e+06</td> <td> 1.32e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Sadness</th>     <td>  569.0868</td> <td> 6.75e+05</td> <td>    0.001</td> <td> 0.999</td> <td>-1.32e+06</td> <td> 1.32e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Fear</th>        <td>  345.2463</td> <td> 6.75e+05</td> <td>    0.001</td> <td> 1.000</td> <td>-1.32e+06</td> <td> 1.32e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Happiness</th>   <td>  690.7780</td> <td> 6.75e+05</td> <td>    0.001</td> <td> 0.999</td> <td>-1.32e+06</td> <td> 1.32e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Emo_Neutral</th> <td>  311.5055</td> <td> 6.75e+05</td> <td>    0.000</td> <td> 1.000</td> <td>-1.32e+06</td> <td> 1.32e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Anger</th>             <td> -369.4200</td> <td>    3e+05</td> <td>   -0.001</td> <td> 0.999</td> <td>-5.88e+05</td> <td> 5.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Boredom</th>           <td> -398.5560</td> <td>    3e+05</td> <td>   -0.001</td> <td> 0.999</td> <td>-5.88e+05</td> <td> 5.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Disgust</th>           <td> -405.4643</td> <td>    3e+05</td> <td>   -0.001</td> <td> 0.999</td> <td>-5.88e+05</td> <td> 5.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Fear</th>              <td> -386.1556</td> <td>    3e+05</td> <td>   -0.001</td> <td> 0.999</td> <td>-5.88e+05</td> <td> 5.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Happiness</th>         <td> -501.1114</td> <td>    3e+05</td> <td>   -0.002</td> <td> 0.999</td> <td>-5.88e+05</td> <td> 5.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Emo_Neutral</th>       <td> -487.9862</td> <td>    3e+05</td> <td>   -0.002</td> <td> 0.999</td> <td>-5.88e+05</td> <td> 5.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Sadness</th>           <td> -410.0562</td> <td>    3e+05</td> <td>   -0.001</td> <td> 0.999</td> <td>-5.88e+05</td> <td> 5.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Anger</th>             <td> -116.6396</td> <td>   35.872</td> <td>   -3.252</td> <td> 0.001</td> <td> -186.947</td> <td>  -46.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Boredom</th>           <td>  -90.2972</td> <td>   29.386</td> <td>   -3.073</td> <td> 0.002</td> <td> -147.892</td> <td>  -32.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Disgust</th>           <td>   12.7982</td> <td>    4.418</td> <td>    2.896</td> <td> 0.004</td> <td>    4.138</td> <td>   21.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Fear</th>              <td>  408.8604</td> <td>  138.745</td> <td>    2.947</td> <td> 0.003</td> <td>  136.925</td> <td>  680.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Happiness</th>         <td>   60.8751</td> <td>  153.227</td> <td>    0.397</td> <td> 0.691</td> <td> -239.445</td> <td>  361.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Sadness</th>           <td>    2.9880</td> <td>    3.201</td> <td>    0.933</td> <td> 0.351</td> <td>   -3.286</td> <td>    9.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Emo_Neutral</th>       <td>  261.3865</td> <td>   99.885</td> <td>    2.617</td> <td> 0.009</td> <td>   65.616</td> <td>  457.157</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  A_Sex   No. Observations:                  195\n",
       "Model:                          Logit   Df Residuals:                      165\n",
       "Method:                           MLE   Df Model:                           29\n",
       "Date:                Wed, 18 Nov 2020   Pseudo R-squ.:                  0.4897\n",
       "Time:                        13:30:29   Log-Likelihood:                -68.942\n",
       "converged:                      False   LL-Null:                       -135.10\n",
       "                                        LLR p-value:                 3.797e-15\n",
       "=======================================================================================\n",
       "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Intercept            -234.5379   4.44e+05     -0.001      1.000    -8.7e+05    8.69e+05\n",
       "Q_Sex                -568.2432   6.75e+05     -0.001      0.999   -1.32e+06    1.32e+06\n",
       "Q_Anger               295.2443   3.86e+05      0.001      0.999   -7.57e+05    7.58e+05\n",
       "Q_Boredom             616.0915   3.86e+05      0.002      0.999   -7.57e+05    7.58e+05\n",
       "Q_Disgust             642.6281   3.86e+05      0.002      0.999   -7.57e+05    7.58e+05\n",
       "Q_Sadness             639.6734   3.86e+05      0.002      0.999   -7.57e+05    7.58e+05\n",
       "Q_Fear                545.3659   3.86e+05      0.001      0.999   -7.57e+05    7.58e+05\n",
       "Q_Happiness          1277.0616   3.86e+05      0.003      0.997   -7.56e+05    7.59e+05\n",
       "Q_Emo_Neutral         693.0392   3.86e+05      0.002      0.999   -7.57e+05    7.58e+05\n",
       "Q_Sex:Q_Anger         546.1131   6.75e+05      0.001      0.999   -1.32e+06    1.32e+06\n",
       "Q_Sex:Q_Boredom       617.7946   6.75e+05      0.001      0.999   -1.32e+06    1.32e+06\n",
       "Q_Sex:Q_Disgust       569.4702   6.75e+05      0.001      0.999   -1.32e+06    1.32e+06\n",
       "Q_Sex:Q_Sadness       569.0868   6.75e+05      0.001      0.999   -1.32e+06    1.32e+06\n",
       "Q_Sex:Q_Fear          345.2463   6.75e+05      0.001      1.000   -1.32e+06    1.32e+06\n",
       "Q_Sex:Q_Happiness     690.7780   6.75e+05      0.001      0.999   -1.32e+06    1.32e+06\n",
       "Q_Sex:Q_Emo_Neutral   311.5055   6.75e+05      0.000      1.000   -1.32e+06    1.32e+06\n",
       "A_Anger              -369.4200      3e+05     -0.001      0.999   -5.88e+05    5.87e+05\n",
       "A_Boredom            -398.5560      3e+05     -0.001      0.999   -5.88e+05    5.87e+05\n",
       "A_Disgust            -405.4643      3e+05     -0.001      0.999   -5.88e+05    5.87e+05\n",
       "A_Fear               -386.1556      3e+05     -0.001      0.999   -5.88e+05    5.87e+05\n",
       "A_Happiness          -501.1114      3e+05     -0.002      0.999   -5.88e+05    5.87e+05\n",
       "A_Emo_Neutral        -487.9862      3e+05     -0.002      0.999   -5.88e+05    5.87e+05\n",
       "A_Sadness            -410.0562      3e+05     -0.001      0.999   -5.88e+05    5.87e+05\n",
       "P_Anger              -116.6396     35.872     -3.252      0.001    -186.947     -46.332\n",
       "P_Boredom             -90.2972     29.386     -3.073      0.002    -147.892     -32.702\n",
       "P_Disgust              12.7982      4.418      2.896      0.004       4.138      21.458\n",
       "P_Fear                408.8604    138.745      2.947      0.003     136.925     680.796\n",
       "P_Happiness            60.8751    153.227      0.397      0.691    -239.445     361.195\n",
       "P_Sadness               2.9880      3.201      0.933      0.351      -3.286       9.262\n",
       "P_Emo_Neutral         261.3865     99.885      2.617      0.009      65.616     457.157\n",
       "=======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Emotion')\n",
    "emo_sex_model = smf.logit(\"A_Sex ~ Q_Sex * (Q_Anger + Q_Boredom + Q_Disgust + Q_Sadness + Q_Fear + Q_Happiness + Q_Emo_Neutral) + A_Anger + A_Boredom + A_Disgust + A_Fear + A_Happiness + A_Emo_Neutral + A_Sadness + P_Anger + P_Boredom + P_Disgust + P_Fear + P_Happiness + P_Sadness + P_Emo_Neutral\", data = emotion)\n",
    "emotion_res = emo_sex_model.fit()\n",
    "emotion_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affect\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.523281\n",
      "         Iterations 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1092: RuntimeWarning: invalid value encountered in sqrt\n",
      "  bse_ = np.sqrt(np.diag(self.cov_params()))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>A_Sex</td>      <th>  No. Observations:  </th>  <td>   195</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   176</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    18</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 18 Nov 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.2447</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:35:04</td>     <th>  Log-Likelihood:    </th> <td> -102.04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -135.10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>2.025e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td>   -4.1108</td> <td> 4.71e+06</td> <td>-8.74e-07</td> <td> 1.000</td> <td>-9.22e+06</td> <td> 9.22e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex</th>               <td>    3.9463</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Aggressiv</th>         <td>   -1.9509</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Cheerful</th>          <td>   -3.2345</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Nervous</th>           <td>    3.7687</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Aff_Neutral</th>       <td>   -2.3524</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Tired</th>             <td>   -0.9246</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Aggressiv</th>   <td>   -8.8430</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Cheerful</th>    <td>   -6.5425</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Nervous</th>     <td>  -18.3202</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Aff_Neutral</th> <td>   43.5614</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Tired</th>       <td>   -5.3402</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Aggressiv</th>         <td>    0.5253</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Cheerful</th>          <td>   -7.2925</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Nervous</th>           <td>   -5.8813</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Aff_Neutral</th>       <td>   13.4724</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Tired</th>             <td>   -5.0318</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Aggressiv</th>         <td>   15.7319</td> <td>    6.187</td> <td>    2.543</td> <td> 0.011</td> <td>    3.605</td> <td>   27.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Cheerful</th>          <td>    7.3158</td> <td>    5.826</td> <td>    1.256</td> <td> 0.209</td> <td>   -4.102</td> <td>   18.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Nervous</th>           <td>   58.2315</td> <td>   28.043</td> <td>    2.076</td> <td> 0.038</td> <td>    3.268</td> <td>  113.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Aff_Neutral</th>       <td>  -12.7710</td> <td>   10.875</td> <td>   -1.174</td> <td> 0.240</td> <td>  -34.085</td> <td>    8.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Tired</th>             <td>    8.7923</td> <td>    5.725</td> <td>    1.536</td> <td> 0.125</td> <td>   -2.428</td> <td>   20.012</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  A_Sex   No. Observations:                  195\n",
       "Model:                          Logit   Df Residuals:                      176\n",
       "Method:                           MLE   Df Model:                           18\n",
       "Date:                Wed, 18 Nov 2020   Pseudo R-squ.:                  0.2447\n",
       "Time:                        16:35:04   Log-Likelihood:                -102.04\n",
       "converged:                       True   LL-Null:                       -135.10\n",
       "                                        LLR p-value:                 2.025e-07\n",
       "=======================================================================================\n",
       "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------\n",
       "Intercept              -4.1108   4.71e+06  -8.74e-07      1.000   -9.22e+06    9.22e+06\n",
       "Q_Sex                   3.9463        nan        nan        nan         nan         nan\n",
       "Q_Aggressiv            -1.9509        nan        nan        nan         nan         nan\n",
       "Q_Cheerful             -3.2345        nan        nan        nan         nan         nan\n",
       "Q_Nervous               3.7687        nan        nan        nan         nan         nan\n",
       "Q_Aff_Neutral          -2.3524        nan        nan        nan         nan         nan\n",
       "Q_Tired                -0.9246        nan        nan        nan         nan         nan\n",
       "Q_Sex:Q_Aggressiv      -8.8430        nan        nan        nan         nan         nan\n",
       "Q_Sex:Q_Cheerful       -6.5425        nan        nan        nan         nan         nan\n",
       "Q_Sex:Q_Nervous       -18.3202        nan        nan        nan         nan         nan\n",
       "Q_Sex:Q_Aff_Neutral    43.5614        nan        nan        nan         nan         nan\n",
       "Q_Sex:Q_Tired          -5.3402        nan        nan        nan         nan         nan\n",
       "A_Aggressiv             0.5253        nan        nan        nan         nan         nan\n",
       "A_Cheerful             -7.2925        nan        nan        nan         nan         nan\n",
       "A_Nervous              -5.8813        nan        nan        nan         nan         nan\n",
       "A_Aff_Neutral          13.4724        nan        nan        nan         nan         nan\n",
       "A_Tired                -5.0318        nan        nan        nan         nan         nan\n",
       "P_Aggressiv            15.7319      6.187      2.543      0.011       3.605      27.859\n",
       "P_Cheerful              7.3158      5.826      1.256      0.209      -4.102      18.734\n",
       "P_Nervous              58.2315     28.043      2.076      0.038       3.268     113.195\n",
       "P_Aff_Neutral         -12.7710     10.875     -1.174      0.240     -34.085       8.543\n",
       "P_Tired                 8.7923      5.725      1.536      0.125      -2.428      20.012\n",
       "=======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Affect')\n",
    "aff_sex_model = smf.logit(\"A_Sex ~ Q_Sex * (Q_Aggressiv + Q_Cheerful + Q_Nervous + Q_Aff_Neutral + Q_Tired) + A_Aggressiv + A_Cheerful + A_Nervous + A_Aff_Neutral + A_Tired + P_Aggressiv + P_Cheerful + P_Nervous + P_Aff_Neutral + P_Tired\", data = affect)\n",
    "affect_res = aff_sex_model.fit()\n",
    "affect_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level of Interest\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.648868\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>A_Sex</td>      <th>  No. Observations:  </th>  <td>   195</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   185</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 18 Nov 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.06344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:30:29</td>     <th>  Log-Likelihood:    </th> <td> -126.53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>False</td>      <th>  LL-Null:           </th> <td> -135.10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.04656</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                    <td>  867.6886</td> <td> 6.13e+05</td> <td>    0.001</td> <td> 0.999</td> <td> -1.2e+06</td> <td>  1.2e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex</th>                        <td>  114.4574</td> <td> 6.38e+05</td> <td>    0.000</td> <td> 1.000</td> <td>-1.25e+06</td> <td> 1.25e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Q_High Interest\")</th>         <td> 1376.6443</td> <td> 3.84e+05</td> <td>    0.004</td> <td> 0.997</td> <td> -7.5e+05</td> <td> 7.53e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Q_Normal Interest\")</th>       <td> 1377.3838</td> <td> 3.84e+05</td> <td>    0.004</td> <td> 0.997</td> <td> -7.5e+05</td> <td> 7.53e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q(\"Q_High Interest\")</th>   <td> -114.5814</td> <td> 6.38e+05</td> <td>   -0.000</td> <td> 1.000</td> <td>-1.25e+06</td> <td> 1.25e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q(\"Q_Normal Interest\")</th> <td> -113.5315</td> <td> 6.38e+05</td> <td>   -0.000</td> <td> 1.000</td> <td>-1.25e+06</td> <td> 1.25e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"A_High Interest\")</th>         <td> 3440.2653</td> <td> 3.13e+05</td> <td>    0.011</td> <td> 0.991</td> <td> -6.1e+05</td> <td> 6.17e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"A_Normal Interest\")</th>       <td> 3440.4835</td> <td> 3.13e+05</td> <td>    0.011</td> <td> 0.991</td> <td> -6.1e+05</td> <td> 6.17e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"P_High Interest\")</th>         <td>-5684.2214</td> <td> 2.97e+05</td> <td>   -0.019</td> <td> 0.985</td> <td>-5.88e+05</td> <td> 5.77e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"P_Normal Interest\")</th>       <td>-5686.4786</td> <td> 2.97e+05</td> <td>   -0.019</td> <td> 0.985</td> <td>-5.88e+05</td> <td> 5.77e+05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  A_Sex   No. Observations:                  195\n",
       "Model:                          Logit   Df Residuals:                      185\n",
       "Method:                           MLE   Df Model:                            9\n",
       "Date:                Wed, 18 Nov 2020   Pseudo R-squ.:                 0.06344\n",
       "Time:                        13:30:29   Log-Likelihood:                -126.53\n",
       "converged:                      False   LL-Null:                       -135.10\n",
       "                                        LLR p-value:                   0.04656\n",
       "================================================================================================\n",
       "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------\n",
       "Intercept                      867.6886   6.13e+05      0.001      0.999    -1.2e+06     1.2e+06\n",
       "Q_Sex                          114.4574   6.38e+05      0.000      1.000   -1.25e+06    1.25e+06\n",
       "Q(\"Q_High Interest\")          1376.6443   3.84e+05      0.004      0.997    -7.5e+05    7.53e+05\n",
       "Q(\"Q_Normal Interest\")        1377.3838   3.84e+05      0.004      0.997    -7.5e+05    7.53e+05\n",
       "Q_Sex:Q(\"Q_High Interest\")    -114.5814   6.38e+05     -0.000      1.000   -1.25e+06    1.25e+06\n",
       "Q_Sex:Q(\"Q_Normal Interest\")  -113.5315   6.38e+05     -0.000      1.000   -1.25e+06    1.25e+06\n",
       "Q(\"A_High Interest\")          3440.2653   3.13e+05      0.011      0.991    -6.1e+05    6.17e+05\n",
       "Q(\"A_Normal Interest\")        3440.4835   3.13e+05      0.011      0.991    -6.1e+05    6.17e+05\n",
       "Q(\"P_High Interest\")         -5684.2214   2.97e+05     -0.019      0.985   -5.88e+05    5.77e+05\n",
       "Q(\"P_Normal Interest\")       -5686.4786   2.97e+05     -0.019      0.985   -5.88e+05    5.77e+05\n",
       "================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Level of Interest')\n",
    "loi_sex_model = smf.logit('A_Sex ~ Q_Sex * (Q(\"Q_High Interest\") + Q(\"Q_Normal Interest\")) + Q(\"A_High Interest\") + Q(\"A_Normal Interest\") + Q(\"P_High Interest\") + Q(\"P_Normal Interest\")', data = loi)\n",
    "loi_res = loi_sex_model.fit()\n",
    "loi_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arousal Valence\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.474784\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>A_Sex</td>      <th>  No. Observations:  </th>  <td>   195</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   185</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     9</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Wed, 18 Nov 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.3147</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:30:29</td>     <th>  Log-Likelihood:    </th> <td> -92.583</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -135.10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.607e-14</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>   -2.3705</td> <td>    0.535</td> <td>   -4.431</td> <td> 0.000</td> <td>   -3.419</td> <td>   -1.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex</th>           <td>    0.4507</td> <td>    0.582</td> <td>    0.775</td> <td> 0.438</td> <td>   -0.689</td> <td>    1.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Arousal</th>       <td>    1.7521</td> <td>    2.344</td> <td>    0.747</td> <td> 0.455</td> <td>   -2.842</td> <td>    6.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Valence</th>       <td>    5.2594</td> <td>    3.248</td> <td>    1.619</td> <td> 0.105</td> <td>   -1.107</td> <td>   11.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Arousal</th> <td>    0.0285</td> <td>    3.798</td> <td>    0.008</td> <td> 0.994</td> <td>   -7.416</td> <td>    7.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Valence</th> <td>   -4.9806</td> <td>    4.968</td> <td>   -1.003</td> <td> 0.316</td> <td>  -14.717</td> <td>    4.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Arousal</th>       <td>    2.6449</td> <td>    2.774</td> <td>    0.953</td> <td> 0.340</td> <td>   -2.792</td> <td>    8.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Valence</th>       <td>   -4.7536</td> <td>    3.421</td> <td>   -1.390</td> <td> 0.165</td> <td>  -11.458</td> <td>    1.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Arousal</th>       <td>   15.2776</td> <td>    3.478</td> <td>    4.392</td> <td> 0.000</td> <td>    8.461</td> <td>   22.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Valence</th>       <td>   -6.8358</td> <td>    4.068</td> <td>   -1.680</td> <td> 0.093</td> <td>  -14.809</td> <td>    1.137</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  A_Sex   No. Observations:                  195\n",
       "Model:                          Logit   Df Residuals:                      185\n",
       "Method:                           MLE   Df Model:                            9\n",
       "Date:                Wed, 18 Nov 2020   Pseudo R-squ.:                  0.3147\n",
       "Time:                        13:30:29   Log-Likelihood:                -92.583\n",
       "converged:                       True   LL-Null:                       -135.10\n",
       "                                        LLR p-value:                 1.607e-14\n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept          -2.3705      0.535     -4.431      0.000      -3.419      -1.322\n",
       "Q_Sex               0.4507      0.582      0.775      0.438      -0.689       1.591\n",
       "Q_Arousal           1.7521      2.344      0.747      0.455      -2.842       6.346\n",
       "Q_Valence           5.2594      3.248      1.619      0.105      -1.107      11.626\n",
       "Q_Sex:Q_Arousal     0.0285      3.798      0.008      0.994      -7.416       7.473\n",
       "Q_Sex:Q_Valence    -4.9806      4.968     -1.003      0.316     -14.717       4.756\n",
       "A_Arousal           2.6449      2.774      0.953      0.340      -2.792       8.082\n",
       "A_Valence          -4.7536      3.421     -1.390      0.165     -11.458       1.951\n",
       "P_Arousal          15.2776      3.478      4.392      0.000       8.461      22.095\n",
       "P_Valence          -6.8358      4.068     -1.680      0.093     -14.809       1.137\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Arousal Valence')\n",
    "arval_sex_model = smf.logit('A_Sex ~ Q_Sex * (Q_Arousal + Q_Valence) + A_Arousal + A_Valence + P_Arousal + P_Valence', data = arval)\n",
    "arval_res = arval_sex_model.fit()\n",
    "arval_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
