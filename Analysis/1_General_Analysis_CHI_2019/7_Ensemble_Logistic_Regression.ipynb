{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import sklearn.preprocessing as pp\n",
    "import statsmodels.api as sm\n",
    "#import nltk\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "import time\n",
    "import Helper as hp\n",
    "\n",
    "#Load Data\n",
    "data = pd.read_csv(\"CHI_2019_FULL.csv\")\n",
    "\n",
    "#Set Labels \n",
    "emotion_label = ['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness']\n",
    "affect_label = ['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired']\n",
    "loi_label = ['Disinterest', 'Normal', 'High Interest']\n",
    "\n",
    "#Get specific data and save it into new data frames\n",
    "# We use the pandas .copy(deep=True) function to prevent the SettingWithCopyWarning we would otherwise get. Since we do\n",
    "# not write, but only read from the data, the warning does not affect the data frames\n",
    "df_emotion = data[['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness', 'Filename']].copy(deep=True)\n",
    "df_affect = data[['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired', 'Filename']].copy(deep=True)\n",
    "df_loi = data[['Disinterest', 'Normal', 'High Interest', 'Filename']].copy(deep=True)\n",
    "df_ar_val = data[['Arousal', 'Valence', 'Filename']].copy(deep=True)\n",
    "#For further usage, we want to append the CharacterID as a column, which is saved with other information in the filename\n",
    "#Since we only want the digits, we can remove all non-digit characters of the filename column and append the column to the df\n",
    "\n",
    "df_emotion['Char_ID'] = df_emotion['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_affect['Char_ID'] = df_affect['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_loi['Char_ID'] = df_loi['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "\n",
    "#Load data about speakers\n",
    "char_data = pd.read_csv(\"CHI_2019_CharacterData.csv\")  \n",
    "char_data.replace({'Male': 0.0, 'Female': 1.0}, inplace = True)\n",
    "\n",
    "#Join above tables and Character Tables\n",
    "#To Join DataFrames we have to cast the column on which we want to join to int, so that both columns have the same data type\n",
    "char_data['ID'] = char_data['ID'].astype(int)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Char_ID'].astype(int)\n",
    "df_emotion['Char_ID'] = df_emotion['Char_ID'].astype(int)\n",
    "df_affect['Char_ID'] = df_affect['Char_ID'].astype(int)\n",
    "df_loi['Char_ID'] = df_loi['Char_ID'].astype(int)\n",
    "\n",
    "#Save new data frames\n",
    "df_ar_val_char = df_ar_val.merge(char_data, how = 'left', left_on='Char_ID', right_on='ID')\n",
    "df_emotion_char = df_emotion.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_affect_char = df_affect.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_loi_char = df_loi.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "\n",
    "#Now, we only want to have data containing information about the answers\n",
    "#For that we need to extract from the filename column, whether the file was part of an answer\n",
    "#a = answer, p = presentation, q = question\n",
    "#sentence_type should be the same for all tables, but just to be sure\n",
    "arval_sentence_type = df_ar_val_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_ar_val_char['SentenceType'] = arval_sentence_type\n",
    "emo_sentence_type = df_emotion_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_emotion_char['SentenceType'] = emo_sentence_type\n",
    "aff_sentence_type = df_affect_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_affect_char['SentenceType'] = aff_sentence_type\n",
    "loi_sentence_type = df_loi_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_loi_char['SentenceType'] = loi_sentence_type\n",
    "\n",
    "#For affect, we will have to drop the intoxication column and thus we will re-normalize the other values\n",
    "affect_label.remove('Intoxicated')\n",
    "df_affect_char = df_affect_char.drop(['Intoxicated'], axis = 1)\n",
    "norm_test = pp.normalize(df_affect_char[affect_label], norm = 'l1')\n",
    "df_affect_char[affect_label] = norm_test\n",
    "\n",
    "df_loi_char['Normal Interest'] = df_loi_char['Disinterest'] + df_loi_char['Normal']\n",
    "df_loi_char = df_loi_char.drop(['Disinterest', 'Normal'], axis = 1)\n",
    "loi_label = ['Normal Interest', 'High Interest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char_a = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'a'].copy()\n",
    "df_emotion_char_a = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'a'].copy()\n",
    "df_affect_char_a = df_affect_char.loc[df_affect_char['SentenceType'] == 'a'].copy()\n",
    "df_loi_char_a = df_loi_char.loc[df_loi_char['SentenceType'] == 'a'].copy()\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char_p = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'p'].copy()\n",
    "df_emotion_char_p = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'p'].copy()\n",
    "df_affect_char_p = df_affect_char.loc[df_affect_char['SentenceType'] == 'p'].copy()\n",
    "df_loi_char_p = df_loi_char.loc[df_loi_char['SentenceType'] == 'p'].copy()\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char_q = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'q'].copy()\n",
    "df_emotion_char_q = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'q'].copy()\n",
    "df_affect_char_q = df_affect_char.loc[df_affect_char['SentenceType'] == 'q'].copy()\n",
    "df_loi_char_q = df_loi_char.loc[df_loi_char['SentenceType'] == 'q'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = df_emotion_char_p['Char_ID'].copy()\n",
    "IDs.drop_duplicates()\n",
    "\n",
    "# For presentations we need an aggregate, e.g. median for the presenters\n",
    "for i in IDs:\n",
    "    #first for emotion\n",
    "    for l in emotion_label:    \n",
    "        emo = df_emotion_char_p.loc[df_emotion_char_p.Char_ID == i,l]\n",
    "        emo_neu = hp.constructMedianSeries(emo)\n",
    "        df_emotion_char_p.loc[df_emotion_char_p.Char_ID == i,l] = emo_neu\n",
    "    #Then for affect\n",
    "    for l in affect_label:    \n",
    "        aff = df_affect_char_p.loc[df_affect_char_p.Char_ID == i,l]\n",
    "        aff_neu = hp.constructMedianSeries(aff)\n",
    "        df_affect_char_p.loc[df_affect_char_p.Char_ID == i,l] = aff_neu  \n",
    "    for l in loi_label:    \n",
    "        loi = df_loi_char_p.loc[df_loi_char_p.Char_ID == i,l]\n",
    "        loi_neu = hp.constructMedianSeries(loi)\n",
    "        df_loi_char_p.loc[df_loi_char_p.Char_ID == i,l] = loi_neu  \n",
    "    for l in ['Arousal', 'Valence']:    \n",
    "        arval = df_ar_val_char_p.loc[df_ar_val_char_p.Char_ID == i,l]\n",
    "        arval_neu = hp.constructMedianSeries(arval)\n",
    "        df_ar_val_char_p.loc[df_ar_val_char_p.Char_ID == i,l] = arval_neu \n",
    "        \n",
    "#Now let's drop the duplicate values, since we only need one row now per person\n",
    "df_emotion_char_p.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_affect_char_p.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_loi_char_p.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_ar_val_char_p.drop_duplicates(subset=['ID'], inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_label.extend(['Sex', 'Academic Status', 'IsNativeSpeaker'])\n",
    "affect_label.extend(['Sex', 'Academic Status', 'IsNativeSpeaker'])\n",
    "loi_label.extend(['Sex', 'Academic Status', 'IsNativeSpeaker'])\n",
    "\n",
    "df_emotion_char_p.columns = df_emotion_char_p.columns.map(lambda x: 'P_' + x if x in emotion_label else x)\n",
    "df_affect_char_p.columns = df_affect_char_p.columns.map(lambda x: 'P_' + x if x in affect_label else x)\n",
    "df_loi_char_p.columns = df_loi_char_p.columns.map(lambda x: 'P_' + x if x in loi_label else x)\n",
    "df_ar_val_char_p.columns = df_ar_val_char_p.columns.map(lambda x: 'P_' + x if x in ['Arousal', 'Valence', 'Sex', 'Academic Status', 'IsNativeSpeaker'] else x)\n",
    "\n",
    "df_emotion_char_a.columns = df_emotion_char_a.columns.map(lambda x: 'A_' + x if x in emotion_label else x)\n",
    "df_affect_char_a.columns = df_affect_char_a.columns.map(lambda x: 'A_' + x if x in affect_label else x)\n",
    "df_loi_char_a.columns = df_loi_char_a.columns.map(lambda x: 'A_' + x if x in loi_label else x)\n",
    "df_ar_val_char_a.columns = df_ar_val_char_a.columns.map(lambda x: 'A_' + x if x in ['Arousal', 'Valence', 'Sex', 'Academic Status', 'IsNativeSpeaker'] else x)\n",
    "\n",
    "df_emotion_char_q.columns = df_emotion_char_q.columns.map(lambda x: 'Q_' + x if x in emotion_label else x)\n",
    "df_affect_char_q.columns = df_affect_char_q.columns.map(lambda x: 'Q_' + x if x in affect_label else x)\n",
    "df_loi_char_q.columns = df_loi_char_q.columns.map(lambda x: 'Q_' + x if x in loi_label else x)\n",
    "df_ar_val_char_q.columns = df_ar_val_char_q.columns.map(lambda x: 'Q_' + x if x in ['Arousal', 'Valence', 'Sex', 'Academic Status', 'IsNativeSpeaker'] else x)\n",
    "\n",
    "df_emotion_char_p = df_emotion_char_p.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_affect_char_p = df_affect_char_p.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_loi_char_p = df_loi_char_p.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_ar_val_char_p = df_ar_val_char_p.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "\n",
    "df_emotion_char_a = df_emotion_char_a.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_affect_char_a = df_affect_char_a.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_loi_char_a = df_loi_char_a.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_ar_val_char_a = df_ar_val_char_a.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "\n",
    "df_emotion_char_q = df_emotion_char_q.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_affect_char_q = df_affect_char_q.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_loi_char_q = df_loi_char_q.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)\n",
    "df_ar_val_char_q = df_ar_val_char_q.drop(['Name', 'Char_ID', 'VideoTitle', 'SentenceType', 'Filename'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_Anger</th>\n",
       "      <th>Q_Boredom</th>\n",
       "      <th>Q_Disgust</th>\n",
       "      <th>Q_Fear</th>\n",
       "      <th>Q_Happiness</th>\n",
       "      <th>Q_Emo_Neutral</th>\n",
       "      <th>Q_Sadness</th>\n",
       "      <th>ID_x</th>\n",
       "      <th>Q_Sex</th>\n",
       "      <th>Q_Academic Status</th>\n",
       "      <th>...</th>\n",
       "      <th>P_Boredom</th>\n",
       "      <th>P_Disgust</th>\n",
       "      <th>P_Fear</th>\n",
       "      <th>P_Happiness</th>\n",
       "      <th>P_Emo_Neutral</th>\n",
       "      <th>P_Sadness</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>P_Sex</th>\n",
       "      <th>P_Academic Status</th>\n",
       "      <th>P_IsNativeSpeaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.959199</td>\n",
       "      <td>193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>0.225678</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.152280</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.827121</td>\n",
       "      <td>194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>0.225678</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>0.014762</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.970133</td>\n",
       "      <td>195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>0.225678</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.151633</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.840536</td>\n",
       "      <td>196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026247</td>\n",
       "      <td>0.225678</td>\n",
       "      <td>0.010919</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.550885</td>\n",
       "      <td>192</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.043610</td>\n",
       "      <td>0.119756</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>0.803436</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016413</td>\n",
       "      <td>0.046260</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.921682</td>\n",
       "      <td>197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>Native Speaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.052537</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.925487</td>\n",
       "      <td>460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210241</td>\n",
       "      <td>0.174924</td>\n",
       "      <td>0.037075</td>\n",
       "      <td>0.049350</td>\n",
       "      <td>0.028904</td>\n",
       "      <td>0.413051</td>\n",
       "      <td>457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>Native Speaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.966359</td>\n",
       "      <td>461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210241</td>\n",
       "      <td>0.174924</td>\n",
       "      <td>0.037075</td>\n",
       "      <td>0.049350</td>\n",
       "      <td>0.028904</td>\n",
       "      <td>0.413051</td>\n",
       "      <td>457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>Native Speaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.020095</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.960965</td>\n",
       "      <td>462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210241</td>\n",
       "      <td>0.174924</td>\n",
       "      <td>0.037075</td>\n",
       "      <td>0.049350</td>\n",
       "      <td>0.028904</td>\n",
       "      <td>0.413051</td>\n",
       "      <td>457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>Native Speaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.992159</td>\n",
       "      <td>463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210241</td>\n",
       "      <td>0.174924</td>\n",
       "      <td>0.037075</td>\n",
       "      <td>0.049350</td>\n",
       "      <td>0.028904</td>\n",
       "      <td>0.413051</td>\n",
       "      <td>457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>Native Speaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.615869</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.375736</td>\n",
       "      <td>465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.084372</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.880614</td>\n",
       "      <td>464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q_Anger  Q_Boredom  Q_Disgust    Q_Fear  Q_Happiness  Q_Emo_Neutral  \\\n",
       "0    0.002253   0.005161   0.028762  0.002877     0.001428       0.000320   \n",
       "1    0.007885   0.004149   0.152280  0.004555     0.003764       0.000246   \n",
       "2    0.003784   0.006456   0.014762  0.002672     0.001569       0.000624   \n",
       "3    0.004143   0.000882   0.151633  0.000632     0.002108       0.000065   \n",
       "4    0.008246   0.043610   0.119756  0.005309     0.007007       0.012636   \n",
       "..        ...        ...        ...       ...          ...            ...   \n",
       "190  0.001621   0.052537   0.003183  0.011076     0.002419       0.003676   \n",
       "191  0.002563   0.004989   0.018547  0.005339     0.001827       0.000377   \n",
       "192  0.001638   0.009019   0.005033  0.020095     0.002618       0.000631   \n",
       "193  0.000195   0.004939   0.001564  0.000372     0.000364       0.000408   \n",
       "194  0.004666   0.001716   0.615869  0.000343     0.001429       0.000241   \n",
       "\n",
       "     Q_Sadness  ID_x  Q_Sex Q_Academic Status  ... P_Boredom P_Disgust  \\\n",
       "0     0.959199   193    0.0               NaN  ...  0.026247  0.225678   \n",
       "1     0.827121   194    1.0               NaN  ...  0.026247  0.225678   \n",
       "2     0.970133   195    0.0               NaN  ...  0.026247  0.225678   \n",
       "3     0.840536   196    0.0               NaN  ...  0.026247  0.225678   \n",
       "4     0.803436   198    0.0               NaN  ...  0.016413  0.046260   \n",
       "..         ...   ...    ...               ...  ...       ...       ...   \n",
       "190   0.925487   460    0.0               NaN  ...  0.210241  0.174924   \n",
       "191   0.966359   461    0.0               NaN  ...  0.210241  0.174924   \n",
       "192   0.960965   462    0.0               NaN  ...  0.210241  0.174924   \n",
       "193   0.992159   463    0.0               NaN  ...  0.210241  0.174924   \n",
       "194   0.375736   465    0.0               NaN  ...  0.021997  0.084372   \n",
       "\n",
       "       P_Fear  P_Happiness  P_Emo_Neutral  P_Sadness  ID_y  P_Sex  \\\n",
       "0    0.010919     0.009425       0.003056   0.550885   192    1.0   \n",
       "1    0.010919     0.009425       0.003056   0.550885   192    1.0   \n",
       "2    0.010919     0.009425       0.003056   0.550885   192    1.0   \n",
       "3    0.010919     0.009425       0.003056   0.550885   192    1.0   \n",
       "4    0.003839     0.004142       0.002316   0.921682   197    1.0   \n",
       "..        ...          ...            ...        ...   ...    ...   \n",
       "190  0.037075     0.049350       0.028904   0.413051   457    0.0   \n",
       "191  0.037075     0.049350       0.028904   0.413051   457    0.0   \n",
       "192  0.037075     0.049350       0.028904   0.413051   457    0.0   \n",
       "193  0.037075     0.049350       0.028904   0.413051   457    0.0   \n",
       "194  0.002434     0.003161       0.003280   0.880614   464    0.0   \n",
       "\n",
       "     P_Academic Status  P_IsNativeSpeaker  \n",
       "0         Grad Student  Europ. Non-Native  \n",
       "1         Grad Student  Europ. Non-Native  \n",
       "2         Grad Student  Europ. Non-Native  \n",
       "3         Grad Student  Europ. Non-Native  \n",
       "4         Grad Student     Native Speaker  \n",
       "..                 ...                ...  \n",
       "190       Grad Student     Native Speaker  \n",
       "191       Grad Student     Native Speaker  \n",
       "192       Grad Student     Native Speaker  \n",
       "193       Grad Student     Native Speaker  \n",
       "194                PhD  Europ. Non-Native  \n",
       "\n",
       "[195 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To do: Merge Data Frames; First Question and Presentation, then answer and question\n",
    "ar_val_char = df_ar_val_char_q.merge(df_ar_val_char_p, how = 'left', left_on='VideoID', right_on='VideoID')\n",
    "loi_char = df_loi_char_q.merge(df_loi_char_p, how = 'left', left_on='VideoID', right_on='VideoID')\n",
    "affect_char = df_affect_char_q.merge(df_affect_char_p, how = 'left', left_on='VideoID', right_on='VideoID')\n",
    "emotion_char = df_emotion_char_q.merge(df_emotion_char_p, how = 'left', left_on='VideoID', right_on='VideoID')\n",
    "emotion_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar_val_char_a.reset_index(drop = True, inplace = True)\n",
    "df_ar_val_char_q.reset_index(drop = True, inplace = True)\n",
    "arval = pd.concat([ar_val_char, df_ar_val_char_a], axis = 1)\n",
    "arval.drop(['ID_x', 'ID_y', 'VideoID', 'ID', 'Q_Academic Status','Q_IsNativeSpeaker', 'A_IsNativeSpeaker', 'A_Academic Status', 'P_Academic Status', 'P_IsNativeSpeaker', 'P_Sex'], axis = 1, inplace = True)\n",
    "\n",
    "df_loi_char_a.reset_index(drop = True, inplace = True)\n",
    "df_loi_char_q.reset_index(drop = True, inplace = True)\n",
    "loi = pd.concat([loi_char, df_loi_char_a], axis = 1)\n",
    "loi.drop(['ID_x', 'ID_y', 'VideoID', 'ID', 'Q_Academic Status','Q_IsNativeSpeaker', 'A_IsNativeSpeaker', 'A_Academic Status', 'P_Academic Status', 'P_IsNativeSpeaker', 'P_Sex'], axis = 1, inplace = True)\n",
    "\n",
    "df_affect_char_a.reset_index(drop = True, inplace = True)\n",
    "df_affect_char_q.reset_index(drop = True, inplace = True)\n",
    "affect = pd.concat([affect_char, df_affect_char_a], axis = 1)\n",
    "affect.drop(['ID_x', 'ID_y', 'VideoID', 'ID', 'Q_Academic Status','Q_IsNativeSpeaker', 'A_IsNativeSpeaker', 'A_Academic Status', 'P_Academic Status', 'P_IsNativeSpeaker', 'P_Sex'], axis = 1, inplace = True)\n",
    "\n",
    "df_emotion_char_a.reset_index(drop = True, inplace = True)\n",
    "df_emotion_char_q.reset_index(drop = True, inplace = True)\n",
    "emotion = pd.concat([emotion_char, df_emotion_char_a], axis = 1)\n",
    "emotion.drop(['ID_x', 'ID_y', 'VideoID', 'ID', 'Q_Academic Status','Q_IsNativeSpeaker', 'A_IsNativeSpeaker', 'A_Academic Status', 'P_Academic Status', 'P_IsNativeSpeaker', 'P_Sex'], axis = 1, inplace = True)\n",
    "#Now we have our dataframe ready for logsitic regression:\n",
    "#Each row resembles an interaction between one question, the corresponding answer and the median of the presenter\n",
    "#We could do this since both dataframes are default sorted by filenames (emotion_char and df_emotion_char_a)\n",
    "#So each question is in the same line as the corresponding answer\n",
    "\n",
    "#Since we only need the labels of gender once, we drop the others before concatenating all data frames together\n",
    "#for the omnibus model\n",
    "test_affect = affect.drop(['Q_Sex', 'A_Sex'], axis = 1)\n",
    "test_loi= loi.drop(['Q_Sex', 'A_Sex'], axis = 1)\n",
    "test_arval = arval.drop(['Q_Sex', 'A_Sex'], axis = 1)\n",
    "\n",
    "#Concat all our data together; Since it's sorted in the same way, we can just use pd.concat()\n",
    "data = pd.concat([emotion, test_affect, test_loi, test_arval], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only want to standardize the data, which contains the continous values, not our labels\n",
    "test = data.loc[:,data.columns != 'A_Sex']\n",
    "test = test.loc[:, test.columns != 'Q_Sex']\n",
    "#Apply Standard Scaler to relevant columns\n",
    "scaler = pp.StandardScaler()\n",
    "data[test.columns] = scaler.fit_transform(data[test.columns])\n",
    "#data.describe() #Calling this we see that the std is ~1 and mean is very close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "Dropping 'Q_Aggressiv' at index: 21\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:181: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 'A_Aggressiv' at index: 30\n",
      "46\n",
      "Dropping 'A_High Interest' at index: 38\n",
      "45\n",
      "Dropping 'P_High Interest' at index: 36\n",
      "44\n",
      "Dropping 'Q_High Interest' at index: 34\n",
      "43\n",
      "Dropping 'A_Sadness' at index: 20\n",
      "42\n",
      "Dropping 'Q_Sadness' at index: 6\n",
      "41\n",
      "Dropping 'P_Happiness' at index: 10\n",
      "40\n",
      "Dropping 'P_Boredom' at index: 7\n",
      "39\n",
      "Dropping 'P_Tired' at index: 25\n",
      "38\n",
      "Dropping 'A_Tired' at index: 28\n",
      "37\n",
      "Dropping 'P_Sadness' at index: 10\n",
      "36\n",
      "Dropping 'A_Boredom' at index: 11\n",
      "35\n",
      "Dropping 'A_Happiness' at index: 13\n",
      "34\n",
      "Dropping 'Q_Tired' at index: 17\n",
      "33\n",
      "Dropping 'Q_Happiness' at index: 4\n",
      "32\n",
      "Dropping 'P_Aggressiv' at index: 16\n",
      "31\n",
      "Dropping 'Q_Boredom' at index: 1\n",
      "30\n",
      "Dropping 'P_Fear' at index: 6\n",
      "29\n",
      "Remaining variables:\n",
      "[['Q_Anger', 'Q_Disgust', 'Q_Fear', 'Q_Emo_Neutral', 'P_Anger', 'P_Disgust', 'P_Emo_Neutral', 'A_Anger', 'A_Disgust', 'A_Fear', 'A_Emo_Neutral', 'Q_Cheerful', 'Q_Nervous', 'Q_Aff_Neutral', 'P_Cheerful', 'P_Nervous', 'P_Aff_Neutral', 'A_Cheerful', 'A_Nervous', 'A_Aff_Neutral', 'Q_Normal Interest', 'P_Normal Interest', 'A_Normal Interest', 'Q_Arousal', 'Q_Valence', 'P_Arousal', 'P_Valence', 'A_Arousal', 'A_Valence']]\n"
     ]
    }
   ],
   "source": [
    "X = hp.calculate_vif(data[test.columns], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_Anger</th>\n",
       "      <th>Q_Disgust</th>\n",
       "      <th>Q_Fear</th>\n",
       "      <th>Q_Emo_Neutral</th>\n",
       "      <th>P_Anger</th>\n",
       "      <th>P_Disgust</th>\n",
       "      <th>P_Emo_Neutral</th>\n",
       "      <th>A_Anger</th>\n",
       "      <th>A_Disgust</th>\n",
       "      <th>A_Fear</th>\n",
       "      <th>...</th>\n",
       "      <th>Q_Valence</th>\n",
       "      <th>P_Arousal</th>\n",
       "      <th>P_Valence</th>\n",
       "      <th>A_Arousal</th>\n",
       "      <th>A_Valence</th>\n",
       "      <th>A_Sex</th>\n",
       "      <th>Q_Sex</th>\n",
       "      <th>P_High Interest</th>\n",
       "      <th>A_High Interest</th>\n",
       "      <th>Q_High Interest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.336285</td>\n",
       "      <td>-0.537413</td>\n",
       "      <td>-0.252757</td>\n",
       "      <td>-0.399605</td>\n",
       "      <td>-0.430552</td>\n",
       "      <td>-0.202080</td>\n",
       "      <td>-0.337672</td>\n",
       "      <td>-0.479038</td>\n",
       "      <td>-0.279274</td>\n",
       "      <td>-0.351458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109221</td>\n",
       "      <td>1.624868</td>\n",
       "      <td>-1.316756</td>\n",
       "      <td>1.583623</td>\n",
       "      <td>-1.072335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.594492</td>\n",
       "      <td>1.332803</td>\n",
       "      <td>1.646681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.155717</td>\n",
       "      <td>0.048516</td>\n",
       "      <td>-0.184362</td>\n",
       "      <td>-0.402044</td>\n",
       "      <td>-0.430552</td>\n",
       "      <td>-0.202080</td>\n",
       "      <td>-0.337672</td>\n",
       "      <td>-0.425289</td>\n",
       "      <td>-0.200572</td>\n",
       "      <td>-0.352068</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.026426</td>\n",
       "      <td>1.624868</td>\n",
       "      <td>-1.316756</td>\n",
       "      <td>1.277500</td>\n",
       "      <td>-0.012624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.594492</td>\n",
       "      <td>1.321897</td>\n",
       "      <td>0.140860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.287199</td>\n",
       "      <td>-0.603825</td>\n",
       "      <td>-0.261113</td>\n",
       "      <td>-0.389589</td>\n",
       "      <td>-0.430552</td>\n",
       "      <td>-0.202080</td>\n",
       "      <td>-0.337672</td>\n",
       "      <td>-0.603274</td>\n",
       "      <td>-0.586883</td>\n",
       "      <td>-0.422374</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.018831</td>\n",
       "      <td>1.624868</td>\n",
       "      <td>-1.316756</td>\n",
       "      <td>2.626954</td>\n",
       "      <td>0.045308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.594492</td>\n",
       "      <td>1.377899</td>\n",
       "      <td>0.828516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.275690</td>\n",
       "      <td>0.045447</td>\n",
       "      <td>-0.344262</td>\n",
       "      <td>-0.408008</td>\n",
       "      <td>-0.430552</td>\n",
       "      <td>-0.202080</td>\n",
       "      <td>-0.337672</td>\n",
       "      <td>-0.052876</td>\n",
       "      <td>-0.166518</td>\n",
       "      <td>-0.153466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195554</td>\n",
       "      <td>1.624868</td>\n",
       "      <td>-1.316756</td>\n",
       "      <td>1.411346</td>\n",
       "      <td>-1.638982</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.594492</td>\n",
       "      <td>0.920352</td>\n",
       "      <td>0.449306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.144143</td>\n",
       "      <td>-0.105767</td>\n",
       "      <td>-0.153629</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>-0.450753</td>\n",
       "      <td>-0.912372</td>\n",
       "      <td>-0.386864</td>\n",
       "      <td>-0.384093</td>\n",
       "      <td>-0.512082</td>\n",
       "      <td>-0.298347</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135704</td>\n",
       "      <td>-1.104231</td>\n",
       "      <td>-0.606353</td>\n",
       "      <td>-0.877265</td>\n",
       "      <td>-0.913776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.160816</td>\n",
       "      <td>-0.635318</td>\n",
       "      <td>0.698191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-0.356547</td>\n",
       "      <td>-0.658752</td>\n",
       "      <td>0.081432</td>\n",
       "      <td>-0.289028</td>\n",
       "      <td>1.819272</td>\n",
       "      <td>-0.403008</td>\n",
       "      <td>1.380592</td>\n",
       "      <td>-0.556303</td>\n",
       "      <td>-0.481645</td>\n",
       "      <td>-0.360483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.397165</td>\n",
       "      <td>-0.464602</td>\n",
       "      <td>-0.415888</td>\n",
       "      <td>0.361207</td>\n",
       "      <td>-1.354555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682264</td>\n",
       "      <td>1.303107</td>\n",
       "      <td>1.653794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-0.326346</td>\n",
       "      <td>-0.585870</td>\n",
       "      <td>-0.152406</td>\n",
       "      <td>-0.397727</td>\n",
       "      <td>1.819272</td>\n",
       "      <td>-0.403008</td>\n",
       "      <td>1.380592</td>\n",
       "      <td>-0.483753</td>\n",
       "      <td>-0.580928</td>\n",
       "      <td>-0.357739</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.232549</td>\n",
       "      <td>-0.464602</td>\n",
       "      <td>-0.415888</td>\n",
       "      <td>0.923056</td>\n",
       "      <td>-0.712541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682264</td>\n",
       "      <td>1.320710</td>\n",
       "      <td>1.550033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-0.356002</td>\n",
       "      <td>-0.649976</td>\n",
       "      <td>0.449044</td>\n",
       "      <td>-0.389358</td>\n",
       "      <td>1.819272</td>\n",
       "      <td>-0.403008</td>\n",
       "      <td>1.380592</td>\n",
       "      <td>-0.535734</td>\n",
       "      <td>-0.512548</td>\n",
       "      <td>-0.363471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.936234</td>\n",
       "      <td>-0.464602</td>\n",
       "      <td>-0.415888</td>\n",
       "      <td>-0.636406</td>\n",
       "      <td>-0.871200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682264</td>\n",
       "      <td>1.092611</td>\n",
       "      <td>0.524793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>-0.402266</td>\n",
       "      <td>-0.666432</td>\n",
       "      <td>-0.354860</td>\n",
       "      <td>-0.396706</td>\n",
       "      <td>1.819272</td>\n",
       "      <td>-0.403008</td>\n",
       "      <td>1.380592</td>\n",
       "      <td>-0.028771</td>\n",
       "      <td>-0.067705</td>\n",
       "      <td>-0.191394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992200</td>\n",
       "      <td>-0.464602</td>\n",
       "      <td>-0.415888</td>\n",
       "      <td>1.040047</td>\n",
       "      <td>0.274062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682264</td>\n",
       "      <td>1.277822</td>\n",
       "      <td>0.732213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>-0.258922</td>\n",
       "      <td>2.247632</td>\n",
       "      <td>-0.356042</td>\n",
       "      <td>-0.402208</td>\n",
       "      <td>-0.509787</td>\n",
       "      <td>-0.761492</td>\n",
       "      <td>-0.322782</td>\n",
       "      <td>-0.259916</td>\n",
       "      <td>-0.621939</td>\n",
       "      <td>-0.243407</td>\n",
       "      <td>...</td>\n",
       "      <td>1.920622</td>\n",
       "      <td>-0.569543</td>\n",
       "      <td>1.150324</td>\n",
       "      <td>-0.479694</td>\n",
       "      <td>0.248984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.207092</td>\n",
       "      <td>-0.251616</td>\n",
       "      <td>-1.302336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q_Anger  Q_Disgust    Q_Fear  Q_Emo_Neutral   P_Anger  P_Disgust  \\\n",
       "0   -0.336285  -0.537413 -0.252757      -0.399605 -0.430552  -0.202080   \n",
       "1   -0.155717   0.048516 -0.184362      -0.402044 -0.430552  -0.202080   \n",
       "2   -0.287199  -0.603825 -0.261113      -0.389589 -0.430552  -0.202080   \n",
       "3   -0.275690   0.045447 -0.344262      -0.408008 -0.430552  -0.202080   \n",
       "4   -0.144143  -0.105767 -0.153629       0.006197 -0.450753  -0.912372   \n",
       "..        ...        ...       ...            ...       ...        ...   \n",
       "190 -0.356547  -0.658752  0.081432      -0.289028  1.819272  -0.403008   \n",
       "191 -0.326346  -0.585870 -0.152406      -0.397727  1.819272  -0.403008   \n",
       "192 -0.356002  -0.649976  0.449044      -0.389358  1.819272  -0.403008   \n",
       "193 -0.402266  -0.666432 -0.354860      -0.396706  1.819272  -0.403008   \n",
       "194 -0.258922   2.247632 -0.356042      -0.402208 -0.509787  -0.761492   \n",
       "\n",
       "     P_Emo_Neutral   A_Anger  A_Disgust    A_Fear  ...  Q_Valence  P_Arousal  \\\n",
       "0        -0.337672 -0.479038  -0.279274 -0.351458  ...  -0.109221   1.624868   \n",
       "1        -0.337672 -0.425289  -0.200572 -0.352068  ...  -1.026426   1.624868   \n",
       "2        -0.337672 -0.603274  -0.586883 -0.422374  ...  -1.018831   1.624868   \n",
       "3        -0.337672 -0.052876  -0.166518 -0.153466  ...   0.195554   1.624868   \n",
       "4        -0.386864 -0.384093  -0.512082 -0.298347  ...  -0.135704  -1.104231   \n",
       "..             ...       ...        ...       ...  ...        ...        ...   \n",
       "190       1.380592 -0.556303  -0.481645 -0.360483  ...  -0.397165  -0.464602   \n",
       "191       1.380592 -0.483753  -0.580928 -0.357739  ...  -1.232549  -0.464602   \n",
       "192       1.380592 -0.535734  -0.512548 -0.363471  ...  -0.936234  -0.464602   \n",
       "193       1.380592 -0.028771  -0.067705 -0.191394  ...   0.992200  -0.464602   \n",
       "194      -0.322782 -0.259916  -0.621939 -0.243407  ...   1.920622  -0.569543   \n",
       "\n",
       "     P_Valence  A_Arousal  A_Valence  A_Sex  Q_Sex  P_High Interest  \\\n",
       "0    -1.316756   1.583623  -1.072335    1.0    0.0         1.594492   \n",
       "1    -1.316756   1.277500  -0.012624    1.0    1.0         1.594492   \n",
       "2    -1.316756   2.626954   0.045308    1.0    0.0         1.594492   \n",
       "3    -1.316756   1.411346  -1.638982    1.0    0.0         1.594492   \n",
       "4    -0.606353  -0.877265  -0.913776    1.0    0.0        -1.160816   \n",
       "..         ...        ...        ...    ...    ...              ...   \n",
       "190  -0.415888   0.361207  -1.354555    0.0    0.0         0.682264   \n",
       "191  -0.415888   0.923056  -0.712541    0.0    0.0         0.682264   \n",
       "192  -0.415888  -0.636406  -0.871200    0.0    0.0         0.682264   \n",
       "193  -0.415888   1.040047   0.274062    0.0    0.0         0.682264   \n",
       "194   1.150324  -0.479694   0.248984    0.0    0.0        -0.207092   \n",
       "\n",
       "     A_High Interest  Q_High Interest  \n",
       "0           1.332803         1.646681  \n",
       "1           1.321897         0.140860  \n",
       "2           1.377899         0.828516  \n",
       "3           0.920352         0.449306  \n",
       "4          -0.635318         0.698191  \n",
       "..               ...              ...  \n",
       "190         1.303107         1.653794  \n",
       "191         1.320710         1.550033  \n",
       "192         1.092611         0.524793  \n",
       "193         1.277822         0.732213  \n",
       "194        -0.251616        -1.302336  \n",
       "\n",
       "[195 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [x for x in X.columns]\n",
    "t.extend(['A_Sex', 'Q_Sex'])\n",
    "t.extend(['P_High Interest', 'A_High Interest', 'Q_High Interest']) #We add these because they were previously\n",
    "#discarded by VIF, but we use them as reference variable, so we'll include them in the data, but not in the model\n",
    "df_vif2 = data[t]\n",
    "df_vif2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that we have constructed our data frame, let's do Logistic Regression!\n",
    "Naively, let's start by pluging in all our data, each feature group in relation to its reference variable (expect for Arousal Valence, since they are not linearly dependent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.136129\n",
      "         Iterations: 35\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>A_Sex</td>      <th>  No. Observations:  </th>  <td>   195</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   141</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    53</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Fri, 20 Nov 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.8035</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:31:33</td>     <th>  Log-Likelihood:    </th> <td> -26.545</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>False</td>      <th>  LL-Null:           </th> <td> -135.10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>9.619e-22</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   -0.2079</td> <td>    1.044</td> <td>   -0.199</td> <td> 0.842</td> <td>   -2.255</td> <td>    1.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex</th>                      <td>    2.1242</td> <td>    3.102</td> <td>    0.685</td> <td> 0.493</td> <td>   -3.955</td> <td>    8.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Anger</th>                    <td>   -1.5968</td> <td>    7.914</td> <td>   -0.202</td> <td> 0.840</td> <td>  -17.107</td> <td>   13.914</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Boredom</th>                  <td>    0.3673</td> <td>   40.798</td> <td>    0.009</td> <td> 0.993</td> <td>  -79.595</td> <td>   80.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Disgust</th>                  <td>   -0.9788</td> <td>   60.496</td> <td>   -0.016</td> <td> 0.987</td> <td> -119.548</td> <td>  117.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sadness</th>                  <td>    0.7060</td> <td>   82.025</td> <td>    0.009</td> <td> 0.993</td> <td> -160.060</td> <td>  161.472</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Fear</th>                     <td>   -0.9302</td> <td>    5.894</td> <td>   -0.158</td> <td> 0.875</td> <td>  -12.482</td> <td>   10.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Happiness</th>                <td>    1.3813</td> <td>   11.863</td> <td>    0.116</td> <td> 0.907</td> <td>  -21.871</td> <td>   24.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Arousal</th>                  <td>    4.1939</td> <td>    1.893</td> <td>    2.215</td> <td> 0.027</td> <td>    0.484</td> <td>    7.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Valence</th>                  <td>    0.6658</td> <td>    0.993</td> <td>    0.670</td> <td> 0.503</td> <td>   -1.281</td> <td>    2.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Q_High Interest\")</th>       <td>   -4.0580</td> <td>    1.706</td> <td>   -2.378</td> <td> 0.017</td> <td>   -7.402</td> <td>   -0.714</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Aggressiv</th>                <td>    0.2908</td> <td>    4.005</td> <td>    0.073</td> <td> 0.942</td> <td>   -7.559</td> <td>    8.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Cheerful</th>                 <td>   -2.3781</td> <td>    4.047</td> <td>   -0.588</td> <td> 0.557</td> <td>  -10.310</td> <td>    5.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Nervous</th>                  <td>   -1.6690</td> <td>    1.547</td> <td>   -1.079</td> <td> 0.281</td> <td>   -4.701</td> <td>    1.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Tired</th>                    <td>   -0.3165</td> <td>    5.744</td> <td>   -0.055</td> <td> 0.956</td> <td>  -11.575</td> <td>   10.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Anger</th>              <td>   -2.4494</td> <td>   13.098</td> <td>   -0.187</td> <td> 0.852</td> <td>  -28.120</td> <td>   23.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Boredom</th>            <td>    2.4933</td> <td>   60.414</td> <td>    0.041</td> <td> 0.967</td> <td> -115.915</td> <td>  120.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Disgust</th>            <td>    0.4686</td> <td>   93.027</td> <td>    0.005</td> <td> 0.996</td> <td> -181.862</td> <td>  182.799</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Sadness</th>            <td>   -0.9602</td> <td>  130.794</td> <td>   -0.007</td> <td> 0.994</td> <td> -257.311</td> <td>  255.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Fear</th>               <td>   -1.3772</td> <td>    8.723</td> <td>   -0.158</td> <td> 0.875</td> <td>  -18.475</td> <td>   15.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Happiness</th>          <td>   -1.6784</td> <td>   30.364</td> <td>   -0.055</td> <td> 0.956</td> <td>  -61.191</td> <td>   57.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Arousal</th>            <td>    0.2736</td> <td>    5.650</td> <td>    0.048</td> <td> 0.961</td> <td>  -10.800</td> <td>   11.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Valence</th>            <td>   -2.1667</td> <td>    3.790</td> <td>   -0.572</td> <td> 0.567</td> <td>   -9.594</td> <td>    5.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q(\"Q_High Interest\")</th> <td>    0.9105</td> <td>    3.854</td> <td>    0.236</td> <td> 0.813</td> <td>   -6.643</td> <td>    8.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Aggressiv</th>          <td>   -0.5827</td> <td>   10.430</td> <td>   -0.056</td> <td> 0.955</td> <td>  -21.026</td> <td>   19.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Cheerful</th>           <td>    0.4497</td> <td>   11.588</td> <td>    0.039</td> <td> 0.969</td> <td>  -22.262</td> <td>   23.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Nervous</th>            <td>   -0.1675</td> <td>    3.886</td> <td>   -0.043</td> <td> 0.966</td> <td>   -7.784</td> <td>    7.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Tired</th>              <td>   -1.2248</td> <td>   16.170</td> <td>   -0.076</td> <td> 0.940</td> <td>  -32.917</td> <td>   30.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Anger</th>                    <td>   -0.4833</td> <td>    3.865</td> <td>   -0.125</td> <td> 0.900</td> <td>   -8.059</td> <td>    7.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Boredom</th>                  <td>   -0.8238</td> <td>   19.064</td> <td>   -0.043</td> <td> 0.966</td> <td>  -38.189</td> <td>   36.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Disgust</th>                  <td>    2.4308</td> <td>   44.573</td> <td>    0.055</td> <td> 0.957</td> <td>  -84.932</td> <td>   89.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Fear</th>                     <td>    0.2905</td> <td>    3.893</td> <td>    0.075</td> <td> 0.941</td> <td>   -7.339</td> <td>    7.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Happiness</th>                <td>   -0.7592</td> <td>    6.329</td> <td>   -0.120</td> <td> 0.905</td> <td>  -13.163</td> <td>   11.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Sadness</th>                  <td>   -1.8017</td> <td>   51.266</td> <td>   -0.035</td> <td> 0.972</td> <td> -102.281</td> <td>   98.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Arousal</th>                  <td>    2.8357</td> <td>    1.620</td> <td>    1.750</td> <td> 0.080</td> <td>   -0.340</td> <td>    6.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Valence</th>                  <td>   -2.9193</td> <td>    1.222</td> <td>   -2.388</td> <td> 0.017</td> <td>   -5.315</td> <td>   -0.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"A_High Interest\")</th>       <td>   -1.2457</td> <td>    0.981</td> <td>   -1.270</td> <td> 0.204</td> <td>   -3.168</td> <td>    0.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Aggressiv</th>                <td>   -2.6553</td> <td>    5.499</td> <td>   -0.483</td> <td> 0.629</td> <td>  -13.433</td> <td>    8.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Cheerful</th>                 <td>   -0.7260</td> <td>    7.226</td> <td>   -0.100</td> <td> 0.920</td> <td>  -14.889</td> <td>   13.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Nervous</th>                  <td>    1.6997</td> <td>    1.480</td> <td>    1.149</td> <td> 0.251</td> <td>   -1.200</td> <td>    4.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Tired</th>                    <td>    0.2412</td> <td>   10.257</td> <td>    0.024</td> <td> 0.981</td> <td>  -19.861</td> <td>   20.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Anger</th>                    <td>   -5.7362</td> <td>    3.118</td> <td>   -1.840</td> <td> 0.066</td> <td>  -11.848</td> <td>    0.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Boredom</th>                  <td>   -3.3670</td> <td>    3.757</td> <td>   -0.896</td> <td> 0.370</td> <td>  -10.731</td> <td>    3.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Disgust</th>                  <td>    1.5148</td> <td>    2.866</td> <td>    0.529</td> <td> 0.597</td> <td>   -4.102</td> <td>    7.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Fear</th>                     <td>    4.9915</td> <td>    4.247</td> <td>    1.175</td> <td> 0.240</td> <td>   -3.332</td> <td>   13.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Happiness</th>                <td>    1.9953</td> <td>    4.899</td> <td>    0.407</td> <td> 0.684</td> <td>   -7.606</td> <td>   11.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Sadness</th>                  <td>   -0.5948</td> <td>    2.675</td> <td>   -0.222</td> <td> 0.824</td> <td>   -5.838</td> <td>    4.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Arousal</th>                  <td>    6.1605</td> <td>    2.233</td> <td>    2.759</td> <td> 0.006</td> <td>    1.784</td> <td>   10.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Valence</th>                  <td>   -2.7940</td> <td>    1.383</td> <td>   -2.020</td> <td> 0.043</td> <td>   -5.506</td> <td>   -0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"P_High Interest\")</th>       <td>   -3.1505</td> <td>    1.264</td> <td>   -2.493</td> <td> 0.013</td> <td>   -5.627</td> <td>   -0.673</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Aggressiv</th>                <td>   -0.6158</td> <td>    3.105</td> <td>   -0.198</td> <td> 0.843</td> <td>   -6.701</td> <td>    5.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Cheerful</th>                 <td>   -1.6040</td> <td>    1.905</td> <td>   -0.842</td> <td> 0.400</td> <td>   -5.337</td> <td>    2.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Tired</th>                    <td>    0.3257</td> <td>    2.559</td> <td>    0.127</td> <td> 0.899</td> <td>   -4.690</td> <td>    5.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Nervous</th>                  <td>    0.5249</td> <td>    0.882</td> <td>    0.595</td> <td> 0.552</td> <td>   -1.204</td> <td>    2.254</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.33 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  A_Sex   No. Observations:                  195\n",
       "Model:                          Logit   Df Residuals:                      141\n",
       "Method:                           MLE   Df Model:                           53\n",
       "Date:                Fri, 20 Nov 2020   Pseudo R-squ.:                  0.8035\n",
       "Time:                        13:31:33   Log-Likelihood:                -26.545\n",
       "converged:                      False   LL-Null:                       -135.10\n",
       "                                        LLR p-value:                 9.619e-22\n",
       "==============================================================================================\n",
       "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     -0.2079      1.044     -0.199      0.842      -2.255       1.839\n",
       "Q_Sex                          2.1242      3.102      0.685      0.493      -3.955       8.203\n",
       "Q_Anger                       -1.5968      7.914     -0.202      0.840     -17.107      13.914\n",
       "Q_Boredom                      0.3673     40.798      0.009      0.993     -79.595      80.329\n",
       "Q_Disgust                     -0.9788     60.496     -0.016      0.987    -119.548     117.590\n",
       "Q_Sadness                      0.7060     82.025      0.009      0.993    -160.060     161.472\n",
       "Q_Fear                        -0.9302      5.894     -0.158      0.875     -12.482      10.621\n",
       "Q_Happiness                    1.3813     11.863      0.116      0.907     -21.871      24.633\n",
       "Q_Arousal                      4.1939      1.893      2.215      0.027       0.484       7.904\n",
       "Q_Valence                      0.6658      0.993      0.670      0.503      -1.281       2.613\n",
       "Q(\"Q_High Interest\")          -4.0580      1.706     -2.378      0.017      -7.402      -0.714\n",
       "Q_Aggressiv                    0.2908      4.005      0.073      0.942      -7.559       8.140\n",
       "Q_Cheerful                    -2.3781      4.047     -0.588      0.557     -10.310       5.554\n",
       "Q_Nervous                     -1.6690      1.547     -1.079      0.281      -4.701       1.363\n",
       "Q_Tired                       -0.3165      5.744     -0.055      0.956     -11.575      10.942\n",
       "Q_Sex:Q_Anger                 -2.4494     13.098     -0.187      0.852     -28.120      23.221\n",
       "Q_Sex:Q_Boredom                2.4933     60.414      0.041      0.967    -115.915     120.902\n",
       "Q_Sex:Q_Disgust                0.4686     93.027      0.005      0.996    -181.862     182.799\n",
       "Q_Sex:Q_Sadness               -0.9602    130.794     -0.007      0.994    -257.311     255.390\n",
       "Q_Sex:Q_Fear                  -1.3772      8.723     -0.158      0.875     -18.475      15.720\n",
       "Q_Sex:Q_Happiness             -1.6784     30.364     -0.055      0.956     -61.191      57.834\n",
       "Q_Sex:Q_Arousal                0.2736      5.650      0.048      0.961     -10.800      11.347\n",
       "Q_Sex:Q_Valence               -2.1667      3.790     -0.572      0.567      -9.594       5.261\n",
       "Q_Sex:Q(\"Q_High Interest\")     0.9105      3.854      0.236      0.813      -6.643       8.464\n",
       "Q_Sex:Q_Aggressiv             -0.5827     10.430     -0.056      0.955     -21.026      19.861\n",
       "Q_Sex:Q_Cheerful               0.4497     11.588      0.039      0.969     -22.262      23.161\n",
       "Q_Sex:Q_Nervous               -0.1675      3.886     -0.043      0.966      -7.784       7.449\n",
       "Q_Sex:Q_Tired                 -1.2248     16.170     -0.076      0.940     -32.917      30.467\n",
       "A_Anger                       -0.4833      3.865     -0.125      0.900      -8.059       7.092\n",
       "A_Boredom                     -0.8238     19.064     -0.043      0.966     -38.189      36.542\n",
       "A_Disgust                      2.4308     44.573      0.055      0.957     -84.932      89.793\n",
       "A_Fear                         0.2905      3.893      0.075      0.941      -7.339       7.920\n",
       "A_Happiness                   -0.7592      6.329     -0.120      0.905     -13.163      11.644\n",
       "A_Sadness                     -1.8017     51.266     -0.035      0.972    -102.281      98.678\n",
       "A_Arousal                      2.8357      1.620      1.750      0.080      -0.340       6.011\n",
       "A_Valence                     -2.9193      1.222     -2.388      0.017      -5.315      -0.523\n",
       "Q(\"A_High Interest\")          -1.2457      0.981     -1.270      0.204      -3.168       0.676\n",
       "A_Aggressiv                   -2.6553      5.499     -0.483      0.629     -13.433       8.122\n",
       "A_Cheerful                    -0.7260      7.226     -0.100      0.920     -14.889      13.437\n",
       "A_Nervous                      1.6997      1.480      1.149      0.251      -1.200       4.600\n",
       "A_Tired                        0.2412     10.257      0.024      0.981     -19.861      20.344\n",
       "P_Anger                       -5.7362      3.118     -1.840      0.066     -11.848       0.375\n",
       "P_Boredom                     -3.3670      3.757     -0.896      0.370     -10.731       3.997\n",
       "P_Disgust                      1.5148      2.866      0.529      0.597      -4.102       7.132\n",
       "P_Fear                         4.9915      4.247      1.175      0.240      -3.332      13.315\n",
       "P_Happiness                    1.9953      4.899      0.407      0.684      -7.606      11.596\n",
       "P_Sadness                     -0.5948      2.675     -0.222      0.824      -5.838       4.649\n",
       "P_Arousal                      6.1605      2.233      2.759      0.006       1.784      10.537\n",
       "P_Valence                     -2.7940      1.383     -2.020      0.043      -5.506      -0.082\n",
       "Q(\"P_High Interest\")          -3.1505      1.264     -2.493      0.013      -5.627      -0.673\n",
       "P_Aggressiv                   -0.6158      3.105     -0.198      0.843      -6.701       5.469\n",
       "P_Cheerful                    -1.6040      1.905     -0.842      0.400      -5.337       2.129\n",
       "P_Tired                        0.3257      2.559      0.127      0.899      -4.690       5.341\n",
       "P_Nervous                      0.5249      0.882      0.595      0.552      -1.204       2.254\n",
       "==============================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.33 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The below code throws an LinAlgError: Singular Matrix; Furthermore I get Runtime Warnings concerning overflow and \n",
    "#division by zero (which aligns with the above inf values for affect of Question and Answer)\n",
    "#to prevent this error we use the bfgs method (https://stackoverflow.com/questions/20703733/logit-regression-and-singular-matrix-error-in-python)\n",
    "#Using this, we get results, but the model does not converge\n",
    "emo_sex_model = smf.logit('A_Sex ~ Q_Sex * (Q_Anger + Q_Boredom + Q_Disgust + Q_Sadness + Q_Fear + Q_Happiness + Q_Arousal + Q_Valence + Q(\"Q_High Interest\") + Q_Aggressiv + Q_Cheerful + Q_Nervous + Q_Tired) + A_Anger + A_Boredom + A_Disgust + A_Fear + A_Happiness + A_Sadness + A_Arousal + A_Valence +Q(\"A_High Interest\") + A_Aggressiv + A_Cheerful + A_Nervous + A_Tired + P_Anger + P_Boredom + P_Disgust + P_Fear + P_Happiness + P_Sadness + P_Arousal + P_Valence + Q(\"P_High Interest\") + P_Aggressiv + P_Cheerful + P_Tired + P_Nervous', data = data)\n",
    "emotion_res = emo_sex_model.fit(method = 'bfgs')\n",
    "emotion_res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That the above model does not converge is no surprise, since we use all features, even if they are collinear. This is why we now go on and only use the features that were not dropped using VIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.250974\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>A_Sex</td>      <th>  No. Observations:  </th>  <td>   195</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   162</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    32</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Fri, 20 Nov 2020</td> <th>  Pseudo R-squ.:     </th>  <td>0.6377</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:31:33</td>     <th>  Log-Likelihood:    </th> <td> -48.940</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -135.10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.769e-21</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                    <td>    0.0510</td> <td>    0.360</td> <td>    0.142</td> <td> 0.887</td> <td>   -0.655</td> <td>    0.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex</th>                        <td>    0.4246</td> <td>    0.720</td> <td>    0.590</td> <td> 0.555</td> <td>   -0.986</td> <td>    1.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Anger</th>                      <td>    0.0213</td> <td>    0.472</td> <td>    0.045</td> <td> 0.964</td> <td>   -0.903</td> <td>    0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Disgust</th>                    <td>   -0.4828</td> <td>    0.514</td> <td>   -0.940</td> <td> 0.347</td> <td>   -1.489</td> <td>    0.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Fear</th>                       <td>    0.1891</td> <td>    0.646</td> <td>    0.293</td> <td> 0.770</td> <td>   -1.077</td> <td>    1.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Arousal</th>                    <td>    2.2794</td> <td>    0.805</td> <td>    2.830</td> <td> 0.005</td> <td>    0.701</td> <td>    3.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Valence</th>                    <td>    0.2009</td> <td>    0.403</td> <td>    0.498</td> <td> 0.619</td> <td>   -0.590</td> <td>    0.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Cheerful</th>                   <td>   -1.4154</td> <td>    0.484</td> <td>   -2.922</td> <td> 0.003</td> <td>   -2.365</td> <td>   -0.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Nervous</th>                    <td>   -0.6492</td> <td>    0.455</td> <td>   -1.428</td> <td> 0.153</td> <td>   -1.540</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Q_Normal Interest\")</th>       <td>    2.6090</td> <td>    0.709</td> <td>    3.680</td> <td> 0.000</td> <td>    1.219</td> <td>    3.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Anger</th>                <td>   -2.5765</td> <td>    2.382</td> <td>   -1.082</td> <td> 0.279</td> <td>   -7.244</td> <td>    2.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Disgust</th>              <td>    0.3829</td> <td>    1.128</td> <td>    0.340</td> <td> 0.734</td> <td>   -1.827</td> <td>    2.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Fear</th>                 <td>   -0.5119</td> <td>    1.929</td> <td>   -0.265</td> <td> 0.791</td> <td>   -4.293</td> <td>    3.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Arousal</th>              <td>    1.0473</td> <td>    1.195</td> <td>    0.877</td> <td> 0.381</td> <td>   -1.295</td> <td>    3.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Valence</th>              <td>   -1.3552</td> <td>    1.003</td> <td>   -1.352</td> <td> 0.176</td> <td>   -3.320</td> <td>    0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Cheerful</th>             <td>    1.4348</td> <td>    0.785</td> <td>    1.827</td> <td> 0.068</td> <td>   -0.104</td> <td>    2.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q_Nervous</th>              <td>   -1.2332</td> <td>    1.160</td> <td>   -1.063</td> <td> 0.288</td> <td>   -3.507</td> <td>    1.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q_Sex:Q(\"Q_Normal Interest\")</th> <td>   -0.3645</td> <td>    0.881</td> <td>   -0.413</td> <td> 0.679</td> <td>   -2.092</td> <td>    1.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Anger</th>                      <td>   -0.6175</td> <td>    0.574</td> <td>   -1.076</td> <td> 0.282</td> <td>   -1.742</td> <td>    0.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Disgust</th>                    <td>    1.2437</td> <td>    0.540</td> <td>    2.305</td> <td> 0.021</td> <td>    0.186</td> <td>    2.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Fear</th>                       <td>    0.2410</td> <td>    0.576</td> <td>    0.418</td> <td> 0.676</td> <td>   -0.889</td> <td>    1.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Arousal</th>                    <td>    1.5344</td> <td>    0.684</td> <td>    2.245</td> <td> 0.025</td> <td>    0.195</td> <td>    2.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Valence</th>                    <td>   -1.9476</td> <td>    0.659</td> <td>   -2.954</td> <td> 0.003</td> <td>   -3.240</td> <td>   -0.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Cheerful</th>                   <td>   -0.8813</td> <td>    0.402</td> <td>   -2.192</td> <td> 0.028</td> <td>   -1.669</td> <td>   -0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>A_Nervous</th>                    <td>    0.8848</td> <td>    0.437</td> <td>    2.025</td> <td> 0.043</td> <td>    0.028</td> <td>    1.741</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"A_Normal Interest\")</th>       <td>    0.4414</td> <td>    0.484</td> <td>    0.912</td> <td> 0.362</td> <td>   -0.508</td> <td>    1.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Anger</th>                      <td>   -1.4028</td> <td>    0.496</td> <td>   -2.826</td> <td> 0.005</td> <td>   -2.376</td> <td>   -0.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Disgust</th>                    <td>    0.6686</td> <td>    0.601</td> <td>    1.112</td> <td> 0.266</td> <td>   -0.510</td> <td>    1.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Arousal</th>                    <td>    2.9897</td> <td>    0.928</td> <td>    3.220</td> <td> 0.001</td> <td>    1.170</td> <td>    4.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Valence</th>                    <td>   -1.4149</td> <td>    0.572</td> <td>   -2.474</td> <td> 0.013</td> <td>   -2.536</td> <td>   -0.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"P_Normal Interest\")</th>       <td>    1.2949</td> <td>    0.610</td> <td>    2.123</td> <td> 0.034</td> <td>    0.099</td> <td>    2.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Cheerful</th>                   <td>   -0.5850</td> <td>    0.409</td> <td>   -1.431</td> <td> 0.152</td> <td>   -1.386</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Nervous</th>                    <td>    0.1098</td> <td>    0.399</td> <td>    0.275</td> <td> 0.783</td> <td>   -0.671</td> <td>    0.891</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.13 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  A_Sex   No. Observations:                  195\n",
       "Model:                          Logit   Df Residuals:                      162\n",
       "Method:                           MLE   Df Model:                           32\n",
       "Date:                Fri, 20 Nov 2020   Pseudo R-squ.:                  0.6377\n",
       "Time:                        13:31:33   Log-Likelihood:                -48.940\n",
       "converged:                       True   LL-Null:                       -135.10\n",
       "                                        LLR p-value:                 3.769e-21\n",
       "================================================================================================\n",
       "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------\n",
       "Intercept                        0.0510      0.360      0.142      0.887      -0.655       0.757\n",
       "Q_Sex                            0.4246      0.720      0.590      0.555      -0.986       1.835\n",
       "Q_Anger                          0.0213      0.472      0.045      0.964      -0.903       0.946\n",
       "Q_Disgust                       -0.4828      0.514     -0.940      0.347      -1.489       0.524\n",
       "Q_Fear                           0.1891      0.646      0.293      0.770      -1.077       1.455\n",
       "Q_Arousal                        2.2794      0.805      2.830      0.005       0.701       3.858\n",
       "Q_Valence                        0.2009      0.403      0.498      0.619      -0.590       0.992\n",
       "Q_Cheerful                      -1.4154      0.484     -2.922      0.003      -2.365      -0.466\n",
       "Q_Nervous                       -0.6492      0.455     -1.428      0.153      -1.540       0.242\n",
       "Q(\"Q_Normal Interest\")           2.6090      0.709      3.680      0.000       1.219       3.999\n",
       "Q_Sex:Q_Anger                   -2.5765      2.382     -1.082      0.279      -7.244       2.091\n",
       "Q_Sex:Q_Disgust                  0.3829      1.128      0.340      0.734      -1.827       2.593\n",
       "Q_Sex:Q_Fear                    -0.5119      1.929     -0.265      0.791      -4.293       3.269\n",
       "Q_Sex:Q_Arousal                  1.0473      1.195      0.877      0.381      -1.295       3.389\n",
       "Q_Sex:Q_Valence                 -1.3552      1.003     -1.352      0.176      -3.320       0.610\n",
       "Q_Sex:Q_Cheerful                 1.4348      0.785      1.827      0.068      -0.104       2.974\n",
       "Q_Sex:Q_Nervous                 -1.2332      1.160     -1.063      0.288      -3.507       1.041\n",
       "Q_Sex:Q(\"Q_Normal Interest\")    -0.3645      0.881     -0.413      0.679      -2.092       1.363\n",
       "A_Anger                         -0.6175      0.574     -1.076      0.282      -1.742       0.507\n",
       "A_Disgust                        1.2437      0.540      2.305      0.021       0.186       2.301\n",
       "A_Fear                           0.2410      0.576      0.418      0.676      -0.889       1.371\n",
       "A_Arousal                        1.5344      0.684      2.245      0.025       0.195       2.874\n",
       "A_Valence                       -1.9476      0.659     -2.954      0.003      -3.240      -0.656\n",
       "A_Cheerful                      -0.8813      0.402     -2.192      0.028      -1.669      -0.093\n",
       "A_Nervous                        0.8848      0.437      2.025      0.043       0.028       1.741\n",
       "Q(\"A_Normal Interest\")           0.4414      0.484      0.912      0.362      -0.508       1.390\n",
       "P_Anger                         -1.4028      0.496     -2.826      0.005      -2.376      -0.430\n",
       "P_Disgust                        0.6686      0.601      1.112      0.266      -0.510       1.847\n",
       "P_Arousal                        2.9897      0.928      3.220      0.001       1.170       4.809\n",
       "P_Valence                       -1.4149      0.572     -2.474      0.013      -2.536      -0.294\n",
       "Q(\"P_Normal Interest\")           1.2949      0.610      2.123      0.034       0.099       2.490\n",
       "P_Cheerful                      -0.5850      0.409     -1.431      0.152      -1.386       0.216\n",
       "P_Nervous                        0.1098      0.399      0.275      0.783      -0.671       0.891\n",
       "================================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.13 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smf.logit('A_Sex ~ Q_Sex * (Q_Anger + Q_Disgust + Q_Fear + Q_Arousal + Q_Valence + Q_Cheerful + Q_Nervous + Q(\"Q_Normal Interest\")) + A_Anger + A_Disgust + A_Fear + A_Arousal + A_Valence + A_Cheerful + A_Nervous + Q(\"A_Normal Interest\") + P_Anger + P_Disgust + P_Arousal + P_Valence + Q(\"P_Normal Interest\")+ P_Cheerful + P_Nervous', data = df_vif2)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
