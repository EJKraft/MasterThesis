{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kruskal Wallis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import statsmodels.api as sm\n",
    "import sklearn.preprocessing as pp\n",
    "#import nltk\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import Helper as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load .csv data with results of OpenSMILE Analysis\n",
    "First we load .csv data and clean it (removing of NaNs), then we store information of all files in seperate panda dataframes containing information about affect, emotion and valence/arousal for all participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"CHI_2019_FULL.csv\")\n",
    "\n",
    "#Set Labels \n",
    "emotion_label = ['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness']\n",
    "affect_label = ['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired']\n",
    "loi_label = ['Disinterest', 'Normal', 'High Interest']\n",
    "\n",
    "#Get specific data and save it into new data frames\n",
    "# We use the pandas .copy(deep=True) function to prevent the SettingWithCopyWarning we would otherwise get. Since we do\n",
    "# not write, but only read from the data, the warning does not affect the data frames\n",
    "df_emotion = data[['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness', 'Filename']].copy(deep=True)\n",
    "df_affect = data[['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired', 'Filename']].copy(deep=True)\n",
    "df_loi = data[['Disinterest', 'Normal', 'High Interest', 'Filename']].copy(deep=True)\n",
    "df_ar_val = data[['Arousal', 'Valence', 'Filename']].copy(deep=True)\n",
    "#For further usage, we want to append the CharacterID as a column, which is saved with other information in the filename\n",
    "#Since we only want the digits, we can remove all non-digit characters of the filename column and append the column to the df\n",
    "\n",
    "df_emotion['Char_ID'] = df_emotion['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_affect['Char_ID'] = df_affect['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_loi['Char_ID'] = df_loi['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Filename'].replace('\\D+','', regex = True).copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load information about the speakers\n",
    "The speaker ID is saved in a single .csv file containing four important columns: ID, Age, Sex and Acadedmic Status. Since before loaded OpenSMILE csv files are named using the corresponding index (ex. speaker with id 0 has two files 0_a.csv and 0_b.csv), so that a link can be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_data = pd.read_csv(\"CHI_2019_CharacterData.csv\")  \n",
    "\n",
    "#Join above tables and Character Tables\n",
    "\n",
    "#To Join DataFrames we have to cast the column on which we want to join to int, so that both columns have the same data type\n",
    "char_data['ID'] = char_data['ID'].astype(int)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Char_ID'].astype(int)\n",
    "df_emotion['Char_ID'] = df_emotion['Char_ID'].astype(int)\n",
    "df_affect['Char_ID'] = df_affect['Char_ID'].astype(int)\n",
    "df_loi['Char_ID'] = df_loi['Char_ID'].astype(int)\n",
    "\n",
    "#Safe new data frames\n",
    "df_ar_val_char = df_ar_val.merge(char_data, how = 'left', left_on='Char_ID', right_on='ID')\n",
    "df_emotion_char = df_emotion.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_affect_char = df_affect.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_loi_char = df_loi.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "\n",
    "arval_sentence_type = df_ar_val_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_ar_val_char['SentenceType'] = arval_sentence_type\n",
    "emo_sentence_type = df_emotion_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_emotion_char['SentenceType'] = emo_sentence_type\n",
    "aff_sentence_type = df_affect_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_affect_char['SentenceType'] = aff_sentence_type\n",
    "loi_sentence_type = df_loi_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_loi_char['SentenceType'] = loi_sentence_type\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'a']\n",
    "df_emotion_char = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'a']\n",
    "df_affect_char = df_affect_char.loc[df_affect_char['SentenceType'] == 'a']\n",
    "df_loi_char = df_loi_char.loc[df_loi_char['SentenceType'] == 'a']\n",
    "\n",
    "affect_label.remove('Intoxicated')\n",
    "df_affect_char = df_affect_char.drop(['Intoxicated'], axis = 1)\n",
    "norm_test = pp.normalize(df_affect_char[affect_label], norm = 'l1')\n",
    "df_affect_char[affect_label] = norm_test\n",
    "\n",
    "df_loi_char['Normal Interest'] = df_loi_char['Disinterest'] + df_loi_char['Normal']\n",
    "df_loi_char = df_loi_char.drop(['Disinterest', 'Normal'], axis = 1)\n",
    "loi_label = ['Normal Interest', 'High Interest']\n",
    "\n",
    "#Now let's compensate for multiple samples of the same person\n",
    "IDs = df_emotion_char['Char_ID'].copy()\n",
    "IDs.drop_duplicates()\n",
    "\n",
    "# I know that for loops make the following operations very very slow, but I could not find a way to get this\n",
    "# working with pd.apply and lambda functions... \n",
    "\n",
    "for i in IDs:\n",
    "    #first for emotion\n",
    "    for l in emotion_label:    \n",
    "        emo = df_emotion_char.loc[df_emotion_char.Char_ID == i,l]\n",
    "        emo_neu = hp.constructMedianSeries(emo)\n",
    "        df_emotion_char.loc[df_emotion_char.Char_ID == i,l] = emo_neu\n",
    "    #Then for affect\n",
    "    for l in affect_label:    \n",
    "        aff = df_affect_char.loc[df_affect_char.Char_ID == i,l]\n",
    "        aff_neu = hp.constructMedianSeries(aff)\n",
    "        df_affect_char.loc[df_affect_char.Char_ID == i,l] = aff_neu  \n",
    "    for l in loi_label:    \n",
    "        loi = df_loi_char.loc[df_loi_char.Char_ID == i,l]\n",
    "        loi_neu = hp.constructMedianSeries(loi)\n",
    "        df_loi_char.loc[df_loi_char.Char_ID == i,l] = loi_neu  \n",
    "    for l in ['Arousal', 'Valence']:    \n",
    "        arval = df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l]\n",
    "        arval_neu = hp.constructMedianSeries(arval)\n",
    "        df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l] = arval_neu  \n",
    "        \n",
    "#Now let's drop the duplicate values, since we only need one row now per person\n",
    "df_emotion_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_affect_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_loi_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_ar_val_char.drop_duplicates(subset=['ID'], inplace = True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kruskal-Wallis Test\n",
    "\n",
    "Scipy stats documentation says to input measurement data, so we go ahead and use our floating point data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOF: 1\n",
      "EMOTION\n",
      "\n",
      "Anger: \t\tKruskalResult(statistic=0.36549672813799816, pvalue=0.5454692285028313)\n",
      "Boredom: \tKruskalResult(statistic=0.6447055324211703, pvalue=0.4220119745039995)\n",
      "Disgust: \tKruskalResult(statistic=21.86421772754312, pvalue=2.92640223905134e-06)\n",
      "Fear: \t\tKruskalResult(statistic=1.6262641284949666, pvalue=0.2022205517145667)\n",
      "Happiness: \tKruskalResult(statistic=0.0043723973825251505, pvalue=0.9472790191064381)\n",
      "Emo_Neutral: \tKruskalResult(statistic=1.5784354550862645, pvalue=0.20898619755328388)\n",
      "Sadness: \tKruskalResult(statistic=14.34869125520521, pvalue=0.00015188523776121654)\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Aggressiv: \tKruskalResult(statistic=8.91041046995835, pvalue=0.002835495242374991)\n",
      "Cheerful: \tKruskalResult(statistic=1.9810529446758096, pvalue=0.15927952518331756)\n",
      "Nervous: \tKruskalResult(statistic=0.00892325996429122, pvalue=0.9247413659949347)\n",
      "Aff_Neutral: \tKruskalResult(statistic=1.6993456276026109, pvalue=0.19237357698400848)\n",
      "Tired: \t\tKruskalResult(statistic=3.75, pvalue=0.052807511416113395)\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Arousal: \tKruskalResult(statistic=10.682569898869701, pvalue=0.0010814971137763786)\n",
      "Valence: \tKruskalResult(statistic=5.312552052349787, pvalue=0.021172319929388287)\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Normal Interest: \tKruskalResult(statistic=1.4392325996430486, pvalue=0.23026356286404154)\n",
      "High Interest: \tKruskalResult(statistic=1.4392325996430486, pvalue=0.23026356286404154)\n"
     ]
    }
   ],
   "source": [
    "print('DOF: 1') #Because of two groups, DOF is 1\n",
    "print('EMOTION\\n')\n",
    "emo_sex = hp.kruskal_wallis(df_emotion_char, emotion_label, 'Sex', True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_sex = hp.kruskal_wallis(df_affect_char, affect_label,'Sex',  True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_sex = hp.kruskal_wallis(df_ar_val_char, ['Arousal', 'Valence'], 'Sex', True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_sex = hp.kruskal_wallis(df_loi_char, ['Normal Interest', 'High Interest'], 'Sex', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOF: 1\n",
      "EMOTION\n",
      "\n",
      "Anger: \t\tKruskalResult(statistic=0.9545086049151053, pvalue=0.3285743197687922)\n",
      "Boredom: \tKruskalResult(statistic=0.002802677599447634, pvalue=0.9577794578225967)\n",
      "Disgust: \tKruskalResult(statistic=0.15956732216895375, pvalue=0.6895551854019952)\n",
      "Fear: \t\tKruskalResult(statistic=0.6154077780093985, pvalue=0.43275892124692017)\n",
      "Happiness: \tKruskalResult(statistic=0.973409306742667, pvalue=0.3238313769939256)\n",
      "Emo_Neutral: \tKruskalResult(statistic=0.02837421536608531, pvalue=0.8662320476486972)\n",
      "Sadness: \tKruskalResult(statistic=0.025224098394829753, pvalue=0.8738099320903019)\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Aggressiv: \tKruskalResult(statistic=2.15470317096333, pvalue=0.14213390887117017)\n",
      "Cheerful: \tKruskalResult(statistic=0.008361707548715458, pvalue=0.9271410941127346)\n",
      "Nervous: \tKruskalResult(statistic=1.2359808213466579, pvalue=0.2662470558739207)\n",
      "Aff_Neutral: \tKruskalResult(statistic=1.0117666133926377, pvalue=0.31447998482558126)\n",
      "Tired: \t\tKruskalResult(statistic=1.0312232182151035, pvalue=0.30987154197376754)\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Arousal: \tKruskalResult(statistic=3.7618187292983976, pvalue=0.05243551475102616)\n",
      "Valence: \tKruskalResult(statistic=1.0508651240358517, pvalue=0.3053079251530546)\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Normal Interest: \tKruskalResult(statistic=0.8273921200750181, pvalue=0.3630277102508763)\n",
      "High Interest: \tKruskalResult(statistic=0.8273921200750181, pvalue=0.3630277102508763)\n"
     ]
    }
   ],
   "source": [
    "print('DOF: 1') #Because of two groups, DOF is 1\n",
    "print('EMOTION\\n')\n",
    "emo_sex = hp.kruskal_wallis(df_emotion_char, emotion_label, 'Academic Status', True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_sex = hp.kruskal_wallis(df_affect_char, affect_label,'Academic Status',  True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_sex = hp.kruskal_wallis(df_ar_val_char, ['Arousal', 'Valence'], 'Academic Status', True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_sex = hp.kruskal_wallis(df_loi_char, ['Normal Interest', 'High Interest'], 'Academic Status', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
