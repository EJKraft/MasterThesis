{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHI Square Test\n",
    "To further look into differences in our data, we conduct multiple chi² tests to see if there are any significant differences between females/males and grad students/PhDs regarding different emotion, affect, level of interest and arousal valence attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import sklearn.preprocessing as pp\n",
    "import statsmodels.api as sm\n",
    "#import nltk\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import Helper as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load .csv data with results of OpenSMILE Analysis\n",
    "First we load .csv data and clean it (removing of NaNs), then we store information of all files in seperate panda dataframes containing information about affect, emotion and valence/arousal for all participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"CHI_2019_FULL.csv\")\n",
    "\n",
    "#Set Labels \n",
    "emotion_label = ['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness']\n",
    "affect_label = ['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired']\n",
    "loi_label = ['Disinterest', 'Normal', 'High Interest']\n",
    "\n",
    "#Get specific data and save it into new data frames\n",
    "# We use the pandas .copy(deep=True) function to prevent the SettingWithCopyWarning we would otherwise get. Since we do\n",
    "# not write, but only read from the data, the warning does not affect the data frames\n",
    "df_emotion = data[['Anger', 'Boredom', 'Disgust', 'Fear', 'Happiness', 'Emo_Neutral', 'Sadness', 'Filename']].copy(deep=True)\n",
    "df_affect = data[['Aggressiv', 'Cheerful', 'Intoxicated', 'Nervous', 'Aff_Neutral', 'Tired', 'Filename']].copy(deep=True)\n",
    "df_loi = data[['Disinterest', 'Normal', 'High Interest', 'Filename']].copy(deep=True)\n",
    "df_ar_val = data[['Arousal', 'Valence', 'Filename']].copy(deep=True)\n",
    "#For further usage, we want to append the CharacterID as a column, which is saved with other information in the filename\n",
    "#Since we only want the digits, we can remove all non-digit characters of the filename column and append the column to the df\n",
    "\n",
    "df_emotion['Char_ID'] = df_emotion['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_affect['Char_ID'] = df_affect['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_loi['Char_ID'] = df_loi['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Filename'].replace('\\D+','', regex = True).copy(deep=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load information about the speakers\n",
    "The speaker ID is saved in a single .csv file containing four important columns: ID, Age, Sex and Acadedmic Status. Since before loaded OpenSMILE csv files are named using the corresponding index (ex. speaker with id 0 has two files 0_a.csv and 0_b.csv), so that a link can be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_data = pd.read_csv(\"CHI_2019_CharacterData.csv\")  \n",
    "\n",
    "#Join above tables and Character Tables\n",
    "\n",
    "#To Join DataFrames we have to cast the column on which we want to join to int, so that both columns have the same data type\n",
    "char_data['ID'] = char_data['ID'].astype(int)\n",
    "df_ar_val['Char_ID'] = df_ar_val['Char_ID'].astype(int)\n",
    "df_emotion['Char_ID'] = df_emotion['Char_ID'].astype(int)\n",
    "df_affect['Char_ID'] = df_affect['Char_ID'].astype(int)\n",
    "df_loi['Char_ID'] = df_loi['Char_ID'].astype(int)\n",
    "\n",
    "#Safe new data frames\n",
    "df_ar_val_char = df_ar_val.merge(char_data, how = 'left', left_on='Char_ID', right_on='ID')\n",
    "df_emotion_char = df_emotion.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_affect_char = df_affect.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "df_loi_char = df_loi.merge(char_data, how = 'left', left_on='Char_ID', right_on= 'ID')\n",
    "\n",
    "#Now, we only want to have data containing information about the answers\n",
    "#For that we need to extract from the filename column, whether the file was part of an answer\n",
    "#a = answer, p = presentation, q = question\n",
    "#sentence_type should be the same for all tables, but just to be sure\n",
    "arval_sentence_type = df_ar_val_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_ar_val_char['SentenceType'] = arval_sentence_type\n",
    "emo_sentence_type = df_emotion_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_emotion_char['SentenceType'] = emo_sentence_type\n",
    "aff_sentence_type = df_affect_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_affect_char['SentenceType'] = aff_sentence_type\n",
    "loi_sentence_type = df_loi_char.Filename.str.replace('\\d+','').str[3:-4]\n",
    "df_loi_char['SentenceType'] = loi_sentence_type\n",
    "\n",
    "#Now select only those who have SentenceType == 'a'\n",
    "df_ar_val_char = df_ar_val_char.loc[df_ar_val_char['SentenceType'] == 'a']\n",
    "df_emotion_char = df_emotion_char.loc[df_emotion_char['SentenceType'] == 'a']\n",
    "df_affect_char = df_affect_char.loc[df_affect_char['SentenceType'] == 'a']\n",
    "df_loi_char = df_loi_char.loc[df_loi_char['SentenceType'] == 'a']\n",
    "\n",
    "affect_label.remove('Intoxicated')\n",
    "df_affect_char = df_affect_char.drop(['Intoxicated'], axis = 1)\n",
    "norm_test = pp.normalize(df_affect_char[affect_label], norm = 'l1')\n",
    "df_affect_char[affect_label] = norm_test\n",
    "\n",
    "df_loi_char['Normal Interest'] = df_loi_char['Disinterest'] + df_loi_char['Normal']\n",
    "df_loi_char = df_loi_char.drop(['Disinterest', 'Normal'], axis = 1)\n",
    "loi_label = ['Normal Interest', 'High Interest']\n",
    "\n",
    "#Now let's compensate for multiple samples of the same person\n",
    "IDs = df_emotion_char['Char_ID'].copy()\n",
    "IDs.drop_duplicates()\n",
    "\n",
    "# I know that for loops make the following operations very very slow, but I could not find a way to get this\n",
    "# working with pd.apply and lambda functions... \n",
    "\n",
    "for i in IDs:\n",
    "    #first for emotion\n",
    "    for l in emotion_label:    \n",
    "        emo = df_emotion_char.loc[df_emotion_char.Char_ID == i,l]\n",
    "        emo_neu = hp.constructMedianSeries(emo)\n",
    "        df_emotion_char.loc[df_emotion_char.Char_ID == i,l] = emo_neu\n",
    "    #Then for affect\n",
    "    for l in affect_label:    \n",
    "        aff = df_affect_char.loc[df_affect_char.Char_ID == i,l]\n",
    "        aff_neu = hp.constructMedianSeries(aff)\n",
    "        df_affect_char.loc[df_affect_char.Char_ID == i,l] = aff_neu  \n",
    "    for l in loi_label:    \n",
    "        loi = df_loi_char.loc[df_loi_char.Char_ID == i,l]\n",
    "        loi_neu = hp.constructMedianSeries(loi)\n",
    "        df_loi_char.loc[df_loi_char.Char_ID == i,l] = loi_neu  \n",
    "    for l in ['Arousal', 'Valence']:    \n",
    "        arval = df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l]\n",
    "        arval_neu = hp.constructMedianSeries(arval)\n",
    "        df_ar_val_char.loc[df_ar_val_char.Char_ID == i,l] = arval_neu  \n",
    "        \n",
    "#Now let's drop the duplicate values, since we only need one row now per person\n",
    "df_emotion_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_affect_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_loi_char.drop_duplicates(subset=['ID'], inplace = True)\n",
    "df_ar_val_char.drop_duplicates(subset=['ID'], inplace = True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared Test of Independence\n",
    "We Start with characteristic sex. The null hypothesis states that the two categorical variables sex and e.g. emotion are independent.\n",
    "\n",
    "Since we have float data and chi² needs integer data, such as observation counts, we have to convert our data. To illustrate how this is done, we'll look at a specific emotion, 'Anger'. We need to make sure that in our observation count, we do not have any cells with a value of less than 5, since this yields errors and may falsify the result. So we calculate the quantiles of our emotion 'Anger', which yields us three thresholds to compare the float data. This way, we can count how many samples were in the 1st, 2nd, 3rd or 4th Quantile. We want to compare two (or more) groups, so we compare only the female values and sort them into quartiles, then for male values. This yields a 2x4 table. An example table is printed below. This table is used to calculate the chi2 statistic. Note that the function 'calcFrequencyTable' takes in a pd.DataFrame, not a pd.Series and returns an array of pd.DataFrames. This means, that the function calculates these tables for all different emotions defined in e.g. emotion_label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Char_ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>VideoTitle</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Academic Status</th>\n",
       "      <th>VideoID</th>\n",
       "      <th>IsNativeSpeaker</th>\n",
       "      <th>SentenceType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.350267</td>\n",
       "      <td>0.057099</td>\n",
       "      <td>192_a_a.wav</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>23 Ways to Nudge: Review of Technology-Mediate...</td>\n",
       "      <td>Ana Caraban</td>\n",
       "      <td>Female</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>-U3Bo7KR108</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.032463</td>\n",
       "      <td>0.065131</td>\n",
       "      <td>197_a_a.wav</td>\n",
       "      <td>197</td>\n",
       "      <td>197</td>\n",
       "      <td>A Badge, Not a Barrier: Designing for- and Trh...</td>\n",
       "      <td>Caroline Pitt</td>\n",
       "      <td>Female</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>HxMSkH5ZpZI</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.135614</td>\n",
       "      <td>0.013635</td>\n",
       "      <td>200_a_a.wav</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>A Change of Perspective: Designing Automated v...</td>\n",
       "      <td>Lenja Sorokin</td>\n",
       "      <td>Female</td>\n",
       "      <td>PhD</td>\n",
       "      <td>SmnSU4QceSk</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.140131</td>\n",
       "      <td>0.043628</td>\n",
       "      <td>203_a_a.wav</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>A Design Space for Gaze Interaction on HMD</td>\n",
       "      <td>Teresa Hirzle</td>\n",
       "      <td>Female</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>91VMIz6MAZ8</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.254557</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>207_a_a.wav</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>Analyzing Value Discovery in Design Decisions ...</td>\n",
       "      <td>Sai Shruthi Chivukula</td>\n",
       "      <td>Female</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>3lV3YQUvyyY</td>\n",
       "      <td>Asian Non-Native</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>0.244323</td>\n",
       "      <td>0.120048</td>\n",
       "      <td>447_a_a.wav</td>\n",
       "      <td>447</td>\n",
       "      <td>447</td>\n",
       "      <td>Implementing Multi-Touch Gestures with Touch G...</td>\n",
       "      <td>Brad Myers</td>\n",
       "      <td>Male</td>\n",
       "      <td>PhD</td>\n",
       "      <td>didYdY83zoc</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>-0.000361</td>\n",
       "      <td>0.105117</td>\n",
       "      <td>451_a_a.wav</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>Improving Early Navigation in Time-Lapse Video...</td>\n",
       "      <td>Michael Van Der Kamp</td>\n",
       "      <td>Male</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>G-LMD3Ro_hQ</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0.174183</td>\n",
       "      <td>0.129396</td>\n",
       "      <td>455_a_a.wav</td>\n",
       "      <td>455</td>\n",
       "      <td>455</td>\n",
       "      <td>In a Silent Way: Communication Between AI and ...</td>\n",
       "      <td>Jon McCormack</td>\n",
       "      <td>Male</td>\n",
       "      <td>PhD</td>\n",
       "      <td>r5KA1Jo_vYU</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0.207187</td>\n",
       "      <td>-0.021107</td>\n",
       "      <td>457_a_a.wav</td>\n",
       "      <td>457</td>\n",
       "      <td>457</td>\n",
       "      <td>Interferi: Gesture Sensing using On-Body Acous...</td>\n",
       "      <td>Yasha Iravantchi</td>\n",
       "      <td>Male</td>\n",
       "      <td>Grad Student</td>\n",
       "      <td>xBpBBpQh7GI</td>\n",
       "      <td>Native Speaker</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0.084669</td>\n",
       "      <td>0.074428</td>\n",
       "      <td>464_a_a.wav</td>\n",
       "      <td>464</td>\n",
       "      <td>464</td>\n",
       "      <td>Interpreting the Diversity in Subjective Judgm...</td>\n",
       "      <td>Jean-Bernard Martens</td>\n",
       "      <td>Male</td>\n",
       "      <td>PhD</td>\n",
       "      <td>pS7CzHfawDU</td>\n",
       "      <td>Europ. Non-Native</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Arousal   Valence     Filename  Char_ID   ID  \\\n",
       "0    0.350267  0.057099  192_a_a.wav      192  192   \n",
       "11   0.032463  0.065131  197_a_a.wav      197  197   \n",
       "18   0.135614  0.013635  200_a_a.wav      200  200   \n",
       "25   0.140131  0.043628  203_a_a.wav      203  203   \n",
       "34   0.254557  0.002145  207_a_a.wav      207  207   \n",
       "..        ...       ...          ...      ...  ...   \n",
       "590  0.244323  0.120048  447_a_a.wav      447  447   \n",
       "599 -0.000361  0.105117  451_a_a.wav      451  451   \n",
       "608  0.174183  0.129396  455_a_a.wav      455  455   \n",
       "613  0.207187 -0.021107  457_a_a.wav      457  457   \n",
       "628  0.084669  0.074428  464_a_a.wav      464  464   \n",
       "\n",
       "                                            VideoTitle                   Name  \\\n",
       "0    23 Ways to Nudge: Review of Technology-Mediate...            Ana Caraban   \n",
       "11   A Badge, Not a Barrier: Designing for- and Trh...          Caroline Pitt   \n",
       "18   A Change of Perspective: Designing Automated v...          Lenja Sorokin   \n",
       "25          A Design Space for Gaze Interaction on HMD          Teresa Hirzle   \n",
       "34   Analyzing Value Discovery in Design Decisions ...  Sai Shruthi Chivukula   \n",
       "..                                                 ...                    ...   \n",
       "590  Implementing Multi-Touch Gestures with Touch G...             Brad Myers   \n",
       "599  Improving Early Navigation in Time-Lapse Video...   Michael Van Der Kamp   \n",
       "608  In a Silent Way: Communication Between AI and ...          Jon McCormack   \n",
       "613  Interferi: Gesture Sensing using On-Body Acous...       Yasha Iravantchi   \n",
       "628  Interpreting the Diversity in Subjective Judgm...   Jean-Bernard Martens   \n",
       "\n",
       "        Sex Academic Status      VideoID    IsNativeSpeaker SentenceType  \n",
       "0    Female    Grad Student  -U3Bo7KR108  Europ. Non-Native            a  \n",
       "11   Female    Grad Student  HxMSkH5ZpZI     Native Speaker            a  \n",
       "18   Female             PhD  SmnSU4QceSk  Europ. Non-Native            a  \n",
       "25   Female    Grad Student  91VMIz6MAZ8  Europ. Non-Native            a  \n",
       "34   Female    Grad Student  3lV3YQUvyyY   Asian Non-Native            a  \n",
       "..      ...             ...          ...                ...          ...  \n",
       "590    Male             PhD  didYdY83zoc     Native Speaker            a  \n",
       "599    Male    Grad Student  G-LMD3Ro_hQ     Native Speaker            a  \n",
       "608    Male             PhD  r5KA1Jo_vYU     Native Speaker            a  \n",
       "613    Male    Grad Student  xBpBBpQh7GI     Native Speaker            a  \n",
       "628    Male             PhD  pS7CzHfawDU  Europ. Non-Native            a  \n",
       "\n",
       "[81 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example Frequency Table for the emotion 'Anger':\n",
    "#Since the function does the table calculation for all different emotions, we only want to select the first table\n",
    "#which holds the table for 'anger' (since it's the first element, see declaration of emotion_label at the start)\n",
    "anger_table = hp.calcFrequencyTable(df_emotion_char, emotion_label, 'Sex')[0]\n",
    "anger_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "\n",
      "Chi square of Anger : 1.8355531358885018 with p-value of: 0.607228904660063\n",
      "Cramers V: 0.05830242253858407\n",
      "Chi square of Boredom : 3.3214939024390246 with p-value of: 0.344662280080847\n",
      "Cramers V: 0.07842776698431711\n",
      "Chi square of Disgust : 21.438540940766547 with p-value of: 8.535270195513537e-05\n",
      "Cramers V: 0.1992511022357474\n",
      "Chi square of Fear : 3.321493902439025 with p-value of: 0.34466228008084693\n",
      "Cramers V: 0.07842776698431712\n",
      "Chi square of Happiness : 1.416441637630662 with p-value of: 0.7016852861743752\n",
      "Cramers V: 0.0512156232968653\n",
      "Chi square of Emo_Neutral : 5.045566202090593 with p-value of: 0.16849080896437843\n",
      "Cramers V: 0.09666251142497065\n",
      "Chi square of Sadness : 14.351746515679443 with p-value of: 0.002463439075194692\n",
      "Cramers V: 0.16302548378204354\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Chi square of Aggressiv : 10.951228222996514 with p-value of: 0.011992547597151456\n",
      "Cramers V: 0.14240804845516408\n",
      "Chi square of Cheerful : 9.836772648083626 with p-value of: 0.02000582312257192\n",
      "Cramers V: 0.13496757256689218\n",
      "Chi square of Nervous : 2.8357055749128923 with p-value of: 0.41765582247759847\n",
      "Cramers V: 0.07246589970606217\n",
      "Chi square of Aff_Neutral : 3.378645470383275 with p-value of: 0.3368457971344178\n",
      "Cramers V: 0.07909962623856158\n",
      "Chi square of Tired : 3.5786759581881533 with p-value of: 0.3107005545636445\n",
      "Cramers V: 0.0814074793882505\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Chi square of Arousal : 11.837077526132404 with p-value of: 0.007962621009858993\n",
      "Cramers V: 0.14805577981721021\n",
      "Chi square of Valence : 7.722164634146343 with p-value of: 0.052116641458770534\n",
      "Cramers V: 0.11958388218338115\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Chi square of Normal Interest : 3.9787369337979106 with p-value of: 0.26376932972217454\n",
      "Cramers V: 0.08583723760050191\n",
      "Chi square of High Interest : 2.978584494773519 with p-value of: 0.3949388250052932\n",
      "Cramers V: 0.07426908652019058\n",
      "\n",
      "Residuals of: Aff_Neutral\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Quartile</th>\n",
       "      <th>2nd Quartile</th>\n",
       "      <th>3rd Quartile</th>\n",
       "      <th>4th Quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>1.333567</td>\n",
       "      <td>0.579005</td>\n",
       "      <td>-1.482506</td>\n",
       "      <td>-0.451751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>-1.333567</td>\n",
       "      <td>-0.579005</td>\n",
       "      <td>1.482506</td>\n",
       "      <td>0.451751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        1st Quartile  2nd Quartile  3rd Quartile  4th Quartile\n",
       "Male        1.333567      0.579005     -1.482506     -0.451751\n",
       "Female     -1.333567     -0.579005      1.482506      0.451751"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('EMOTION\\n')\n",
    "emo_sex_chi2 = hp.chi2(df_emotion_char, emotion_label,'Sex',  True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_sec_chi2 = hp.chi2(df_affect_char, affect_label,'Sex',  True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_sec_chi2 = hp.chi2(df_ar_val_char, ['Arousal', 'Valence'], 'Sex', True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_sec_chi2 = hp.chi2(df_loi_char, ['Normal Interest', 'High Interest'], 'Sex', True)\n",
    "#Have a look at residuals for significant results\n",
    "print('\\nResiduals of: '+ affect_label[3])\n",
    "aff_sec_chi2[1][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a look at the p-values regarding the different emotions, we can see significant differences in boredom, disgust, fear, neutral and sadness and can reject our hypothesis.\n",
    "To further investigate where the differences are, we'll have a look at the standardized residuals. \n",
    "Regarding boredom we see that the main differences between females and males lie between the 1st and 2nd quartile: Females have a value of ~3.11 in the 1st quartile, while males have a value of ~3.04 in the 2nd quartile. Regarding disgust we see that females tend to have values above the median (positive values in the 3rd and 4th Quartile) whereas males tend to have values below the median (positive values in 1st and 2nd Quartile). Looking at fear we see that females tend to have lower values (~3.11 in 1st Quartile) while males have a value of ~1.37 for the 2nd Quartile and ~2.04 for the 3rd Quartile, the 4th quartile does not show great differences. This means, that men tend to have more values around the median than females. Looking at neutral (emotion) we can see that males and females only differ between the 1st and 2nd quartile (female 1st quartile ~3.1; male 2nd quartile ~2.7). Regarding sadness, we see that females and males differ in the extremes: females have a value of ~4.10 for the 1st quartile whereas males have a value of ~4.04 for the 4th quartile. This implies that females tend to have lower values for sadness than males.\n",
    "\n",
    "Looking at the affect p-values, we also see statistical significance in aggressive, cheerful, intoxicated and tired; meaning the two populations are significantly different from each other and therefore again rejecting our hypotheses.\n",
    "Further looking at the residuals, we are able to see where the differences are. Regarding aggressive, we see that males tend to have lower values (1st quartile ~4.17 for males) than females (4th quartile ~4.62 for females). Looking at cheerful, we see that females tend to have lower values than males, since the value for the 4th quartile for males is ~4.04, whereas the values for females for the 2nd and 3rd quartile are ~2.96 and ~1.62. Regarding intoxication we are able to see that females tend to have higher values (3rd quartile and 4th quartile positive), whereas males have lower intoxication values (1st quartile ~4.84). Regarding tiredness, we see the most differences in the 1st and 4th quartile: males have higher values for tiredness (4th quartile ~3.71) than females (1st quartile ~3.44).\n",
    "\n",
    "Also for Arousal-Valence, we can say that the populations differ in arousal significantly. Looking at the residuals we see that females tend to have higher values than males (only 1st quartile is positive for males ~5.50).\n",
    "\n",
    "Regarding Level of Interest, we only see a statistic significant difference in disinterest. Regarding the residuals we see that females have lower values (1st and 2nd Quartile positive) for disinterest than males.\n",
    "\n",
    "So now we know, that females and males differ significantly regarding the distribution into the quantiles.\n",
    "Now move on to academic status, the hypothesis being that the variables academic status and e.g. emotion are independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "\n",
      "Chi square of Anger : 0.9505941213258285 with p-value of: 0.8132042399757146\n",
      "Cramers V: 0.04195663813911595\n",
      "Chi square of Boredom : 0.15009380863039404 with p-value of: 0.9852126093766351\n",
      "Cramers V: 0.016671877442678514\n",
      "Chi square of Disgust : 1.350844277673546 with p-value of: 0.7170964469463956\n",
      "Cramers V: 0.05001563232803554\n",
      "Chi square of Fear : 3.7523452157598496 with p-value of: 0.2894780532221424\n",
      "Cramers V: 0.08335938721339256\n",
      "Chi square of Happiness : 2.951844903064415 with p-value of: 0.399109490932093\n",
      "Cramers V: 0.07393496770892165\n",
      "Chi square of Emo_Neutral : 0.15009380863039404 with p-value of: 0.9852126093766351\n",
      "Cramers V: 0.016671877442678514\n",
      "Chi square of Sadness : 1.6532889446881744 with p-value of: 0.6473681624396519\n",
      "Cramers V: 0.05533214430931617\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Chi square of Aggressiv : 4.152595372107567 with p-value of: 0.24545104939706014\n",
      "Cramers V: 0.08769259620873833\n",
      "Chi square of Cheerful : 3.3520950594121324 with p-value of: 0.3404575488246489\n",
      "Cramers V: 0.07878821893757848\n",
      "Chi square of Nervous : 5.353345841150719 with p-value of: 0.1476780745346126\n",
      "Cramers V: 0.09956707994883836\n",
      "Chi square of Aff_Neutral : 2.951844903064415 with p-value of: 0.399109490932093\n",
      "Cramers V: 0.07393496770892165\n",
      "Chi square of Tired : 1.4320980688118046 with p-value of: 0.698028313491549\n",
      "Cramers V: 0.05149789763439476\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Chi square of Arousal : 6.275225273941578 with p-value of: 0.09896127911943746\n",
      "Cramers V: 0.10779975669887319\n",
      "Chi square of Valence : 2.9588668356319205 with p-value of: 0.39801067667467394\n",
      "Cramers V: 0.07402285477437358\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Chi square of Normal Interest : 1.4320980688118046 with p-value of: 0.698028313491549\n",
      "Cramers V: 0.05149789763439476\n",
      "Chi square of High Interest : 0.8317228342902279 with p-value of: 0.8418652630992175\n",
      "Cramers V: 0.03924573188141393\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st Quartile</th>\n",
       "      <th>2nd Quartile</th>\n",
       "      <th>3rd Quartile</th>\n",
       "      <th>4th Quartile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Grad Student</th>\n",
       "      <td>-0.387628</td>\n",
       "      <td>-1.162258</td>\n",
       "      <td>-0.913259</td>\n",
       "      <td>2.453656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhD</th>\n",
       "      <td>0.387628</td>\n",
       "      <td>1.162258</td>\n",
       "      <td>0.913259</td>\n",
       "      <td>-2.453656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1st Quartile  2nd Quartile  3rd Quartile  4th Quartile\n",
       "Grad Student     -0.387628     -1.162258     -0.913259      2.453656\n",
       "PhD               0.387628      1.162258      0.913259     -2.453656"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('EMOTION\\n')\n",
    "emo_aca_chi2 = hp.chi2(df_emotion_char, emotion_label,'Academic' , True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_aca_chi2 = hp.chi2(df_affect_char, affect_label,'Academic', True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_aca_chi2 = hp.chi2(df_ar_val_char, ['Arousal', 'Valence'],  'Academic',True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_aca_chi2 = hp.chi2(df_loi_char, ['Normal Interest', 'High Interest'],'Academic', True)\n",
    "ar_val_aca_chi2[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at emotion, we see that Grad Students and PhDs do not differ significantly.\n",
    "\n",
    "The same thing goes for affect, we can't see any significant resutls.\n",
    "\n",
    "Looking at arousal valence, we see that Grad Students and PhDs differ in arousal. By looking at the residuals we see that PhDs have lower values (2nd Quartile ~2.58) than Grad Students (4th Quartile ~1.76).\n",
    "\n",
    "Looking at Level of Interest, we can see that GradStudents and PhDs do not differ.\n",
    "\n",
    "So, PhDs and Grad Students only differ in arousal.\n",
    "\n",
    "Again, we do not know yet where exactly those differences are.\n",
    "\n",
    "\n",
    "Now let's look at Native Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "\n",
      "Chi square of Anger : 10.462144612144611 with p-value of: 0.10649119848258841\n",
      "Cramers V: 0.13919174499352277\n",
      "Chi square of Boredom : 10.374008424008423 with p-value of: 0.10975981176500317\n",
      "Cramers V: 0.13860420885069366\n",
      "Chi square of Disgust : 6.205071955071954 with p-value of: 0.40061445305667526\n",
      "Cramers V: 0.10719549426572923\n",
      "Chi square of Fear : 6.1441821691821685 with p-value of: 0.40723419803423266\n",
      "Cramers V: 0.10666824798465159\n",
      "Chi square of Happiness : 6.3730519480519465 with p-value of: 0.38272290337583825\n",
      "Cramers V: 0.10863677117784774\n",
      "Chi square of Emo_Neutral : 9.75539663039663 with p-value of: 0.13533795785838437\n",
      "Cramers V: 0.13440814452833325\n",
      "Chi square of Sadness : 6.849271674271674 with p-value of: 0.3350118012481717\n",
      "Cramers V: 0.11262253963499683\n",
      "\n",
      "AFFECT\n",
      "\n",
      "Chi square of Aggressiv : 6.528474903474904 with p-value of: 0.36665916243772895\n",
      "Cramers V: 0.10995348261773404\n",
      "Chi square of Cheerful : 5.346691821691819 with p-value of: 0.500176183426803\n",
      "Cramers V: 0.09950518152981355\n",
      "Chi square of Nervous : 7.581844506844506 with p-value of: 0.27036604192093866\n",
      "Cramers V: 0.1184924165947036\n",
      "Chi square of Aff_Neutral : 9.373710073710075 with p-value of: 0.15362591796476632\n",
      "Cramers V: 0.13175250418387638\n",
      "Chi square of Tired : 6.087320112320111 with p-value of: 0.4134799154086797\n",
      "Cramers V: 0.10617351375373718\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "Chi square of Arousal : 3.2029922779922777 with p-value of: 0.7829717740890527\n",
      "Cramers V: 0.07701601899259128\n",
      "Chi square of Valence : 5.544998244998246 with p-value of: 0.4760348266005041\n",
      "Cramers V: 0.10133368279360655\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "Chi square of Normal Interest : 2.5057213057213055 with p-value of: 0.8678268114920646\n",
      "Cramers V: 0.0681191943597738\n",
      "Chi square of High Interest : 3.8291856791856786 with p-value of: 0.6997792686379445\n",
      "Cramers V: 0.0842085778949187\n"
     ]
    }
   ],
   "source": [
    "print('EMOTION\\n')\n",
    "emo_age_chi2 = hp.chi2(df_emotion_char, emotion_label,'IsNativeSpeaker', True)\n",
    "print('\\nAFFECT\\n')\n",
    "aff_age_chi2 = hp.chi2(df_affect_char, affect_label, 'IsNativeSpeaker', True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "ar_val_age_chi2 = hp.chi2(df_ar_val_char, ['Arousal', 'Valence'],'IsNativeSpeaker' ,True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "loi_age_chi2 = hp.chi2(df_loi_char, ['Normal Interest', 'High Interest'], 'IsNativeSpeaker',  True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Hoc tests for age and native speaker, as they have three different groups\n",
    "\n",
    "If a significant p-value for the category 'NativeSpeaker' is found, we do not yet know which groups differ significantly from each other, so post-hoc testing is done for this character feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "\n",
      "post-hoc emotions and different groups\n",
      "Anger\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [0.94784137 1.         1.        ]\n",
      "Boredom\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1.         0.69507846 0.96736552]\n",
      "Disgust\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Fear\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1.         1.         0.98814352]\n",
      "Happiness\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Emo_Neutral\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1.         0.99638625 0.65983048]\n",
      "Sadness\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "\n",
      "AFFECT\n",
      "\n",
      "\n",
      " post-hoc affect and different groups\n",
      "Aggressiv\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Cheerful\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Nervous\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Aff_Neutral\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1.         1.         0.51492915]\n",
      "Tired\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "\n",
      "AROUSAL-VALENCE\n",
      "\n",
      "\n",
      " post-hoc arousal-valence and different groups\n",
      "Arousal\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "Valence\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "\n",
      "LEVEL OF INTEREST\n",
      "\n",
      "\n",
      " post-hoc level of intereset and different groups\n",
      "Normal Interest\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n",
      "High Interest\n",
      "Combinations: [('Asian Non-Native', 'Europ. Non-Native'), ('Asian Non-Native', 'Native Speaker'), ('Europ. Non-Native', 'Native Speaker')]\n",
      "Reject List: [False False False]\n",
      "Corrected p-values: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('EMOTION\\n')\n",
    "print('post-hoc emotions and different groups')\n",
    "emo_reject_list, emo_corrected_p_vals, emo_combinations, emo_residuals= hp.chi2_post_hoc(df_emotion_char,emotion_label, 'IsNativeSpeaker', 'bonferroni', True, True)\n",
    "print('\\nAFFECT\\n')\n",
    "print('\\n post-hoc affect and different groups')\n",
    "aff_reject_list, emo_corrected_p_vals, emo_combinations, aff_residuals = hp.chi2_post_hoc(df_affect_char, affect_label, 'IsNativeSpeaker' ,'bonferroni', True, True)\n",
    "print('\\nAROUSAL-VALENCE\\n')\n",
    "print('\\n post-hoc arousal-valence and different groups')\n",
    "ar_val_reject_list, ar_val_corrected_p_vals, ar_val_combinations, ar_val_residuals = hp.chi2_post_hoc(df_ar_val_char, ['Arousal', 'Valence'], 'IsNativeSpeaker', 'bonferroni',True, True)\n",
    "print('\\nLEVEL OF INTEREST\\n')\n",
    "print('\\n post-hoc level of intereset and different groups')\n",
    "loi_reject_list, loi_corrected_p_vals, loi_combinations, loi_residuals = hp.chi2_post_hoc(df_loi_char, ['Normal Interest', 'High Interest'], 'IsNativeSpeaker', 'bonferroni', True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
